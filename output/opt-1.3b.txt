main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-21 11:21:51 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 6.6452435174473905, 'ppl_stderr': 0.1717334950286951, 'acc': 0.578497962352028, 'acc_stderr': 0.006879594313377058}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7efefe6d0880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-21 11:28:26 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 6.6452435174473905, 'ppl_stderr': 0.1717334950286951, 'acc': 0.578497962352028, 'acc_stderr': 0.006879594313377058}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f21fe1aa820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks piqa 2023-08-21 11:33:07 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='piqa', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'piqa': {'acc': 0.7181719260065288, 'acc_stderr': 0.010496675231258168, 'acc_norm': 0.7236126224156693, 'acc_norm_stderr': 0.010434162388275598}}, 'versions': {'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fd182115820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks openbookqa 2023-08-21 11:35:52 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='openbookqa', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'openbookqa': {'acc': 0.234, 'acc_stderr': 0.018952741564893676, 'acc_norm': 0.33, 'acc_norm_stderr': 0.021049612166134806}}, 'versions': {'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f3f9664dbe0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks boolq 2023-08-21 11:43:06 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'boolq': {'acc': 0.5761467889908257, 'acc_stderr': 0.008643046537505767}}, 'versions': {'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f8698e53850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_easy 2023-08-21 11:57:20 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='arc_easy', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'arc_easy': {'acc': 0.5707070707070707, 'acc_stderr': 0.010156678075911084, 'acc_norm': 0.51010101010101, 'acc_norm_stderr': 0.010257689687458363}}, 'versions': {'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f22ab78bb20>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge 2023-08-21 12:01:58 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='arc_challenge', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'arc_challenge': {'acc': 0.23293515358361774, 'acc_stderr': 0.012352507042617396, 'acc_norm': 0.29436860068259385, 'acc_norm_stderr': 0.013318528460539426}}, 'versions': {'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fc14d25e5e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-21 12:39:35 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 16.866004943847656, 'ptb': 19.355514526367188, 'c4': 16.580123901367188, 'results': {'arc_easy': {'acc': 0.5572390572390572, 'acc_stderr': 0.010192333348394455, 'acc_norm': 0.49158249158249157, 'acc_norm_stderr': 0.010258329515226443}, 'openbookqa': {'acc': 0.22, 'acc_stderr': 0.01854421137582033, 'acc_norm': 0.308, 'acc_norm_stderr': 0.020667032987466104}, 'piqa': {'acc': 0.6947769314472253, 'acc_stderr': 0.01074426704560648, 'acc_norm': 0.705114254624592, 'acc_norm_stderr': 0.010639030620156987}, 'boolq': {'acc': 0.5342507645259938, 'acc_stderr': 0.00872451294182108}, 'lambada_openai': {'ppl': 8.410804730785049, 'ppl_stderr': 0.22762419081562965, 'acc': 0.5309528430040753, 'acc_stderr': 0.006952616937575539}, 'arc_challenge': {'acc': 0.24829351535836178, 'acc_stderr': 0.012624912868089753, 'acc_norm': 0.2909556313993174, 'acc_norm_stderr': 0.013273077865907586}}, 'versions': {'arc_easy': 0, 'openbookqa': 0, 'piqa': 0, 'boolq': 1, 'lambada_openai': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f298db7a940>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:06:49 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 14.624846458435059, 'ptb': 16.961503982543945, 'c4': 14.72014045715332, 'results': {'boolq': {'acc': 0.5761467889908257, 'acc_stderr': 0.008643046537505767}, 'lambada_openai': {'ppl': 6.6452435174473905, 'ppl_stderr': 0.1717334950286951, 'acc': 0.578497962352028, 'acc_stderr': 0.006879594313377058}, 'piqa': {'acc': 0.7181719260065288, 'acc_stderr': 0.010496675231258168, 'acc_norm': 0.7236126224156693, 'acc_norm_stderr': 0.010434162388275598}, 'arc_easy': {'acc': 0.5707070707070707, 'acc_stderr': 0.010156678075911084, 'acc_norm': 0.51010101010101, 'acc_norm_stderr': 0.010257689687458363}, 'arc_challenge': {'acc': 0.23293515358361774, 'acc_stderr': 0.012352507042617396, 'acc_norm': 0.29436860068259385, 'acc_norm_stderr': 0.013318528460539426}, 'openbookqa': {'acc': 0.234, 'acc_stderr': 0.018952741564893676, 'acc_norm': 0.33, 'acc_norm_stderr': 0.021049612166134806}}, 'versions': {'boolq': 1, 'lambada_openai': 0, 'piqa': 0, 'arc_easy': 0, 'arc_challenge': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7ff715bb08b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:11:41 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 14.624846458435059}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:13:11 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 14.624846458435059}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:20:00 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 14.624846458435059}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:21:45 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:24:54 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:26:04 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:26:53 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:27:18 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 10:53:47 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:06:36 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:34:06 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:35:27 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:35:57 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:36:27 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:36:54 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:37:24 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:39:33 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:43:44 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:48:06 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'ptb': 1.070285439491272}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 11:49:02 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'ptb': 1.070285439491272}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge --multigpu 2023-08-25 10:07:58 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 16.891199111938477}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge --multigpu 2023-08-25 10:15:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'ptb': 19.240766525268555}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge --multigpu 2023-08-25 10:25:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'ptb': 19.240766525268555}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge 2023-08-25 11:05:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0175347328186035}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge 2023-08-25 11:10:48 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0175347328186035}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge 2023-08-25 11:17:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0175347328186035}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge 2023-08-25 11:22:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0175347328186035}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge 2023-08-25 11:27:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0175347328186035}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge 2023-08-25 11:31:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0175347328186035}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks arc_challenge 2023-08-25 16:07:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='arc_challenge', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, batch_size=1, model='facebook/opt-1.3b') 
 w4a4 {'wikitext2': 14.6225004196167}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-08 20:44:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.676910400390625, 'ptb': 21.379087448120117, 'c4': 18.05318260192871, 'results': {'piqa': {'acc': 0.6887921653971708, 'acc_stderr': 0.01080226387804584, 'acc_norm': 0.690424374319913, 'acc_norm_stderr': 0.010786656752183345}, 'openbookqa': {'acc': 0.236, 'acc_stderr': 0.019008699622084718, 'acc_norm': 0.326, 'acc_norm_stderr': 0.02098400956239357}, 'boolq': {'acc': 0.5697247706422018, 'acc_stderr': 0.008659608602932498}, 'lambada_openai': {'ppl': 9.864813405686112, 'ppl_stderr': 0.2827855304049638, 'acc': 0.5051426353580438, 'acc_stderr': 0.006965609193226177}, 'arc_challenge': {'acc': 0.23122866894197952, 'acc_stderr': 0.012320858834772273, 'acc_norm': 0.2636518771331058, 'acc_norm_stderr': 0.012875929151297061}, 'arc_easy': {'acc': 0.5269360269360269, 'acc_stderr': 0.010244884740620117, 'acc_norm': 0.4764309764309764, 'acc_norm_stderr': 0.010248378585554037}}, 'versions': {'piqa': 0, 'openbookqa': 0, 'boolq': 1, 'lambada_openai': 0, 'arc_challenge': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f04957488e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-08 21:39:58 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.57569694519043, 'ptb': 21.25879669189453, 'c4': 17.936487197875977, 'results': {'arc_easy': {'acc': 0.5353535353535354, 'acc_stderr': 0.010234104543411436, 'acc_norm': 0.4692760942760943, 'acc_norm_stderr': 0.01024039558481524}, 'openbookqa': {'acc': 0.23, 'acc_stderr': 0.018839050391123137, 'acc_norm': 0.322, 'acc_norm_stderr': 0.02091666833001988}, 'piqa': {'acc': 0.6947769314472253, 'acc_stderr': 0.01074426704560648, 'acc_norm': 0.6844396082698585, 'acc_norm_stderr': 0.010843119201758938}, 'arc_challenge': {'acc': 0.23720136518771331, 'acc_stderr': 0.012430399829260846, 'acc_norm': 0.26791808873720135, 'acc_norm_stderr': 0.012942030195136423}, 'boolq': {'acc': 0.5593272171253822, 'acc_stderr': 0.008683276495829013}, 'lambada_openai': {'ppl': 9.877312122100891, 'ppl_stderr': 0.28689091661823934, 'acc': 0.5115466718416456, 'acc_stderr': 0.00696411992274735}}, 'versions': {'arc_easy': 0, 'openbookqa': 0, 'piqa': 0, 'arc_challenge': 0, 'boolq': 1, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7fbbdbc880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-08 22:31:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.612272262573242, 'ptb': 21.112594604492188, 'c4': 17.897871017456055, 'results': {'openbookqa': {'acc': 0.226, 'acc_stderr': 0.018722956449139933, 'acc_norm': 0.308, 'acc_norm_stderr': 0.020667032987466104}, 'lambada_openai': {'ppl': 9.846389651774654, 'ppl_stderr': 0.28310798069134513, 'acc': 0.5028138948185523, 'acc_stderr': 0.00696586734303969}, 'arc_easy': {'acc': 0.523989898989899, 'acc_stderr': 0.010247967392742688, 'acc_norm': 0.4743265993265993, 'acc_norm_stderr': 0.010246249665591237}, 'boolq': {'acc': 0.5706422018348624, 'acc_stderr': 0.008657333755353677}, 'arc_challenge': {'acc': 0.24232081911262798, 'acc_stderr': 0.012521593295800116, 'acc_norm': 0.2636518771331058, 'acc_norm_stderr': 0.012875929151297058}, 'piqa': {'acc': 0.7007616974972797, 'acc_stderr': 0.01068413067313458, 'acc_norm': 0.705114254624592, 'acc_norm_stderr': 0.010639030620156992}}, 'versions': {'openbookqa': 0, 'lambada_openai': 0, 'arc_easy': 0, 'boolq': 1, 'arc_challenge': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fab9e95c850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-08 23:24:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.389917373657227, 'ptb': 20.8956298828125, 'c4': 17.71977996826172, 'results': {'lambada_openai': {'ppl': 9.52785757531731, 'ppl_stderr': 0.27315327323966915, 'acc': 0.5148457209392587, 'acc_stderr': 0.006962906440875387}, 'arc_challenge': {'acc': 0.2431740614334471, 'acc_stderr': 0.012536554144587092, 'acc_norm': 0.27986348122866894, 'acc_norm_stderr': 0.013119040897725923}, 'openbookqa': {'acc': 0.228, 'acc_stderr': 0.0187813065293632, 'acc_norm': 0.348, 'acc_norm_stderr': 0.0213237286328075}, 'arc_easy': {'acc': 0.5429292929292929, 'acc_stderr': 0.010221897564256052, 'acc_norm': 0.476010101010101, 'acc_norm_stderr': 0.010247967392742693}, 'boolq': {'acc': 0.5896024464831804, 'acc_stderr': 0.008603488048617521}, 'piqa': {'acc': 0.6893362350380848, 'acc_stderr': 0.010797078933727673, 'acc_norm': 0.6980413492927094, 'acc_norm_stderr': 0.01071173289158834}}, 'versions': {'lambada_openai': 0, 'arc_challenge': 0, 'openbookqa': 0, 'arc_easy': 0, 'boolq': 1, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fac293bc7c0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-09 00:21:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.577081680297852, 'ptb': 18.05855941772461, 'c4': 15.801896095275879, 'results': {'boolq': {'acc': 0.5892966360856269, 'acc_stderr': 0.008604460608471412}, 'arc_challenge': {'acc': 0.2363481228668942, 'acc_stderr': 0.012414960524301829, 'acc_norm': 0.2790102389078498, 'acc_norm_stderr': 0.013106784883601346}, 'arc_easy': {'acc': 0.563973063973064, 'acc_stderr': 0.010175459582759743, 'acc_norm': 0.49537037037037035, 'acc_norm_stderr': 0.01025934370588974}, 'lambada_openai': {'ppl': 6.907021546694096, 'ppl_stderr': 0.18363104179873596, 'acc': 0.5736464195614205, 'acc_stderr': 0.006889999234952311}, 'openbookqa': {'acc': 0.232, 'acc_stderr': 0.018896193591952045, 'acc_norm': 0.336, 'acc_norm_stderr': 0.021144791425048843}, 'piqa': {'acc': 0.7089227421109902, 'acc_stderr': 0.010598612490942596, 'acc_norm': 0.7083786724700761, 'acc_norm_stderr': 0.010604441527428794}}, 'versions': {'boolq': 1, 'arc_challenge': 0, 'arc_easy': 0, 'lambada_openai': 0, 'openbookqa': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f1b50ba87c0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-09 01:11:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.4410982131958, 'ptb': 18.053075790405273, 'c4': 15.676322937011719, 'results': {'piqa': {'acc': 0.7094668117519043, 'acc_stderr': 0.010592765034696536, 'acc_norm': 0.7121871599564744, 'acc_norm_stderr': 0.010563250383059188}, 'arc_challenge': {'acc': 0.23720136518771331, 'acc_stderr': 0.012430399829260846, 'acc_norm': 0.2883959044368601, 'acc_norm_stderr': 0.013238394422428164}, 'boolq': {'acc': 0.5948012232415902, 'acc_stderr': 0.008586427929715524}, 'openbookqa': {'acc': 0.236, 'acc_stderr': 0.019008699622084718, 'acc_norm': 0.336, 'acc_norm_stderr': 0.02114479142504885}, 'arc_easy': {'acc': 0.5664983164983165, 'acc_stderr': 0.010168640625454103, 'acc_norm': 0.494949494949495, 'acc_norm_stderr': 0.010259260102565849}, 'lambada_openai': {'ppl': 6.49676377193709, 'ppl_stderr': 0.17092844619510533, 'acc': 0.5911119736076073, 'acc_stderr': 0.006849346665262429}}, 'versions': {'piqa': 0, 'arc_challenge': 0, 'boolq': 1, 'openbookqa': 0, 'arc_easy': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f0bb7898850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-09 02:09:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.429793357849121, 'ptb': 18.0076847076416, 'c4': 15.645108222961426, 'results': {'lambada_openai': {'ppl': 6.524483038901522, 'ppl_stderr': 0.17167187773254503, 'acc': 0.5897535416262372, 'acc_stderr': 0.006852827058720169}, 'arc_challenge': {'acc': 0.24488054607508533, 'acc_stderr': 0.012566273985131356, 'acc_norm': 0.29180887372013653, 'acc_norm_stderr': 0.013284525292403501}, 'piqa': {'acc': 0.7127312295973884, 'acc_stderr': 0.010557291761528635, 'acc_norm': 0.7094668117519043, 'acc_norm_stderr': 0.010592765034696534}, 'boolq': {'acc': 0.599388379204893, 'acc_stderr': 0.008570545612096374}, 'arc_easy': {'acc': 0.571969696969697, 'acc_stderr': 0.01015294331642625, 'acc_norm': 0.5016835016835017, 'acc_norm_stderr': 0.01025972536458276}, 'openbookqa': {'acc': 0.234, 'acc_stderr': 0.018952741564893676, 'acc_norm': 0.328, 'acc_norm_stderr': 0.021017027165175495}}, 'versions': {'lambada_openai': 0, 'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'arc_easy': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7d28ce0850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-09 03:02:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.446808815002441, 'ptb': 17.975671768188477, 'c4': 15.626976013183594, 'results': {'piqa': {'acc': 0.7100108813928183, 'acc_stderr': 0.010586899128169328, 'acc_norm': 0.7143634385201306, 'acc_norm_stderr': 0.010539303948661915}, 'arc_challenge': {'acc': 0.2431740614334471, 'acc_stderr': 0.01253655414458709, 'acc_norm': 0.2841296928327645, 'acc_norm_stderr': 0.013179442447653884}, 'openbookqa': {'acc': 0.23, 'acc_stderr': 0.018839050391123137, 'acc_norm': 0.33, 'acc_norm_stderr': 0.021049612166134796}, 'arc_easy': {'acc': 0.5652356902356902, 'acc_stderr': 0.010172083670402792, 'acc_norm': 0.4983164983164983, 'acc_norm_stderr': 0.010259725364582785}, 'boolq': {'acc': 0.6082568807339449, 'acc_stderr': 0.008537618477478614}, 'lambada_openai': {'ppl': 6.557797361135642, 'ppl_stderr': 0.17249066994627407, 'acc': 0.5858723073937512, 'acc_stderr': 0.006862473721550981}}, 'versions': {'piqa': 0, 'arc_challenge': 0, 'openbookqa': 0, 'arc_easy': 0, 'boolq': 1, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f8bcd4e4760>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-09 12:21:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.44567108154297, 'ptb': 21.600141525268555, 'c4': 17.824012756347656, 'results': {'lambada_openai': {'ppl': 9.515361534509461, 'ppl_stderr': 0.2757811567850233, 'acc': 0.5226081894042306, 'acc_stderr': 0.006958852970187403}, 'openbookqa': {'acc': 0.194, 'acc_stderr': 0.017701827855304626, 'acc_norm': 0.306, 'acc_norm_stderr': 0.020629569998345396}, 'piqa': {'acc': 0.6942328618063112, 'acc_stderr': 0.010749627366141634, 'acc_norm': 0.6898803046789989, 'acc_norm_stderr': 0.010791876566843042}, 'arc_challenge': {'acc': 0.23122866894197952, 'acc_stderr': 0.01232085883477228, 'acc_norm': 0.27047781569965873, 'acc_norm_stderr': 0.012980954547659554}, 'boolq': {'acc': 0.5525993883792049, 'acc_stderr': 0.008696530539281535}, 'arc_easy': {'acc': 0.5446127946127947, 'acc_stderr': 0.010218861787618716, 'acc_norm': 0.48358585858585856, 'acc_norm_stderr': 0.010254253565929301}}, 'versions': {'lambada_openai': 0, 'openbookqa': 0, 'piqa': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7feb211dc7f0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-09 13:16:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.482120513916016, 'ptb': 21.60388946533203, 'c4': 17.729955673217773, 'results': {'openbookqa': {'acc': 0.208, 'acc_stderr': 0.018169542221229892, 'acc_norm': 0.3, 'acc_norm_stderr': 0.020514426225628046}, 'arc_challenge': {'acc': 0.23720136518771331, 'acc_stderr': 0.01243039982926084, 'acc_norm': 0.2696245733788396, 'acc_norm_stderr': 0.012968040686869147}, 'boolq': {'acc': 0.5645259938837921, 'acc_stderr': 0.008671927333703597}, 'arc_easy': {'acc': 0.5429292929292929, 'acc_stderr': 0.010221897564256049, 'acc_norm': 0.4831649831649832, 'acc_norm_stderr': 0.0102539662612889}, 'piqa': {'acc': 0.6833514689880305, 'acc_stderr': 0.010853160531978481, 'acc_norm': 0.6947769314472253, 'acc_norm_stderr': 0.01074426704560648}, 'lambada_openai': {'ppl': 9.579981709656616, 'ppl_stderr': 0.27623450229082946, 'acc': 0.5136813506695129, 'acc_stderr': 0.0069633693944619055}}, 'versions': {'openbookqa': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0, 'piqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f61a241c820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-09 14:07:05 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.41893196105957, 'ptb': 21.333669662475586, 'c4': 17.722551345825195, 'results': {'arc_easy': {'acc': 0.5496632996632996, 'acc_stderr': 0.010209047724374158, 'acc_norm': 0.48569023569023567, 'acc_norm_stderr': 0.01025558088160363}, 'arc_challenge': {'acc': 0.24146757679180889, 'acc_stderr': 0.012506564839739432, 'acc_norm': 0.27559726962457337, 'acc_norm_stderr': 0.013057169655761838}, 'lambada_openai': {'ppl': 9.520441577214962, 'ppl_stderr': 0.27517966605061417, 'acc': 0.5165922763438774, 'acc_stderr': 0.006962141082747484}, 'piqa': {'acc': 0.690968443960827, 'acc_stderr': 0.01078141946440698, 'acc_norm': 0.6985854189336235, 'acc_norm_stderr': 0.010706248242753758}, 'openbookqa': {'acc': 0.222, 'acc_stderr': 0.01860441475825008, 'acc_norm': 0.312, 'acc_norm_stderr': 0.02074059653648807}, 'boolq': {'acc': 0.5859327217125382, 'acc_stderr': 0.008614932353134947}}, 'versions': {'arc_easy': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'piqa': 0, 'openbookqa': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7fe328380850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-09 14:56:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.312471389770508, 'ptb': 21.065914154052734, 'c4': 17.654434204101562, 'results': {'arc_easy': {'acc': 0.547979797979798, 'acc_stderr': 0.010212436978834094, 'acc_norm': 0.4810606060606061, 'acc_norm_stderr': 0.010252420496894489}, 'lambada_openai': {'ppl': 9.297431630715126, 'ppl_stderr': 0.2661289611281539, 'acc': 0.5119347952648943, 'acc_stderr': 0.006963992915953921}, 'arc_challenge': {'acc': 0.2363481228668942, 'acc_stderr': 0.012414960524301837, 'acc_norm': 0.26706484641638223, 'acc_norm_stderr': 0.01292893319649635}, 'piqa': {'acc': 0.6926006528835691, 'acc_stderr': 0.010765602506939068, 'acc_norm': 0.6936887921653971, 'acc_norm_stderr': 0.010754970032367321}, 'openbookqa': {'acc': 0.2, 'acc_stderr': 0.017906459241433848, 'acc_norm': 0.312, 'acc_norm_stderr': 0.02074059653648807}, 'boolq': {'acc': 0.5929663608562691, 'acc_stderr': 0.008592562887068868}}, 'versions': {'arc_easy': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'piqa': 0, 'openbookqa': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f14a0a687c0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-09 15:50:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.389915466308594, 'ptb': 17.767019271850586, 'c4': 15.476144790649414, 'results': {'arc_challenge': {'acc': 0.2431740614334471, 'acc_stderr': 0.012536554144587092, 'acc_norm': 0.2815699658703072, 'acc_norm_stderr': 0.013143376735009019}, 'piqa': {'acc': 0.7072905331882481, 'acc_stderr': 0.010616044462393092, 'acc_norm': 0.7121871599564744, 'acc_norm_stderr': 0.010563250383059188}, 'arc_easy': {'acc': 0.5698653198653199, 'acc_stderr': 0.010159130445178495, 'acc_norm': 0.49452861952861954, 'acc_norm_stderr': 0.010259169228615033}, 'openbookqa': {'acc': 0.218, 'acc_stderr': 0.018483378223178856, 'acc_norm': 0.318, 'acc_norm_stderr': 0.020847571620814007}, 'boolq': {'acc': 0.5874617737003058, 'acc_stderr': 0.008610223886822886}, 'lambada_openai': {'ppl': 6.878675513901142, 'ppl_stderr': 0.1841663546071837, 'acc': 0.5763632835241607, 'acc_stderr': 0.006884256176207532}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'arc_easy': 0, 'openbookqa': 0, 'boolq': 1, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fc3ab9e8880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-09 16:40:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.40140438079834, 'ptb': 17.741588592529297, 'c4': 15.47044849395752, 'results': {'piqa': {'acc': 0.7072905331882481, 'acc_stderr': 0.010616044462393092, 'acc_norm': 0.7078346028291621, 'acc_norm_stderr': 0.010610252174513666}, 'arc_challenge': {'acc': 0.23720136518771331, 'acc_stderr': 0.01243039982926084, 'acc_norm': 0.27474402730375425, 'acc_norm_stderr': 0.013044617212771227}, 'openbookqa': {'acc': 0.226, 'acc_stderr': 0.018722956449139926, 'acc_norm': 0.33, 'acc_norm_stderr': 0.0210496121661348}, 'lambada_openai': {'ppl': 6.760956817408331, 'ppl_stderr': 0.1798421553493889, 'acc': 0.5800504560450224, 'acc_stderr': 0.006876121089945557}, 'boolq': {'acc': 0.5712538226299694, 'acc_stderr': 0.008655800332760222}, 'arc_easy': {'acc': 0.5660774410774411, 'acc_stderr': 0.010169795770462111, 'acc_norm': 0.49663299663299665, 'acc_norm_stderr': 0.010259550893798932}}, 'versions': {'piqa': 0, 'arc_challenge': 0, 'openbookqa': 0, 'lambada_openai': 0, 'boolq': 1, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7709120820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-09 17:32:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.378219604492188, 'ptb': 17.761619567871094, 'c4': 15.484647750854492, 'results': {'boolq': {'acc': 0.5954128440366973, 'acc_stderr': 0.008584355308932692}, 'lambada_openai': {'ppl': 6.684576601254408, 'ppl_stderr': 0.1775416788401868, 'acc': 0.5823791965845139, 'acc_stderr': 0.006870780296924439}, 'arc_challenge': {'acc': 0.24061433447098976, 'acc_stderr': 0.012491468532390575, 'acc_norm': 0.29180887372013653, 'acc_norm_stderr': 0.013284525292403504}, 'arc_easy': {'acc': 0.5681818181818182, 'acc_stderr': 0.010163945352271726, 'acc_norm': 0.5037878787878788, 'acc_norm_stderr': 0.01025948910135184}, 'openbookqa': {'acc': 0.23, 'acc_stderr': 0.018839050391123133, 'acc_norm': 0.318, 'acc_norm_stderr': 0.020847571620814007}, 'piqa': {'acc': 0.7094668117519043, 'acc_stderr': 0.010592765034696538, 'acc_norm': 0.7149075081610446, 'acc_norm_stderr': 0.010533270588738947}}, 'versions': {'boolq': 1, 'lambada_openai': 0, 'arc_challenge': 0, 'arc_easy': 0, 'openbookqa': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f90dce688e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-09 18:22:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.390557289123535, 'ptb': 17.746206283569336, 'c4': 15.468353271484375, 'results': {'piqa': {'acc': 0.70620239390642, 'acc_stderr': 0.010627574080514802, 'acc_norm': 0.705658324265506, 'acc_norm_stderr': 0.010633311470347507}, 'arc_easy': {'acc': 0.5669191919191919, 'acc_stderr': 0.01016747801370178, 'acc_norm': 0.49747474747474746, 'acc_norm_stderr': 0.010259652668783469}, 'arc_challenge': {'acc': 0.24232081911262798, 'acc_stderr': 0.012521593295800116, 'acc_norm': 0.2935153583617747, 'acc_norm_stderr': 0.013307250444941127}, 'boolq': {'acc': 0.5819571865443425, 'acc_stderr': 0.008626774352070744}, 'openbookqa': {'acc': 0.22, 'acc_stderr': 0.01854421137582033, 'acc_norm': 0.324, 'acc_norm_stderr': 0.020950557312477455}, 'lambada_openai': {'ppl': 6.509452630679015, 'ppl_stderr': 0.1728664526053479, 'acc': 0.5883951096448671, 'acc_stderr': 0.006856253444470222}}, 'versions': {'piqa': 0, 'arc_easy': 0, 'arc_challenge': 0, 'boolq': 1, 'openbookqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fa866274850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-09-10 10:23:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 16.893321990966797, 'ptb': 19.314395904541016, 'c4': 16.58018684387207, 'results': {'arc_easy': {'acc': 0.5534511784511784, 'acc_stderr': 0.01020099007624532, 'acc_norm': 0.48653198653198654, 'acc_norm_stderr': 0.010256060854840748}, 'lambada_openai': {'ppl': 8.258894167527707, 'ppl_stderr': 0.22608299466076567, 'acc': 0.5486124587618862, 'acc_stderr': 0.006932975888368622}, 'openbookqa': {'acc': 0.216, 'acc_stderr': 0.01842190906141194, 'acc_norm': 0.306, 'acc_norm_stderr': 0.020629569998345396}, 'piqa': {'acc': 0.70620239390642, 'acc_stderr': 0.010627574080514802, 'acc_norm': 0.7072905331882481, 'acc_norm_stderr': 0.010616044462393094}, 'boolq': {'acc': 0.5513761467889908, 'acc_stderr': 0.008698767182005275}, 'arc_challenge': {'acc': 0.23720136518771331, 'acc_stderr': 0.01243039982926084, 'acc_norm': 0.2764505119453925, 'acc_norm_stderr': 0.013069662474252425}}, 'versions': {'arc_easy': 0, 'lambada_openai': 0, 'openbookqa': 0, 'piqa': 0, 'boolq': 1, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7efaf7db4dc0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 11:15:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 14.804670333862305, 'ptb': 17.12721061706543, 'c4': 14.979722023010254}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 11:25:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 14.804670333862305, 'ptb': 17.12721061706543, 'c4': 14.979722023010254}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 11:33:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 14.804670333862305, 'ptb': 17.12721061706543, 'c4': 14.979722023010254}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 11:49:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.312471389770508, 'ptb': 21.065914154052734, 'c4': 17.654434204101562}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 11:59:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.333431243896484, 'ptb': 20.96194076538086, 'c4': 17.602752685546875}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 12:56:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 17.754135131835938, 'ptb': 20.429309844970703, 'c4': 17.239450454711914}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 13:05:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 17.66284942626953, 'ptb': 20.15365219116211, 'c4': 17.194461822509766}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 13:15:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.35223960876465, 'ptb': 21.06957244873047, 'c4': 17.62986946105957}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 13:24:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.05373191833496, 'ptb': 20.933757781982422, 'c4': 17.4466552734375}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 13:33:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 17.17791175842285, 'ptb': 19.726993560791016, 'c4': 16.837818145751953}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 13:42:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 14.804670333862305, 'ptb': 17.12721061706543, 'c4': 14.979722023010254}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 13:53:36 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 16.038515090942383, 'ptb': 18.457944869995117, 'c4': 16.003814697265625}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-09-10 14:18:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 15.311214447021484, 'ptb': 17.746980667114258, 'c4': 15.39609146118164}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-10 14:38:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 16.038515090942383, 'ptb': 18.457944869995117, 'c4': 16.003814697265625}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-09-10 15:23:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=1, R3_clusters=1, R4_clusters=32, R5_clusters=128, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.617856979370117, 'ptb': 21.379087448120117, 'c4': 17.796836853027344}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-09-10 16:09:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=1, R3_clusters=1, R4_clusters=32, R5_clusters=128, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.617856979370117, 'ptb': 21.379087448120117, 'c4': 17.796836853027344, 'results': {'piqa': {'acc': 0.6985854189336235, 'acc_stderr': 0.01070624824275376, 'acc_norm': 0.6931447225244831, 'acc_norm_stderr': 0.010760295070580366}, 'boolq': {'acc': 0.5510703363914373, 'acc_stderr': 0.008699318031464162}, 'openbookqa': {'acc': 0.208, 'acc_stderr': 0.018169542221229882, 'acc_norm': 0.33, 'acc_norm_stderr': 0.021049612166134792}, 'arc_easy': {'acc': 0.5324074074074074, 'acc_stderr': 0.010238210368801896, 'acc_norm': 0.47895622895622897, 'acc_norm_stderr': 0.010250692602022582}, 'lambada_openai': {'ppl': 9.912727480717935, 'ppl_stderr': 0.28347750754155004, 'acc': 0.5068891907626625, 'acc_stderr': 0.006965316401981031}, 'arc_challenge': {'acc': 0.23122866894197952, 'acc_stderr': 0.012320858834772264, 'acc_norm': 0.27303754266211605, 'acc_norm_stderr': 0.013019332762635737}}, 'versions': {'piqa': 0, 'boolq': 1, 'openbookqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fb8ff1c8d30>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-10 19:55:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=1, R3_clusters=1, R4_clusters=32, R5_clusters=128, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, batch_size=1, model='facebook/opt-1.3b') 
 w4a4 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875, 'results': {'piqa': {'acc': 0.7187159956474428, 'acc_stderr': 0.010490509832327423, 'acc_norm': 0.7241566920565833, 'acc_norm_stderr': 0.010427805502729119}, 'boolq': {'acc': 0.5782874617737003, 'acc_stderr': 0.008637194202160971}, 'arc_challenge': {'acc': 0.23293515358361774, 'acc_stderr': 0.012352507042617398, 'acc_norm': 0.295221843003413, 'acc_norm_stderr': 0.013329750293382318}, 'arc_easy': {'acc': 0.5702861952861953, 'acc_stderr': 0.010157908005763676, 'acc_norm': 0.5096801346801347, 'acc_norm_stderr': 0.010257860554461127}, 'lambada_openai': {'ppl': 6.646152117455575, 'ppl_stderr': 0.17185073174126536, 'acc': 0.5800504560450224, 'acc_stderr': 0.006876121089945559}, 'openbookqa': {'acc': 0.234, 'acc_stderr': 0.018952741564893676, 'acc_norm': 0.33, 'acc_norm_stderr': 0.021049612166134806}}, 'versions': {'piqa': 0, 'boolq': 1, 'arc_challenge': 0, 'arc_easy': 0, 'lambada_openai': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f1bcb9c1d20>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-10 20:16:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 14.818000793457031, 'ptb': 17.29753875732422, 'c4': 15.101818084716797, 'results': {'arc_challenge': {'acc': 0.2440273037542662, 'acc_stderr': 0.012551447627856257, 'acc_norm': 0.2909556313993174, 'acc_norm_stderr': 0.013273077865907581}, 'piqa': {'acc': 0.7127312295973884, 'acc_stderr': 0.010557291761528635, 'acc_norm': 0.7116430903155604, 'acc_norm_stderr': 0.010569190399220657}, 'lambada_openai': {'ppl': 6.3785487042754445, 'ppl_stderr': 0.1678030170049463, 'acc': 0.5911119736076073, 'acc_stderr': 0.006849346665262439}, 'boolq': {'acc': 0.5691131498470948, 'acc_stderr': 0.008661108320775369}, 'openbookqa': {'acc': 0.228, 'acc_stderr': 0.018781306529363197, 'acc_norm': 0.326, 'acc_norm_stderr': 0.020984009562393567}, 'arc_easy': {'acc': 0.5686026936026936, 'acc_stderr': 0.01016275284774752, 'acc_norm': 0.5016835016835017, 'acc_norm_stderr': 0.010259725364582762}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'lambada_openai': 0, 'boolq': 1, 'openbookqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f895d3c1b40>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-10 20:50:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=1, R3_clusters=1, R4_clusters=32, R5_clusters=128, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.216239929199219, 'ptb': 17.767019271850586, 'c4': 15.466465950012207, 'results': {'lambada_openai': {'ppl': 7.3522464401678915, 'ppl_stderr': 0.19330569949974225, 'acc': 0.5612264700174655, 'acc_stderr': 0.006913553944132543}, 'openbookqa': {'acc': 0.222, 'acc_stderr': 0.01860441475825008, 'acc_norm': 0.33, 'acc_norm_stderr': 0.021049612166134796}, 'piqa': {'acc': 0.7116430903155604, 'acc_stderr': 0.010569190399220645, 'acc_norm': 0.7116430903155604, 'acc_norm_stderr': 0.010569190399220657}, 'arc_easy': {'acc': 0.5660774410774411, 'acc_stderr': 0.01016979577046211, 'acc_norm': 0.5050505050505051, 'acc_norm_stderr': 0.010259260102565887}, 'arc_challenge': {'acc': 0.22866894197952217, 'acc_stderr': 0.012272853582540806, 'acc_norm': 0.28924914675767915, 'acc_norm_stderr': 0.013250012579393443}, 'boolq': {'acc': 0.5663608562691131, 'acc_stderr': 0.008667690464344678}}, 'versions': {'lambada_openai': 0, 'openbookqa': 0, 'piqa': 0, 'arc_easy': 0, 'arc_challenge': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f093ef808b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-10 21:07:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.820634841918945, 'ptb': 21.670564651489258, 'c4': 18.20591926574707, 'results': {'piqa': {'acc': 0.6893362350380848, 'acc_stderr': 0.010797078933727671, 'acc_norm': 0.6958650707290533, 'acc_norm_stderr': 0.0107334933357213}, 'arc_easy': {'acc': 0.5248316498316499, 'acc_stderr': 0.010247123122159287, 'acc_norm': 0.4654882154882155, 'acc_norm_stderr': 0.0102353142389694}, 'openbookqa': {'acc': 0.214, 'acc_stderr': 0.018359797502387008, 'acc_norm': 0.314, 'acc_norm_stderr': 0.020776701920308997}, 'arc_challenge': {'acc': 0.23122866894197952, 'acc_stderr': 0.012320858834772274, 'acc_norm': 0.26621160409556316, 'acc_norm_stderr': 0.012915774781523217}, 'lambada_openai': {'ppl': 10.346971638919632, 'ppl_stderr': 0.2995522082942579, 'acc': 0.4851542790607413, 'acc_stderr': 0.006962906440875394}, 'boolq': {'acc': 0.5559633027522936, 'acc_stderr': 0.008690105214920795}}, 'versions': {'piqa': 0, 'arc_easy': 0, 'openbookqa': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f0796d9c850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-10 21:38:12 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.52620792388916, 'ptb': 18.292856216430664, 'c4': 15.785297393798828, 'results': {'piqa': {'acc': 0.7116430903155604, 'acc_stderr': 0.010569190399220649, 'acc_norm': 0.7072905331882481, 'acc_norm_stderr': 0.010616044462393094}, 'openbookqa': {'acc': 0.246, 'acc_stderr': 0.01927981905635255, 'acc_norm': 0.34, 'acc_norm_stderr': 0.021206117013673066}, 'arc_easy': {'acc': 0.5686026936026936, 'acc_stderr': 0.01016275284774752, 'acc_norm': 0.4957912457912458, 'acc_norm_stderr': 0.010259420038764091}, 'lambada_openai': {'ppl': 7.104031178023904, 'ppl_stderr': 0.1896710815454885, 'acc': 0.5635552105569571, 'acc_stderr': 0.006909473636524467}, 'arc_challenge': {'acc': 0.23890784982935154, 'acc_stderr': 0.01246107137631662, 'acc_norm': 0.29266211604095566, 'acc_norm_stderr': 0.013295916103619411}, 'boolq': {'acc': 0.5938837920489297, 'acc_stderr': 0.00858951094378741}}, 'versions': {'piqa': 0, 'openbookqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7fa589940850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-10 22:44:10 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.641508102416992, 'ptb': 21.53181266784668, 'c4': 17.83884048461914, 'results': {'openbookqa': {'acc': 0.236, 'acc_stderr': 0.019008699622084718, 'acc_norm': 0.316, 'acc_norm_stderr': 0.02081235951585586}, 'boolq': {'acc': 0.5678899082568807, 'acc_stderr': 0.008664067354619371}, 'piqa': {'acc': 0.6926006528835691, 'acc_stderr': 0.010765602506939064, 'acc_norm': 0.6996735582154516, 'acc_norm_stderr': 0.010695225308183145}, 'arc_challenge': {'acc': 0.2295221843003413, 'acc_stderr': 0.012288926760890785, 'acc_norm': 0.2773037542662116, 'acc_norm_stderr': 0.013082095839059376}, 'lambada_openai': {'ppl': 9.264832601216769, 'ppl_stderr': 0.2672755084139099, 'acc': 0.5226081894042306, 'acc_stderr': 0.006958852970187403}, 'arc_easy': {'acc': 0.5404040404040404, 'acc_stderr': 0.010226230740889023, 'acc_norm': 0.4823232323232323, 'acc_norm_stderr': 0.010253369805698975}}, 'versions': {'openbookqa': 0, 'boolq': 1, 'piqa': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7ff27f7f8880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-11 02:02:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.501340866088867, 'ptb': 21.501924514770508, 'c4': 17.74193000793457, 'results': {'arc_challenge': {'acc': 0.2354948805460751, 'acc_stderr': 0.012399451855004748, 'acc_norm': 0.27986348122866894, 'acc_norm_stderr': 0.013119040897725925}, 'boolq': {'acc': 0.5746177370030581, 'acc_stderr': 0.00864712510067608}, 'lambada_openai': {'ppl': 9.44113252224216, 'ppl_stderr': 0.27235801185784486, 'acc': 0.5152338443625073, 'acc_stderr': 0.006962743717451537}, 'arc_easy': {'acc': 0.5429292929292929, 'acc_stderr': 0.010221897564256054, 'acc_norm': 0.47685185185185186, 'acc_norm_stderr': 0.010248782484554474}, 'piqa': {'acc': 0.6866158868335147, 'acc_stderr': 0.010822829929195503, 'acc_norm': 0.6964091403699674, 'acc_norm_stderr': 0.01072807989307637}, 'openbookqa': {'acc': 0.204, 'acc_stderr': 0.018039369104138645, 'acc_norm': 0.32, 'acc_norm_stderr': 0.020882340488761808}}, 'versions': {'arc_challenge': 0, 'boolq': 1, 'lambada_openai': 0, 'arc_easy': 0, 'piqa': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f1f710708b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-11 05:18:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.419958114624023, 'ptb': 21.28095817565918, 'c4': 17.69114112854004, 'results': {'piqa': {'acc': 0.6936887921653971, 'acc_stderr': 0.010754970032367321, 'acc_norm': 0.6969532100108814, 'acc_norm_stderr': 0.01072264868953151}, 'boolq': {'acc': 0.5706422018348624, 'acc_stderr': 0.008657333755353677}, 'lambada_openai': {'ppl': 9.150943522290197, 'ppl_stderr': 0.2628665630069485, 'acc': 0.523578497962352, 'acc_stderr': 0.0069582279375865405}, 'openbookqa': {'acc': 0.206, 'acc_stderr': 0.01810479403733355, 'acc_norm': 0.31, 'acc_norm_stderr': 0.020704041021724795}, 'arc_easy': {'acc': 0.5311447811447811, 'acc_stderr': 0.010239860250021738, 'acc_norm': 0.47264309764309764, 'acc_norm_stderr': 0.01024441516439054}, 'arc_challenge': {'acc': 0.2354948805460751, 'acc_stderr': 0.012399451855004753, 'acc_norm': 0.2713310580204778, 'acc_norm_stderr': 0.012993807727545789}}, 'versions': {'piqa': 0, 'boolq': 1, 'lambada_openai': 0, 'openbookqa': 0, 'arc_easy': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fbd03750850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-11 09:02:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.334585189819336, 'ptb': 21.046720504760742, 'c4': 17.665313720703125, 'results': {'boolq': {'acc': 0.5691131498470948, 'acc_stderr': 0.008661108320775376}, 'arc_easy': {'acc': 0.5441919191919192, 'acc_stderr': 0.010219631763437853, 'acc_norm': 0.47895622895622897, 'acc_norm_stderr': 0.010250692602022583}, 'piqa': {'acc': 0.6844396082698585, 'acc_stderr': 0.010843119201758946, 'acc_norm': 0.6931447225244831, 'acc_norm_stderr': 0.010760295070580376}, 'openbookqa': {'acc': 0.202, 'acc_stderr': 0.01797326003128824, 'acc_norm': 0.306, 'acc_norm_stderr': 0.0206295699983454}, 'lambada_openai': {'ppl': 9.08781656759617, 'ppl_stderr': 0.2593260713601457, 'acc': 0.5220260042693576, 'acc_stderr': 0.006959215358336663}, 'arc_challenge': {'acc': 0.24232081911262798, 'acc_stderr': 0.012521593295800116, 'acc_norm': 0.28242320819112626, 'acc_norm_stderr': 0.013155456884097222}}, 'versions': {'boolq': 1, 'arc_easy': 0, 'piqa': 0, 'openbookqa': 0, 'lambada_openai': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f3d0cce8880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-11 13:08:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.391310691833496, 'ptb': 17.740047454833984, 'c4': 15.470685005187988, 'results': {'boolq': {'acc': 0.5629969418960244, 'acc_stderr': 0.008675365793227084}, 'arc_easy': {'acc': 0.5673400673400674, 'acc_stderr': 0.010166307932642867, 'acc_norm': 0.49537037037037035, 'acc_norm_stderr': 0.010259343705889736}, 'openbookqa': {'acc': 0.22, 'acc_stderr': 0.01854421137582033, 'acc_norm': 0.326, 'acc_norm_stderr': 0.020984009562393564}, 'lambada_openai': {'ppl': 6.824190675448657, 'ppl_stderr': 0.1822872128781676, 'acc': 0.5833495051426354, 'acc_stderr': 0.006868508510588675}, 'arc_challenge': {'acc': 0.23208191126279865, 'acc_stderr': 0.012336718284948854, 'acc_norm': 0.28668941979522183, 'acc_norm_stderr': 0.013214986329274762}, 'piqa': {'acc': 0.7149075081610446, 'acc_stderr': 0.010533270588738937, 'acc_norm': 0.720348204570185, 'acc_norm_stderr': 0.010471899530306557}}, 'versions': {'boolq': 1, 'arc_easy': 0, 'openbookqa': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f447d214910>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-11 15:57:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.391093254089355, 'ptb': 17.727731704711914, 'c4': 15.474138259887695, 'results': {'arc_easy': {'acc': 0.5698653198653199, 'acc_stderr': 0.010159130445178497, 'acc_norm': 0.5008417508417509, 'acc_norm_stderr': 0.010259768981815232}, 'lambada_openai': {'ppl': 6.789817125166059, 'ppl_stderr': 0.18049917387685727, 'acc': 0.5763632835241607, 'acc_stderr': 0.006884256176207532}, 'piqa': {'acc': 0.7089227421109902, 'acc_stderr': 0.01059861249094259, 'acc_norm': 0.7121871599564744, 'acc_norm_stderr': 0.010563250383059188}, 'openbookqa': {'acc': 0.218, 'acc_stderr': 0.018483378223178856, 'acc_norm': 0.322, 'acc_norm_stderr': 0.02091666833001988}, 'arc_challenge': {'acc': 0.24488054607508533, 'acc_stderr': 0.012566273985131358, 'acc_norm': 0.2858361774744027, 'acc_norm_stderr': 0.013203196088537369}, 'boolq': {'acc': 0.5764525993883792, 'acc_stderr': 0.008642220663071512}}, 'versions': {'arc_easy': 0, 'lambada_openai': 0, 'piqa': 0, 'openbookqa': 0, 'arc_challenge': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f784a948940>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-11 18:50:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.381114959716797, 'ptb': 17.776273727416992, 'c4': 15.470714569091797, 'results': {'lambada_openai': {'ppl': 6.544033249099121, 'ppl_stderr': 0.17403792478316515, 'acc': 0.587036677663497, 'acc_stderr': 0.006859625903442966}, 'openbookqa': {'acc': 0.224, 'acc_stderr': 0.018663994464710787, 'acc_norm': 0.336, 'acc_norm_stderr': 0.021144791425048853}, 'boolq': {'acc': 0.5740061162079511, 'acc_stderr': 0.008648732832949143}, 'arc_challenge': {'acc': 0.23976109215017063, 'acc_stderr': 0.012476304127453947, 'acc_norm': 0.28498293515358364, 'acc_norm_stderr': 0.01319134817983879}, 'piqa': {'acc': 0.7100108813928183, 'acc_stderr': 0.010586899128169328, 'acc_norm': 0.7149075081610446, 'acc_norm_stderr': 0.010533270588738944}, 'arc_easy': {'acc': 0.5757575757575758, 'acc_stderr': 0.010141333654958548, 'acc_norm': 0.49663299663299665, 'acc_norm_stderr': 0.010259550893798932}}, 'versions': {'lambada_openai': 0, 'openbookqa': 0, 'boolq': 1, 'arc_challenge': 0, 'piqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fdc68394940>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-11 21:44:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.425596237182617, 'ptb': 17.763935089111328, 'c4': 15.46513843536377, 'results': {'openbookqa': {'acc': 0.224, 'acc_stderr': 0.018663994464710794, 'acc_norm': 0.33, 'acc_norm_stderr': 0.021049612166134796}, 'arc_challenge': {'acc': 0.24744027303754265, 'acc_stderr': 0.012610352663292673, 'acc_norm': 0.28071672354948807, 'acc_norm_stderr': 0.013131238126975583}, 'lambada_openai': {'ppl': 6.4199015338843015, 'ppl_stderr': 0.170075207176652, 'acc': 0.5930525907238502, 'acc_stderr': 0.006844280824156637}, 'piqa': {'acc': 0.7110990206746464, 'acc_stderr': 0.010575111841364905, 'acc_norm': 0.7138193688792165, 'acc_norm_stderr': 0.010545318576106653}, 'arc_easy': {'acc': 0.5728114478114478, 'acc_stderr': 0.010150415974210873, 'acc_norm': 0.49663299663299665, 'acc_norm_stderr': 0.010259550893798932}, 'boolq': {'acc': 0.5847094801223242, 'acc_stderr': 0.008618637526341674}}, 'versions': {'openbookqa': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'piqa': 0, 'arc_easy': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f7b7224c8b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-13 10:11:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.36069107055664, 'ptb': 21.197067260742188, 'c4': 17.72870445251465, 'results': {'lambada_openai': {'ppl': 9.357023285882722, 'ppl_stderr': 0.2674525431096062, 'acc': 0.5152338443625073, 'acc_stderr': 0.006962743717451543}, 'piqa': {'acc': 0.6877040261153428, 'acc_stderr': 0.010812581599154424, 'acc_norm': 0.6936887921653971, 'acc_norm_stderr': 0.010754970032367321}, 'openbookqa': {'acc': 0.22, 'acc_stderr': 0.01854421137582033, 'acc_norm': 0.32, 'acc_norm_stderr': 0.020882340488761808}, 'arc_challenge': {'acc': 0.21843003412969283, 'acc_stderr': 0.01207429160570098, 'acc_norm': 0.2764505119453925, 'acc_norm_stderr': 0.013069662474252425}, 'boolq': {'acc': 0.591743119266055, 'acc_stderr': 0.008596583869583195}, 'arc_easy': {'acc': 0.5433501683501684, 'acc_stderr': 0.010221149650118186, 'acc_norm': 0.4819023569023569, 'acc_norm_stderr': 0.01025306065347918}}, 'versions': {'lambada_openai': 0, 'piqa': 0, 'openbookqa': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7406d48970>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-13 11:20:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.251514434814453, 'ptb': 21.045808792114258, 'c4': 17.58553695678711, 'results': {'arc_challenge': {'acc': 0.24488054607508533, 'acc_stderr': 0.012566273985131358, 'acc_norm': 0.2773037542662116, 'acc_norm_stderr': 0.013082095839059374}, 'arc_easy': {'acc': 0.5408249158249159, 'acc_stderr': 0.010225526906982599, 'acc_norm': 0.48274410774410775, 'acc_norm_stderr': 0.010253671674754631}, 'lambada_openai': {'ppl': 9.149808047083432, 'ppl_stderr': 0.2599844849414911, 'acc': 0.5181447700368718, 'acc_stderr': 0.006961389291072819}, 'boolq': {'acc': 0.5547400611620795, 'acc_stderr': 0.008692488322023064}, 'openbookqa': {'acc': 0.216, 'acc_stderr': 0.01842190906141194, 'acc_norm': 0.298, 'acc_norm_stderr': 0.02047511809298897}, 'piqa': {'acc': 0.6871599564744287, 'acc_stderr': 0.010817714425701104, 'acc_norm': 0.7029379760609358, 'acc_norm_stderr': 0.010661725404814786}}, 'versions': {'arc_challenge': 0, 'arc_easy': 0, 'lambada_openai': 0, 'boolq': 1, 'openbookqa': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f546f5d4790>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-13 12:26:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.199392318725586, 'ptb': 20.796104431152344, 'c4': 17.622507095336914, 'results': {'lambada_openai': {'ppl': 9.12908670043369, 'ppl_stderr': 0.2635414295954251, 'acc': 0.524160683097225, 'acc_stderr': 0.006957840284118757}, 'arc_easy': {'acc': 0.5349326599326599, 'acc_stderr': 0.010234713052723665, 'acc_norm': 0.484006734006734, 'acc_norm_stderr': 0.010254533589288172}, 'boolq': {'acc': 0.5801223241590214, 'acc_stderr': 0.008632045504781746}, 'arc_challenge': {'acc': 0.23208191126279865, 'acc_stderr': 0.012336718284948854, 'acc_norm': 0.25853242320819114, 'acc_norm_stderr': 0.012794553754288679}, 'piqa': {'acc': 0.6844396082698585, 'acc_stderr': 0.010843119201758948, 'acc_norm': 0.6855277475516867, 'acc_norm_stderr': 0.010833009065106562}, 'openbookqa': {'acc': 0.202, 'acc_stderr': 0.017973260031288237, 'acc_norm': 0.314, 'acc_norm_stderr': 0.020776701920308997}}, 'versions': {'lambada_openai': 0, 'arc_easy': 0, 'boolq': 1, 'arc_challenge': 0, 'piqa': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7cb25c88e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-13 14:10:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.08612632751465, 'ptb': 20.790691375732422, 'c4': 17.56117057800293, 'results': {'arc_challenge': {'acc': 0.23037542662116042, 'acc_stderr': 0.01230492841874761, 'acc_norm': 0.2696245733788396, 'acc_norm_stderr': 0.012968040686869159}, 'piqa': {'acc': 0.6849836779107725, 'acc_stderr': 0.010838072746240653, 'acc_norm': 0.6849836779107725, 'acc_norm_stderr': 0.010838072746240652}, 'lambada_openai': {'ppl': 9.064346344939624, 'ppl_stderr': 0.26036387192054206, 'acc': 0.5270716087715893, 'acc_stderr': 0.00695575982335559}, 'boolq': {'acc': 0.5681957186544343, 'acc_stderr': 0.008663332644225127}, 'arc_easy': {'acc': 0.5382996632996633, 'acc_stderr': 0.01022963982061052, 'acc_norm': 0.4734848484848485, 'acc_norm_stderr': 0.010245347015573704}, 'openbookqa': {'acc': 0.216, 'acc_stderr': 0.01842190906141194, 'acc_norm': 0.308, 'acc_norm_stderr': 0.020667032987466104}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'lambada_openai': 0, 'boolq': 1, 'arc_easy': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f3ad982c7c0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-13 15:04:09 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.428284645080566, 'ptb': 17.805618286132812, 'c4': 15.480365753173828, 'results': {'arc_easy': {'acc': 0.5593434343434344, 'acc_stderr': 0.010187264635711988, 'acc_norm': 0.49957912457912457, 'acc_norm_stderr': 0.010259779886094427}, 'openbookqa': {'acc': 0.216, 'acc_stderr': 0.01842190906141194, 'acc_norm': 0.32, 'acc_norm_stderr': 0.02088234048876181}, 'piqa': {'acc': 0.7110990206746464, 'acc_stderr': 0.010575111841364901, 'acc_norm': 0.7138193688792165, 'acc_norm_stderr': 0.010545318576106648}, 'lambada_openai': {'ppl': 6.654906004811484, 'ppl_stderr': 0.17781769075035506, 'acc': 0.5841257519891325, 'acc_stderr': 0.006866671378867615}, 'boolq': {'acc': 0.5672782874617737, 'acc_stderr': 0.008665526684416246}, 'arc_challenge': {'acc': 0.23122866894197952, 'acc_stderr': 0.012320858834772287, 'acc_norm': 0.28498293515358364, 'acc_norm_stderr': 0.013191348179838792}}, 'versions': {'arc_easy': 0, 'openbookqa': 0, 'piqa': 0, 'lambada_openai': 0, 'boolq': 1, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f044712c850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-13 15:58:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.40140438079834, 'ptb': 17.764707565307617, 'c4': 15.474373817443848, 'results': {'boolq': {'acc': 0.6058103975535168, 'acc_stderr': 0.008546995661233635}, 'lambada_openai': {'ppl': 6.82397789579258, 'ppl_stderr': 0.1818251745600356, 'acc': 0.5800504560450224, 'acc_stderr': 0.006876121089945559}, 'openbookqa': {'acc': 0.218, 'acc_stderr': 0.018483378223178856, 'acc_norm': 0.336, 'acc_norm_stderr': 0.02114479142504885}, 'arc_challenge': {'acc': 0.23208191126279865, 'acc_stderr': 0.012336718284948854, 'acc_norm': 0.2841296928327645, 'acc_norm_stderr': 0.013179442447653884}, 'piqa': {'acc': 0.7094668117519043, 'acc_stderr': 0.010592765034696536, 'acc_norm': 0.705114254624592, 'acc_norm_stderr': 0.010639030620156984}, 'arc_easy': {'acc': 0.5627104377104377, 'acc_stderr': 0.0101787684293216, 'acc_norm': 0.4962121212121212, 'acc_norm_stderr': 0.010259489101351847}}, 'versions': {'boolq': 1, 'lambada_openai': 0, 'openbookqa': 0, 'arc_challenge': 0, 'piqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f1b58aa08b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-13 16:51:59 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.384442329406738, 'ptb': 17.7362003326416, 'c4': 15.462985038757324, 'results': {'arc_challenge': {'acc': 0.24061433447098976, 'acc_stderr': 0.012491468532390576, 'acc_norm': 0.2815699658703072, 'acc_norm_stderr': 0.013143376735009015}, 'openbookqa': {'acc': 0.228, 'acc_stderr': 0.018781306529363197, 'acc_norm': 0.318, 'acc_norm_stderr': 0.020847571620814007}, 'piqa': {'acc': 0.7154515778019587, 'acc_stderr': 0.010527218464130616, 'acc_norm': 0.7110990206746464, 'acc_norm_stderr': 0.010575111841364912}, 'arc_easy': {'acc': 0.571969696969697, 'acc_stderr': 0.010152943316426249, 'acc_norm': 0.5, 'acc_norm_stderr': 0.01025978352085154}, 'boolq': {'acc': 0.5691131498470948, 'acc_stderr': 0.00866110832077537}, 'lambada_openai': {'ppl': 6.620915595112497, 'ppl_stderr': 0.17624089243994984, 'acc': 0.5827673200077624, 'acc_stderr': 0.006869874864639986}}, 'versions': {'arc_challenge': 0, 'openbookqa': 0, 'piqa': 0, 'arc_easy': 0, 'boolq': 1, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fbacd114910>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-13 17:46:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.411076545715332, 'ptb': 17.7362003326416, 'c4': 15.470301628112793, 'results': {'openbookqa': {'acc': 0.23, 'acc_stderr': 0.018839050391123133, 'acc_norm': 0.326, 'acc_norm_stderr': 0.020984009562393567}, 'piqa': {'acc': 0.7170837867247007, 'acc_stderr': 0.010508949177489683, 'acc_norm': 0.7127312295973884, 'acc_norm_stderr': 0.010557291761528637}, 'arc_easy': {'acc': 0.5677609427609428, 'acc_stderr': 0.010165130379698739, 'acc_norm': 0.4978956228956229, 'acc_norm_stderr': 0.010259692651537047}, 'arc_challenge': {'acc': 0.24658703071672355, 'acc_stderr': 0.012595726268790115, 'acc_norm': 0.28242320819112626, 'acc_norm_stderr': 0.013155456884097224}, 'lambada_openai': {'ppl': 6.537510026337449, 'ppl_stderr': 0.1736511927006059, 'acc': 0.592276343877353, 'acc_stderr': 0.006846320422742705}, 'boolq': {'acc': 0.6058103975535168, 'acc_stderr': 0.008546995661233635}}, 'versions': {'openbookqa': 0, 'piqa': 0, 'arc_easy': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f4a867988b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-13 19:14:49 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.378376007080078, 'ptb': 21.194307327270508, 'c4': 17.75482749938965, 'results': {'lambada_openai': {'ppl': 9.358156131336393, 'ppl_stderr': 0.2700864759416662, 'acc': 0.525519115078595, 'acc_stderr': 0.006956898900155674}, 'arc_easy': {'acc': 0.5294612794612794, 'acc_stderr': 0.01024195772840969, 'acc_norm': 0.476010101010101, 'acc_norm_stderr': 0.010247967392742693}, 'arc_challenge': {'acc': 0.2380546075085324, 'acc_stderr': 0.012445770028026206, 'acc_norm': 0.2738907849829352, 'acc_norm_stderr': 0.013032004972989501}, 'boolq': {'acc': 0.5611620795107034, 'acc_stderr': 0.00867938137585734}, 'piqa': {'acc': 0.6947769314472253, 'acc_stderr': 0.01074426704560648, 'acc_norm': 0.6855277475516867, 'acc_norm_stderr': 0.010833009065106565}, 'openbookqa': {'acc': 0.216, 'acc_stderr': 0.018421909061411938, 'acc_norm': 0.31, 'acc_norm_stderr': 0.020704041021724795}}, 'versions': {'lambada_openai': 0, 'arc_easy': 0, 'arc_challenge': 0, 'boolq': 1, 'piqa': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f46e2a08940>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-13 20:07:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.26539421081543, 'ptb': 21.049461364746094, 'c4': 17.681156158447266, 'results': {'openbookqa': {'acc': 0.194, 'acc_stderr': 0.017701827855304633, 'acc_norm': 0.31, 'acc_norm_stderr': 0.020704041021724795}, 'piqa': {'acc': 0.6969532100108814, 'acc_stderr': 0.010722648689531518, 'acc_norm': 0.705114254624592, 'acc_norm_stderr': 0.01063903062015699}, 'arc_easy': {'acc': 0.5462962962962963, 'acc_stderr': 0.010215708295494117, 'acc_norm': 0.48358585858585856, 'acc_norm_stderr': 0.0102542535659293}, 'arc_challenge': {'acc': 0.2363481228668942, 'acc_stderr': 0.01241496052430183, 'acc_norm': 0.27303754266211605, 'acc_norm_stderr': 0.013019332762635734}, 'lambada_openai': {'ppl': 9.30338995948877, 'ppl_stderr': 0.2664857970570142, 'acc': 0.5138754123811372, 'acc_stderr': 0.006963294862063176}, 'boolq': {'acc': 0.5418960244648318, 'acc_stderr': 0.008714300914033354}}, 'versions': {'openbookqa': 0, 'piqa': 0, 'arc_easy': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f39feaec8e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-14 10:49:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.408066749572754, 'ptb': 17.754684448242188, 'c4': 15.507731437683105, 'results': {'piqa': {'acc': 0.7105549510337323, 'acc_stderr': 0.010581014740675604, 'acc_norm': 0.7078346028291621, 'acc_norm_stderr': 0.010610252174513671}, 'openbookqa': {'acc': 0.22, 'acc_stderr': 0.01854421137582033, 'acc_norm': 0.32, 'acc_norm_stderr': 0.02088234048876181}, 'arc_easy': {'acc': 0.5656565656565656, 'acc_stderr': 0.010170943451269418, 'acc_norm': 0.4936868686868687, 'acc_norm_stderr': 0.01025896566804443}, 'boolq': {'acc': 0.5844036697247706, 'acc_stderr': 0.008619555273337565}, 'lambada_openai': {'ppl': 6.818608409299553, 'ppl_stderr': 0.1824406024183922, 'acc': 0.5796623326217737, 'acc_stderr': 0.0068769959378442444}, 'arc_challenge': {'acc': 0.2363481228668942, 'acc_stderr': 0.012414960524301834, 'acc_norm': 0.28071672354948807, 'acc_norm_stderr': 0.013131238126975584}}, 'versions': {'piqa': 0, 'openbookqa': 0, 'arc_easy': 0, 'boolq': 1, 'lambada_openai': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fe9efd7c880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-14 11:43:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.385406494140625, 'ptb': 17.746980667114258, 'c4': 15.477001190185547, 'results': {'arc_easy': {'acc': 0.5643939393939394, 'acc_stderr': 0.010174341733665226, 'acc_norm': 0.49242424242424243, 'acc_norm_stderr': 0.010258605792153326}, 'piqa': {'acc': 0.7149075081610446, 'acc_stderr': 0.010533270588738935, 'acc_norm': 0.7110990206746464, 'acc_norm_stderr': 0.010575111841364912}, 'boolq': {'acc': 0.5819571865443425, 'acc_stderr': 0.008626774352070743}, 'openbookqa': {'acc': 0.216, 'acc_stderr': 0.01842190906141194, 'acc_norm': 0.326, 'acc_norm_stderr': 0.02098400956239357}, 'lambada_openai': {'ppl': 6.733218684863275, 'ppl_stderr': 0.17972196343937155, 'acc': 0.5876188627983698, 'acc_stderr': 0.0068581871620307325}, 'arc_challenge': {'acc': 0.2440273037542662, 'acc_stderr': 0.012551447627856255, 'acc_norm': 0.28498293515358364, 'acc_norm_stderr': 0.013191348179838792}}, 'versions': {'arc_easy': 0, 'piqa': 0, 'boolq': 1, 'openbookqa': 0, 'lambada_openai': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f25ec028940>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-14 12:38:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.301711082458496, 'ptb': 17.74081802368164, 'c4': 15.477148056030273, 'results': {'boolq': {'acc': 0.5853211009174312, 'acc_stderr': 0.008616791778981302}, 'piqa': {'acc': 0.7105549510337323, 'acc_stderr': 0.010581014740675607, 'acc_norm': 0.720892274211099, 'acc_norm_stderr': 0.010465657948498233}, 'lambada_openai': {'ppl': 6.586723631637975, 'ppl_stderr': 0.17500939268721666, 'acc': 0.5897535416262372, 'acc_stderr': 0.006852827058720169}, 'openbookqa': {'acc': 0.228, 'acc_stderr': 0.018781306529363197, 'acc_norm': 0.326, 'acc_norm_stderr': 0.020984009562393567}, 'arc_easy': {'acc': 0.5728114478114478, 'acc_stderr': 0.010150415974210873, 'acc_norm': 0.5012626262626263, 'acc_norm_stderr': 0.010259750807991064}, 'arc_challenge': {'acc': 0.23890784982935154, 'acc_stderr': 0.012461071376316623, 'acc_norm': 0.2858361774744027, 'acc_norm_stderr': 0.013203196088537367}}, 'versions': {'boolq': 1, 'piqa': 0, 'lambada_openai': 0, 'openbookqa': 0, 'arc_easy': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fd9ee6208e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-14 13:29:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.319757461547852, 'ptb': 17.728500366210938, 'c4': 15.489965438842773, 'results': {'boolq': {'acc': 0.6036697247706422, 'acc_stderr': 0.008555016706540432}, 'arc_challenge': {'acc': 0.24232081911262798, 'acc_stderr': 0.012521593295800116, 'acc_norm': 0.2841296928327645, 'acc_norm_stderr': 0.013179442447653886}, 'openbookqa': {'acc': 0.222, 'acc_stderr': 0.01860441475825008, 'acc_norm': 0.322, 'acc_norm_stderr': 0.02091666833001988}, 'arc_easy': {'acc': 0.5702861952861953, 'acc_stderr': 0.010157908005763678, 'acc_norm': 0.49915824915824913, 'acc_norm_stderr': 0.010259768981815241}, 'lambada_openai': {'ppl': 6.545094308326996, 'ppl_stderr': 0.1747186463761061, 'acc': 0.5951872695517174, 'acc_stderr': 0.006838580607651544}, 'piqa': {'acc': 0.7116430903155604, 'acc_stderr': 0.010569190399220644, 'acc_norm': 0.7127312295973884, 'acc_norm_stderr': 0.010557291761528637}}, 'versions': {'boolq': 1, 'arc_challenge': 0, 'openbookqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f72043248b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-15 09:31:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.305957794189453, 'ptb': 20.817777633666992, 'c4': 17.587718963623047, 'results': {'boolq': {'acc': 0.5737003058103975, 'acc_stderr': 0.008649531625805673}, 'arc_challenge': {'acc': 0.24744027303754265, 'acc_stderr': 0.01261035266329267, 'acc_norm': 0.27303754266211605, 'acc_norm_stderr': 0.013019332762635732}, 'piqa': {'acc': 0.6898803046789989, 'acc_stderr': 0.010791876566843056, 'acc_norm': 0.6920565832426551, 'acc_norm_stderr': 0.010770892367463676}, 'arc_easy': {'acc': 0.5382996632996633, 'acc_stderr': 0.010229639820610517, 'acc_norm': 0.4831649831649832, 'acc_norm_stderr': 0.010253966261288897}, 'openbookqa': {'acc': 0.208, 'acc_stderr': 0.018169542221229892, 'acc_norm': 0.326, 'acc_norm_stderr': 0.020984009562393567}, 'lambada_openai': {'ppl': 8.980296630144084, 'ppl_stderr': 0.25499172344384663, 'acc': 0.5288181641762081, 'acc_stderr': 0.006954397730205831}}, 'versions': {'boolq': 1, 'arc_challenge': 0, 'piqa': 0, 'arc_easy': 0, 'openbookqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7ff933df8880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-15 10:18:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.08360481262207, 'ptb': 20.752824783325195, 'c4': 17.548112869262695, 'results': {'openbookqa': {'acc': 0.218, 'acc_stderr': 0.018483378223178856, 'acc_norm': 0.322, 'acc_norm_stderr': 0.02091666833001988}, 'arc_challenge': {'acc': 0.2431740614334471, 'acc_stderr': 0.012536554144587094, 'acc_norm': 0.27303754266211605, 'acc_norm_stderr': 0.013019332762635737}, 'piqa': {'acc': 0.6838955386289445, 'acc_stderr': 0.010848148455700453, 'acc_norm': 0.6893362350380848, 'acc_norm_stderr': 0.010797078933727673}, 'boolq': {'acc': 0.5535168195718655, 'acc_stderr': 0.008694818132096653}, 'lambada_openai': {'ppl': 9.00589686419078, 'ppl_stderr': 0.25864247256602, 'acc': 0.5228022511158549, 'acc_stderr': 0.006958730069051655}, 'arc_easy': {'acc': 0.5315656565656566, 'acc_stderr': 0.010239317603199512, 'acc_norm': 0.4751683501683502, 'acc_norm_stderr': 0.010247123122159266}}, 'versions': {'openbookqa': 0, 'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'lambada_openai': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f77cd8308e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks piqa 2023-09-19 10:43:24 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=0, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='piqa', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'piqa': {'acc': 0.7029379760609358, 'acc_stderr': 0.010661725404814786, 'acc_norm': 0.6996735582154516, 'acc_norm_stderr': 0.010695225308183143}}, 'versions': {'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f72cd3e1520>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-19 10:49:42 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=0, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 7.3871013505758745, 'ppl_stderr': 0.19780152578497767, 'acc': 0.5375509411993014, 'acc_stderr': 0.006946304801195765}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7ffd507580>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-19 10:56:54 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=0, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875, 'results': {'lambada_openai': {'ppl': 7.3871013505758745, 'ppl_stderr': 0.19780152578497767, 'acc': 0.5375509411993014, 'acc_stderr': 0.006946304801195765}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f77b8cad610>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 14:24:32 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, w_quantizer='gptq', wbits=4) 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 14:35:22 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 15.390557289123535, 'ptb': 17.746206283569336, 'c4': 15.468353271484375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 14:46:33 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 15.397538185119629, 'ptb': 17.763935089111328, 'c4': 15.528746604919434}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 14:56:15 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=False, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 18.75131607055664, 'ptb': 21.7138729095459, 'c4': 18.02256202697754}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 18:55:08 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 15.97175407409668, 'ptb': 18.330209732055664, 'c4': 15.923341751098633}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 19:04:42 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 19.375041961669922, 'ptb': 22.397314071655273, 'c4': 18.618579864501953}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 256 2023-09-20 20:00:17 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=256, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 19.375041961669922, 'ptb': 22.397314071655273, 'c4': 18.618579864501953}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 512 2023-09-20 20:11:15 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=512, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 16.116456985473633, 'ptb': 18.556745529174805, 'c4': 16.16968536376953}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 128 2023-09-20 20:19:50 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=128, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 15.708348274230957, 'ptb': 18.264293670654297, 'c4': 15.825512886047363}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 32 2023-09-20 20:29:58 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=32, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 15.438727378845215, 'ptb': 18.231821060180664, 'c4': 15.797406196594238}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 16 2023-09-20 20:42:41 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=16, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 15.468157768249512, 'ptb': 18.298412322998047, 'c4': 15.965187072753906}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 8 2023-09-20 21:00:45 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=8, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 15.632923126220703, 'ptb': 18.451534271240234, 'c4': 16.252458572387695}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 512 2023-09-20 21:11:29 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=512, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 19.946475982666016, 'ptb': 23.207788467407227, 'c4': 19.216339111328125}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 128 2023-09-20 21:21:15 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=128, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 19.11301612854004, 'ptb': 21.846216201782227, 'c4': 18.322479248046875}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 32 2023-09-20 21:31:50 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=32, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 18.052093505859375, 'ptb': 20.860288619995117, 'c4': 17.899372100830078}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 16 2023-09-20 21:44:24 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=16, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 17.62973976135254, 'ptb': 20.40804100036621, 'c4': 17.6733341217041}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 8 2023-09-20 22:02:22 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=8, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 17.682573318481445, 'ptb': 20.442611694335938, 'c4': 18.00397491455078}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 512 2023-09-21 13:15:26 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=512, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 14.973127365112305, 'ptb': 17.47942352294922, 'c4': 15.293100357055664}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 256 2023-09-21 13:23:22 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=256, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 15.039803504943848, 'ptb': 17.3245906829834, 'c4': 15.191520690917969}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 128 2023-09-21 13:31:23 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=128, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 14.852252960205078, 'ptb': 17.311059951782227, 'c4': 15.139049530029297}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 32 2023-09-21 13:40:51 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=32, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 14.724854469299316, 'ptb': 17.2181453704834, 'c4': 15.073328971862793}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 16 2023-09-21 13:52:52 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=16, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 14.690587997436523, 'ptb': 17.208431243896484, 'c4': 15.090127944946289}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 8 2023-09-21 14:09:44 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/1.3b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=8, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-1.3b', multigpu=True, net='opt-1.3b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 14.729578971862793, 'ptb': 17.164419174194336, 'c4': 15.093610763549805}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-10-30 09:51:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-10-30 10:03:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-10-30 10:13:59 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': nan, 'ptb': nan, 'c4': nan}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-10-30 10:14:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': nan}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-10-30 10:16:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-10-30 10:20:53 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.78475570678711, 'ptb': 17.3245906829834, 'c4': 14.901328086853027}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-10-30 10:25:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624336242675781, 'ptb': 16.962238311767578, 'c4': 14.721122741699219}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-01 18:53:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624336242675781, 'ptb': 16.962238311767578, 'c4': 14.721122741699219}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-01 18:55:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 17.87666130065918, 'ptb': 23.89776039123535, 'c4': 16.766033172607422}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-01 19:34:25 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 18.3129825592041, 'ptb': 24.731380462646484, 'c4': 17.068334579467773}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-01 19:42:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 18.369659423828125, 'ptb': 24.778656005859375, 'c4': 17.1080322265625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-02 11:00:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.726805686950684, 'ptb': 17.068586349487305, 'c4': 14.786408424377441}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-02 11:53:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.809320449829102, 'ptb': 17.242820739746094, 'c4': 14.875117301940918}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-02 17:33:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.807046890258789, 'ptb': 17.34640884399414, 'c4': 14.94125747680664}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-02 19:04:48 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.845728874206543, 'ptb': 17.317821502685547, 'c4': 14.91625690460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-02 19:39:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.726805686950684, 'ptb': 17.068586349487305, 'c4': 14.786408424377441}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 09:02:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.300642967224121, 'ptb': 18.981969833374023, 'c4': 15.777802467346191}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 09:06:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 16.994609832763672, 'ptb': 18.599483489990234, 'c4': 15.663052558898926}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 09:10:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.64168643951416, 'ptb': 16.97696876525879, 'c4': 14.733537673950195}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 09:15:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.822961807250977, 'ptb': 17.260042190551758, 'c4': 14.89794635772705}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:07:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:07:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:09:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:10:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:12:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:13:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:14:49 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:35:59 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:36:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 128405.1953125}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:45:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:48:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:50:45 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:55:12 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:56:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:57:23 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:59:53 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:05:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:08:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:10:59 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:11:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:14:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:16:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:20:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0876725912094116}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:21:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:22:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624539375305176}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:24:59 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624539375305176, 'ptb': 16.962238311767578, 'c4': 14.72238540649414}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:27:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:28:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0386465787887573}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:32:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0386465787887573}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:32:45 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0386465787887573}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:42:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0386465787887573}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 17:46:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 24.353843688964844}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:23:10 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0386465787887573}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:23:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0386465787887573}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:24:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0386465787887573}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:25:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0386465787887573}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:26:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.046427845954895}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:27:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 24.353843688964844}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:35:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.040619134902954}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:36:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 16.11140251159668}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:53:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': nan}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 19:55:13 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': nan}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 15:58:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624539375305176}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 15:59:23 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 16.11140251159668}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 16:00:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 16.08018684387207}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 16:39:30 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 16.25067901611328}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 16:46:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 2947.9560546875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 17:19:32 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1587.022705078125}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 17:26:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 25.19466781616211}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 17:28:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1111.4498291015625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 17:31:58 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1587.022705078125}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 17:33:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 32.465885162353516}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 17:35:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.65420150756836}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 17:36:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 16.25067901611328}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 17:47:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.773208618164062}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 17:50:12 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.773208618164062, 'ptb': 17.224870681762695, 'c4': 14.895048141479492}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 19:19:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.773208618164062, 'ptb': 17.224870681762695, 'c4': 14.895048141479492}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 19:24:05 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 17689.869140625, 'ptb': 16218.76171875, 'c4': 14243.94140625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 19:27:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.920369148254395, 'ptb': 17.25480079650879, 'c4': 14.915318489074707}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 19:52:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.578502655029297, 'ptb': 17.019023895263672, 'c4': 14.758569717407227}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:10:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.672872543334961, 'ptb': 17.0064697265625, 'c4': 14.760738372802734}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:43:13 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174354314804077}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:47:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.631580352783203, 'ptb': 16.97328758239746, 'c4': 14.730953216552734}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:57:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0173927545547485}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:20:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624539375305176, 'ptb': 16.962238311767578, 'c4': 14.72238540649414}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:22:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.017406940460205}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 09:46:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.918395042419434, 'ptb': 17.25554847717285, 'c4': 14.913583755493164}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 10:23:36 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.648634910583496, 'ptb': 16.99466323852539, 'c4': 14.757500648498535}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 10:39:04 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.00396728515625, 'ptb': 17.35770606994629, 'c4': 15.017828941345215}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 10:45:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.900713920593262, 'ptb': 17.30955696105957, 'c4': 14.988725662231445}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 11:05:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.680755615234375, 'ptb': 17.036760330200195, 'c4': 14.798286437988281}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 11:26:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.638727188110352, 'ptb': 16.985816955566406, 'c4': 14.746527671813965}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 14:45:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.864378929138184, 'ptb': 17.256298065185547, 'c4': 14.9561128616333}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 14:53:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.825340270996094, 'ptb': 17.122751235961914, 'c4': 14.860315322875977}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 15:33:32 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 15:47:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.78475570678711, 'ptb': 17.3245906829834, 'c4': 14.901328086853027}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 15:56:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.470401763916016, 'ptb': 17.41278839111328, 'c4': 14.984952926635742}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 16:01:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.4391450881958, 'ptb': 17.092308044433594, 'c4': 14.80551528930664}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 18:33:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.479689598083496, 'ptb': 17.16665267944336, 'c4': 14.845243453979492}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 19:12:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.64638614654541, 'ptb': 17.07895851135254, 'c4': 14.780261039733887}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 19:46:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.683521270751953, 'ptb': 17.127952575683594, 'c4': 14.80492115020752}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 10:39:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.815104484558105, 'ptb': 17.276531219482422, 'c4': 14.904596328735352}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 12:33:11 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.747775077819824, 'ptb': 17.314815521240234, 'c4': 14.914549827575684}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 12:38:58 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.459704399108887, 'ptb': 17.26528549194336, 'c4': 14.90957260131836}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 12:39:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.455571174621582, 'ptb': 17.31932830810547, 'c4': 14.937809944152832}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 13:08:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 13:11:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.900713920593262, 'ptb': 17.30955696105957, 'c4': 14.988725662231445}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 13:20:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.714792251586914, 'ptb': 17.083410263061523, 'c4': 14.818227767944336}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 13:52:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1479.638916015625, 'ptb': 1038.0010986328125, 'c4': 479.8078308105469}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 13:56:25 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.680755615234375, 'ptb': 17.036760330200195, 'c4': 14.798286437988281}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 14:04:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.555334091186523, 'ptb': 17.268287658691406, 'c4': 14.928695678710938}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 14:32:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.4391450881958, 'ptb': 17.092308044433594, 'c4': 14.80551528930664}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 14:46:13 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602624893188477, 'ptb': 17.009422302246094, 'c4': 14.746133804321289}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 15:14:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.492218971252441, 'ptb': 17.016809463500977, 'c4': 14.756319046020508}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 15:41:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.592339515686035, 'ptb': 16.989501953125, 'c4': 14.739469528198242}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 16:13:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.534839630126953, 'ptb': 16.993927001953125, 'c4': 14.743404388427734}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 16:46:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.594475746154785, 'ptb': 17.16665267944336, 'c4': 14.87094783782959}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 19:01:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.635254859924316, 'ptb': 17.13985252380371, 'c4': 14.85195541381836}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 19:36:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.559294700622559, 'ptb': 16.988027572631836, 'c4': 14.740116119384766}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 20:17:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.4788818359375, 'ptb': 17.14803695678711, 'c4': 14.850992202758789}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 20:58:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.635254859924316, 'ptb': 17.05451774597168, 'c4': 14.784857749938965}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 21:07:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.635254859924316, 'ptb': 17.05451774597168, 'c4': 14.784857749938965}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 10:29:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.526933670043945, 'ptb': 17.074512481689453, 'c4': 14.800517082214355}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 11:01:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624946594238281, 'ptb': 17.025671005249023, 'c4': 14.776455879211426}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 11:39:25 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.569354057312012, 'ptb': 17.048593521118164, 'c4': 14.785758972167969}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 12:17:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.593052864074707, 'ptb': 17.033803939819336, 'c4': 14.77806282043457}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 13:02:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701043128967285, 'ptb': 17.136878967285156, 'c4': 14.850964546203613}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 13:36:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.682905197143555, 'ptb': 17.11680793762207, 'c4': 14.846631050109863}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 14:05:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.686284065246582, 'ptb': 17.115318298339844, 'c4': 14.841704368591309}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 14:43:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620255470275879, 'ptb': 17.028627395629883, 'c4': 14.77406120300293}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 19:12:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.593052864074707, 'ptb': 16.99466323852539, 'c4': 14.744023323059082}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 19:45:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.565897941589355, 'ptb': 17.0064697265625, 'c4': 14.747735977172852}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 10:06:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.59631061553955, 'ptb': 16.996875762939453, 'c4': 14.74436092376709}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 10:19:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.544171333312988, 'ptb': 17.0072078704834, 'c4': 14.749565124511719}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 10:57:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.600994110107422, 'ptb': 16.996875762939453, 'c4': 14.744220733642578}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 11:28:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.502028465270996, 'ptb': 17.0219783782959, 'c4': 14.765103340148926}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 11:58:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.613117218017578, 'ptb': 17.016809463500977, 'c4': 14.754179000854492}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 12:58:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.447002410888672, 'ptb': 17.098241806030273, 'c4': 14.81102180480957}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 13:07:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.63209056854248, 'ptb': 16.974760055541992, 'c4': 14.725924491882324}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 13:26:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.645261764526367, 'ptb': 17.001306533813477, 'c4': 14.746527671813965}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 13:47:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.46878433227539, 'ptb': 17.13092613220215, 'c4': 14.831828117370605}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 14:17:05 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.623929023742676, 'ptb': 17.049333572387695, 'c4': 14.775779724121094}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 14:46:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.511235237121582, 'ptb': 17.04489517211914, 'c4': 14.7849702835083}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 15:15:45 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.612507820129395, 'ptb': 17.034543991088867, 'c4': 14.765947341918945}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 15:45:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.558280944824219, 'ptb': 17.04193687438965, 'c4': 14.771271705627441}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 16:15:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.61026382446289, 'ptb': 17.038240432739258, 'c4': 14.761920928955078}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 18:35:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 18:40:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.750349044799805, 'ptb': 17.073772430419922, 'c4': 14.830697059631348}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 18:49:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.625153541564941, 'ptb': 16.962974548339844, 'c4': 14.720701217651367}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 18:55:26 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624946594238281, 'ptb': 16.962974548339844, 'c4': 14.720813751220703}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 18:57:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 19:22:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.621784210205078, 'ptb': 16.970340728759766, 'c4': 14.727919578552246}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 19:40:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.66304874420166, 'ptb': 17.016067504882812, 'c4': 14.757500648498535}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 20:05:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.902480125427246, 'ptb': 17.146549224853516, 'c4': 14.92735767364502}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 20:21:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.0361328125, 'ptb': 17.21291160583496, 'c4': 14.990069389343262}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 20:39:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624438285827637, 'ptb': 16.961503982543945, 'c4': 14.720813751220703}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 20:55:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.623315811157227, 'ptb': 16.96076774597168, 'c4': 14.720477104187012}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 09:32:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.623824119567871, 'ptb': 16.96371078491211, 'c4': 14.721319198608398}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 09:50:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.625253677368164, 'ptb': 16.961503982543945, 'c4': 14.721712112426758}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 10:05:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.626785278320312, 'ptb': 16.96371078491211, 'c4': 14.721319198608398}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 10:23:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.632190704345703, 'ptb': 16.967395782470703, 'c4': 14.722273826599121}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 10:59:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.643218994140625, 'ptb': 16.970340728759766, 'c4': 14.725419044494629}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 11:14:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.672358512878418, 'ptb': 16.989501953125, 'c4': 14.737444877624512}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 11:30:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.764039039611816, 'ptb': 17.05451774597168, 'c4': 14.7815580368042}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 11:47:26 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.069944381713867, 'ptb': 17.337377548217773, 'c4': 14.95340347290039}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 12:03:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624438285827637, 'ptb': 16.961503982543945, 'c4': 14.720813751220703}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 12:03:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.623520851135254, 'ptb': 16.96002960205078, 'c4': 14.7206449508667}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 12:06:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.623824119567871, 'ptb': 16.962974548339844, 'c4': 14.72126293182373}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 12:06:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.625253677368164, 'ptb': 16.961503982543945, 'c4': 14.721487998962402}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 12:09:53 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.626579284667969, 'ptb': 16.96371078491211, 'c4': 14.72154426574707}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 12:09:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.632190704345703, 'ptb': 16.966655731201172, 'c4': 14.722162246704102}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 12:12:48 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.643016815185547, 'ptb': 16.970340728759766, 'c4': 14.725699424743652}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 12:12:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.672155380249023, 'ptb': 16.988765716552734, 'c4': 14.737163543701172}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:28:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.622398376464844, 'ptb': 16.96813201904297, 'c4': 14.727806091308594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:28:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.621582984924316, 'ptb': 16.967395782470703, 'c4': 14.72811508178711}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:28:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.621784210205078, 'ptb': 16.967395782470703, 'c4': 14.727638244628906}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:28:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.623213768005371, 'ptb': 16.96813201904297, 'c4': 14.727638244628906}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:31:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.623213768005371, 'ptb': 16.967395782470703, 'c4': 14.728705406188965}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:32:10 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.629132270812988, 'ptb': 16.97181510925293, 'c4': 14.728986740112305}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:32:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.638827323913574, 'ptb': 16.97696876525879, 'c4': 14.73173999786377}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:32:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.667856216430664, 'ptb': 16.993927001953125, 'c4': 14.744754791259766}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:20:26 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.937450408935547, 'ptb': 17.396169662475586, 'c4': 15.01018238067627}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:20:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.937450408935547, 'ptb': 17.396169662475586, 'c4': 15.01018238067627}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:24:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.937450408935547, 'ptb': 17.396169662475586, 'c4': 15.01018238067627}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:24:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.937450408935547, 'ptb': 17.396169662475586, 'c4': 15.01018238067627}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:28:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.61607551574707, 'ptb': 16.989501953125, 'c4': 14.74129581451416}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:28:42 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.680549621582031, 'ptb': 17.071550369262695, 'c4': 14.798738479614258}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:32:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.616584777832031, 'ptb': 16.967395782470703, 'c4': 14.726850509643555}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:32:25 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:37:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 16.406494140625, 'ptb': 19.014955520629883, 'c4': 15.83544635772705}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:37:10 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 24.26161003112793, 'ptb': 29.608585357666016, 'c4': 20.984281539916992}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:41:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:41:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:45:05 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:45:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:48:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:49:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:52:45 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:52:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:19:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.677066802978516, 'ptb': 16.980653762817383, 'c4': 14.754011154174805}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:25:49 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:30:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.626171112060547, 'ptb': 16.9696044921875, 'c4': 14.727919578552246}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:30:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.616584777832031, 'ptb': 16.967395782470703, 'c4': 14.726850509643555}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:34:11 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.61607551574707, 'ptb': 16.989501953125, 'c4': 14.74129581451416}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:34:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.680549621582031, 'ptb': 17.071550369262695, 'c4': 14.798738479614258}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:37:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609654426574707, 'ptb': 16.967395782470703, 'c4': 14.727020263671875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:38:09 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.937450408935547, 'ptb': 17.396169662475586, 'c4': 15.01018238067627}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 10:38:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.615870475769043, 'ptb': 16.961503982543945, 'c4': 14.725671768188477}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 10:43:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.615870475769043, 'ptb': 16.961503982543945, 'c4': 14.725671768188477}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 10:44:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.615870475769043, 'ptb': 16.961503982543945, 'c4': 14.725671768188477}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 10:49:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.615870475769043, 'ptb': 16.961503982543945, 'c4': 14.725671768188477}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 10:50:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.615870475769043, 'ptb': 16.961503982543945, 'c4': 14.725671768188477}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 10:55:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.615870475769043, 'ptb': 16.961503982543945, 'c4': 14.725671768188477}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 10:56:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.615870475769043, 'ptb': 16.961503982543945, 'c4': 14.725671768188477}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:01:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.710378646850586, 'ptb': 16.96371078491211, 'c4': 14.737024307250977}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:01:30 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.915790557861328, 'ptb': 17.036022186279297, 'c4': 14.94125747680664}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:07:04 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.96002960205078, 'c4': 14.724801063537598}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:07:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.63148021697998, 'ptb': 16.952672958374023, 'c4': 14.724858283996582}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:11:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.65977668762207, 'ptb': 16.937963485717773, 'c4': 14.728312492370605}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:11:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.727217674255371, 'ptb': 16.934289932250977, 'c4': 14.756149291992188}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 15:59:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.96002960205078, 'c4': 14.724801063537598}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:03:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.647102355957031, 'ptb': 17.009422302246094, 'c4': 14.738569259643555}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:04:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.647102355957031, 'ptb': 17.009422302246094, 'c4': 14.738569259643555}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:08:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.62821102142334, 'ptb': 16.974023818969727, 'c4': 14.730419158935547}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:08:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.962974548339844, 'c4': 14.727413177490234}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:13:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.962974548339844, 'c4': 14.727413177490234}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:14:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.962974548339844, 'c4': 14.727413177490234}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:18:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.962974548339844, 'c4': 14.727413177490234}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:18:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.962974548339844, 'c4': 14.727413177490234}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:22:13 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.962974548339844, 'c4': 14.727413177490234}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:22:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.962974548339844, 'c4': 14.727413177490234}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:26:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620359420776367, 'ptb': 16.962974548339844, 'c4': 14.727413177490234}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:26:48 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 20.960525512695312, 'ptb': 22.86981201171875, 'c4': 19.186748504638672}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 20:19:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.601402282714844, 'ptb': 16.993927001953125, 'c4': 14.75440502166748}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 20:56:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.601603507995605, 'ptb': 16.993927001953125, 'c4': 14.754292488098145}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 10:39:05 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:18:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 399.1850891113281, 'ptb': 338.16180419921875, 'c4': 211.1034698486328}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:20:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 914.3046875, 'ptb': 826.131103515625, 'c4': 528.1007690429688}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:23:42 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.558992385864258, 'ptb': 17.012374877929688, 'c4': 14.759161949157715}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:29:04 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 17923.3828125, 'ptb': 16244.1162109375, 'c4': 14326.7724609375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:34:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.658550262451172, 'ptb': 17.0219783782959, 'c4': 14.758598327636719}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:38:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.68116569519043, 'ptb': 17.05377769470215, 'c4': 14.796029090881348}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:48:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 47.63862609863281, 'ptb': 53.84041213989258, 'c4': 51.6418342590332}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:51:12 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.636580467224121, 'ptb': 16.987289428710938, 'c4': 14.743855476379395}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:13:13 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 4686.30322265625, 'ptb': 3027.3759765625, 'c4': 2925.800048828125}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:20:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.641993522644043, 'ptb': 16.993186950683594, 'c4': 14.742308616638184}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:31:30 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.668573379516602, 'ptb': 17.000568389892578, 'c4': 14.747061729431152}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:43:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 3516.643310546875, 'ptb': 2548.642333984375, 'c4': 2214.009765625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:46:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.856606483459473, 'ptb': 17.269786834716797, 'c4': 14.970239639282227}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:55:23 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.741194725036621, 'ptb': 17.090824127197266, 'c4': 14.816248893737793}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:03:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.835478782653809, 'ptb': 17.11457633972168, 'c4': 14.842611312866211}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:14:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.849672317504883, 'ptb': 18.456342697143555, 'c4': 15.6731538772583}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:23:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.042010307312012, 'ptb': 17.623397827148438, 'c4': 15.118216514587402}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:29:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.251836776733398, 'ptb': 17.86522102355957, 'c4': 15.197288513183594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:51:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.631887435913086, 'ptb': 16.974760055541992, 'c4': 14.726880073547363}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:59:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.642094612121582, 'ptb': 16.966655731201172, 'c4': 14.727217674255371}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 16:17:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.592541694641113, 'ptb': 17.00351905822754, 'c4': 14.743349075317383}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 16:34:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602417945861816, 'ptb': 16.998350143432617, 'c4': 14.755023956298828}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 18:23:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602417945861816, 'ptb': 16.998350143432617, 'c4': 14.755023956298828}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 18:25:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602417945861816, 'ptb': 16.998350143432617, 'c4': 14.755023956298828}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 18:26:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602417945861816, 'ptb': 16.998350143432617, 'c4': 14.755023956298828}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 18:40:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602417945861816, 'ptb': 16.998350143432617, 'c4': 14.755023956298828}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 18:41:23 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602417945861816, 'ptb': 16.998350143432617, 'c4': 14.755023956298828}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 18:42:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602417945861816, 'ptb': 16.998350143432617, 'c4': 14.755023956298828}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 18:55:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602624893188477, 'ptb': 16.99761199951172, 'c4': 14.753954887390137}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 18:57:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602417945861816, 'ptb': 16.998350143432617, 'c4': 14.755023956298828}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 18:57:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.662027359008789, 'ptb': 17.00278091430664, 'c4': 14.754714965820312}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 19:10:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 648.3756103515625, 'ptb': 603.1002197265625, 'c4': 289.18994140625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 19:11:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.604968070983887, 'ptb': 16.993186950683594, 'c4': 14.75139331817627}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 19:12:30 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.605476379394531, 'ptb': 16.986553192138672, 'c4': 14.750971794128418}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 19:25:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.726907730102539, 'ptb': 17.102699279785156, 'c4': 14.813678741455078}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 19:26:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.614238739013672, 'ptb': 16.987289428710938, 'c4': 14.753307342529297}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 10:02:09 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.614238739013672, 'ptb': 16.987289428710938, 'c4': 14.753307342529297}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 10:02:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.648941993713379, 'ptb': 17.028627395629883, 'c4': 14.7797269821167}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 10:18:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.731224060058594, 'ptb': 17.115318298339844, 'c4': 14.828829765319824}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 10:21:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.73225212097168, 'ptb': 17.12200927734375, 'c4': 14.829565048217773}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 10:22:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.727936744689941, 'ptb': 17.11309242248535, 'c4': 14.830018043518066}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 10:39:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.73739242553711, 'ptb': 17.117549896240234, 'c4': 14.829819679260254}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 10:39:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.742326736450195, 'ptb': 17.115318298339844, 'c4': 14.825889587402344}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 10:39:42 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.734719276428223, 'ptb': 17.11606216430664, 'c4': 14.828292846679688}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 11:02:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.744483947753906, 'ptb': 17.11012077331543, 'c4': 14.827275276184082}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 11:05:23 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.744793891906738, 'ptb': 17.105667114257812, 'c4': 14.82741641998291}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 11:05:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.733588218688965, 'ptb': 17.11606216430664, 'c4': 14.824220657348633}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 11:22:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.731121063232422, 'ptb': 17.11012077331543, 'c4': 14.829622268676758}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 11:24:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.732765197753906, 'ptb': 17.1086368560791, 'c4': 14.829197883605957}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 11:24:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.731431007385254, 'ptb': 17.109378814697266, 'c4': 14.826793670654297}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 12:11:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620867729187012, 'ptb': 16.993186950683594, 'c4': 14.754996299743652}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 12:14:26 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620255470275879, 'ptb': 16.993927001953125, 'c4': 14.754292488098145}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 12:14:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.620052337646484, 'ptb': 16.993927001953125, 'c4': 14.75440502166748}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 12:55:26 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.607105255126953, 'ptb': 16.990976333618164, 'c4': 14.75747299194336}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 12:57:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.612709999084473, 'ptb': 16.99171257019043, 'c4': 14.757332801818848}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 12:57:53 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.598040580749512, 'ptb': 16.9902400970459, 'c4': 14.755952835083008}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 13:24:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.569354057312012, 'ptb': 17.007946014404297, 'c4': 14.773356437683105}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 13:26:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.580535888671875, 'ptb': 16.989501953125, 'c4': 14.76251220703125}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 13:27:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.576570510864258, 'ptb': 17.04637336730957, 'c4': 14.804526329040527}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 13:38:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.72208023071289}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 13:39:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0175632238388062}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 13:39:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0175632238388062}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 13:40:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0175632238388062}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 13:59:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.644035339355469, 'ptb': 17.028627395629883, 'c4': 14.772257804870605}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 15:52:30 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.70166015625, 'ptb': 17.09601593017578, 'c4': 14.829707145690918}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 15:53:04 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.580129623413086, 'ptb': 17.024194717407227, 'c4': 14.780655860900879}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 15:53:59 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 17.750295639038086, 'ptb': 18.19308853149414, 'c4': 15.588662147521973}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 16:10:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.569354057312012, 'ptb': 17.007946014404297, 'c4': 14.773356437683105}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 16:12:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.569354057312012, 'ptb': 17.007946014404297, 'c4': 14.773356437683105}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 16:13:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568235397338867, 'ptb': 17.013851165771484, 'c4': 14.774258613586426}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 16:27:12 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568235397338867, 'ptb': 17.013851165771484, 'c4': 14.774258613586426}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 16:31:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568235397338867, 'ptb': 17.013851165771484, 'c4': 14.774258613586426}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 16:31:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568235397338867, 'ptb': 17.013851165771484, 'c4': 14.774258613586426}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 16:48:42 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568235397338867, 'ptb': 17.013851165771484, 'c4': 14.774258613586426}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 16:49:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568235397338867, 'ptb': 17.013851165771484, 'c4': 14.774258613586426}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 16:50:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568235397338867, 'ptb': 17.013851165771484, 'c4': 14.774258613586426}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 17:06:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568235397338867, 'ptb': 17.013851165771484, 'c4': 14.774258613586426}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 17:08:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.569047927856445, 'ptb': 17.012374877929688, 'c4': 14.773552894592285}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 17:08:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.566916465759277, 'ptb': 17.012374877929688, 'c4': 14.77679443359375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 17:24:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.534233093261719, 'ptb': 17.09156608581543, 'c4': 14.819132804870605}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 17:24:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.554727554321289, 'ptb': 17.02936553955078, 'c4': 14.783758163452148}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 20:21:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.577995300292969, 'ptb': 17.01976203918457, 'c4': 14.77761173248291}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 20:21:58 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.565999031066895, 'ptb': 17.016067504882812, 'c4': 14.771158218383789}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 20:22:49 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.575044631958008, 'ptb': 17.013851165771484, 'c4': 14.774088859558105}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 20:44:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.575145721435547, 'ptb': 17.02050018310547, 'c4': 14.775357246398926}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 20:44:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568134307861328, 'ptb': 17.016809463500977, 'c4': 14.776738166809082}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 20:44:58 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.569252967834473, 'ptb': 17.019023895263672, 'c4': 14.77206039428711}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 21:01:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.571487426757812, 'ptb': 17.021240234375, 'c4': 14.772708892822266}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 21:03:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.596410751342773, 'ptb': 17.018285751342773, 'c4': 14.774511337280273}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 21:04:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.581450462341309, 'ptb': 17.0072078704834, 'c4': 14.774371147155762}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 09:11:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.571487426757812, 'ptb': 17.021240234375, 'c4': 14.772708892822266}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 09:12:12 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.571487426757812, 'ptb': 17.021240234375, 'c4': 14.772708892822266}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 09:12:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.571487426757812, 'ptb': 17.021240234375, 'c4': 14.772708892822266}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 09:34:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.606799125671387, 'ptb': 17.00278091430664, 'c4': 14.762032508850098}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 09:35:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.592134475708008, 'ptb': 16.996875762939453, 'c4': 14.759780883789062}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 09:36:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.653640747070312, 'ptb': 17.002042770385742, 'c4': 14.758879661560059}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 09:53:10 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.577689170837402, 'ptb': 16.992450714111328, 'c4': 14.762680053710938}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 10:12:23 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 12:13:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.586743354797363, 'ptb': 16.993186950683594, 'c4': 14.764427185058594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 12:15:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585723876953125, 'ptb': 16.999088287353516, 'c4': 14.761920928955078}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 12:58:49 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 12:59:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 12:59:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 13:00:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 13:29:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 13:31:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 13:31:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 13:33:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 13:55:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 13:56:53 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 13:57:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 13:58:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 14:21:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.75786304473877, 'ptb': 17.00351905822754, 'c4': 14.833498001098633}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 14:23:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 14:24:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 14:25:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 14:53:42 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 16:16:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582876205444336, 'ptb': 16.99466323852539, 'c4': 14.762118339538574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 16:17:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.589386940002441, 'ptb': 16.990976333618164, 'c4': 14.76335620880127}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 16:17:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.584504127502441, 'ptb': 17.005733489990234, 'c4': 14.758992195129395}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 16:18:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.588269233703613, 'ptb': 16.999088287353516, 'c4': 14.761018753051758}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 19:11:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.581857681274414, 'ptb': 16.999826431274414, 'c4': 14.758148193359375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 19:12:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.58949089050293, 'ptb': 17.0064697265625, 'c4': 14.762032508850098}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 19:13:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.588777542114258, 'ptb': 17.000568389892578, 'c4': 14.763243675231934}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 19:14:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.58216381072998, 'ptb': 16.993186950683594, 'c4': 14.760034561157227}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 20:42:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.600179672241211, 'ptb': 17.025671005249023, 'c4': 14.77716064453125}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 20:44:04 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.722593307495117, 'ptb': 17.083410263061523, 'c4': 14.849746704101562}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 20:52:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.58491039276123, 'ptb': 16.998350143432617, 'c4': 14.759527206420898}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 20:55:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585417747497559, 'ptb': 16.993927001953125, 'c4': 14.76177978515625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 10:17:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585417747497559, 'ptb': 16.993927001953125, 'c4': 14.76177978515625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 10:18:10 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585417747497559, 'ptb': 16.993927001953125, 'c4': 14.76177978515625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 10:19:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585417747497559, 'ptb': 16.993927001953125, 'c4': 14.76177978515625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 10:20:48 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585417747497559, 'ptb': 16.993927001953125, 'c4': 14.76177978515625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 10:36:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585417747497559, 'ptb': 16.993927001953125, 'c4': 14.76177978515625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 11:24:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585417747497559, 'ptb': 16.993927001953125, 'c4': 14.76132869720459}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 11:24:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585417747497559, 'ptb': 16.993927001953125, 'c4': 14.76177978515625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 11:25:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585417747497559, 'ptb': 16.993927001953125, 'c4': 14.76177978515625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 11:26:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.86417007446289, 'ptb': 17.063398361206055, 'c4': 14.881360054016113}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 13:22:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.132832527160645, 'ptb': 17.99362564086914, 'c4': 15.53956127166748}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 13:23:36 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.132832527160645, 'ptb': 17.99362564086914, 'c4': 15.53956127166748}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 13:24:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.132832527160645, 'ptb': 17.99362564086914, 'c4': 15.53956127166748}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 13:25:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 15.139165878295898, 'ptb': 17.997528076171875, 'c4': 15.539383888244629}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 13:47:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.612813949584961, 'ptb': 17.104183197021484, 'c4': 14.835224151611328}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 13:48:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.58257007598877, 'ptb': 17.012374877929688, 'c4': 14.763553619384766}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 13:49:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.590200424194336, 'ptb': 17.03232192993164, 'c4': 14.780628204345703}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 13:50:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.587250709533691, 'ptb': 17.010160446166992, 'c4': 14.76352596282959}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 14:10:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579723358154297, 'ptb': 17.004995346069336, 'c4': 14.761018753051758}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 14:12:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.58491039276123, 'ptb': 16.99466323852539, 'c4': 14.766144752502441}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 14:13:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582469940185547, 'ptb': 16.999088287353516, 'c4': 14.76298999786377}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 14:13:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.58491039276123, 'ptb': 16.99466323852539, 'c4': 14.766144752502441}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 22:50:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.584197998046875, 'ptb': 17.0064697265625, 'c4': 14.76048469543457}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 22:50:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.586843490600586, 'ptb': 16.999826431274414, 'c4': 14.762032508850098}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 22:51:36 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.586843490600586, 'ptb': 17.00351905822754, 'c4': 14.761442184448242}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 22:52:21 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585723876953125, 'ptb': 17.004255294799805, 'c4': 14.761610984802246}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 23:19:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.584096908569336, 'ptb': 17.0072078704834, 'c4': 14.762483596801758}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 23:19:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.58368968963623, 'ptb': 17.005733489990234, 'c4': 14.761526107788086}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 23:20:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.577689170837402, 'ptb': 17.004255294799805, 'c4': 14.762399673461914}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 23:20:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.583078384399414, 'ptb': 17.013851165771484, 'c4': 14.764793395996094}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 11:50:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.57575798034668, 'ptb': 17.000568389892578, 'c4': 14.765159606933594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 11:51:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.583283424377441, 'ptb': 17.0072078704834, 'c4': 14.76214599609375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 11:53:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.574638366699219, 'ptb': 17.030105590820312, 'c4': 14.776034355163574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 11:54:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.727217674255371, 'ptb': 17.183801651000977, 'c4': 14.895133972167969}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 12:55:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.727217674255371, 'ptb': 17.183801651000977, 'c4': 14.895133972167969}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 15:17:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.57575798034668, 'ptb': 17.000568389892578, 'c4': 14.765159606933594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 15:22:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.57575798034668, 'ptb': 17.000568389892578, 'c4': 14.765159606933594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 15:22:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.57575798034668, 'ptb': 17.000568389892578, 'c4': 14.765159606933594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 16:36:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.57575798034668, 'ptb': 17.000568389892578, 'c4': 14.765159606933594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 18:15:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 18.639686584472656, 'ptb': 20.1807861328125, 'c4': 17.699140548706055}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 18:15:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.57575798034668, 'ptb': 17.000568389892578, 'c4': 14.765159606933594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 18:16:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.57575798034668, 'ptb': 17.000568389892578, 'c4': 14.765159606933594}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 19:54:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579723358154297, 'ptb': 17.004995346069336, 'c4': 14.761272430419922}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 20:00:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.599261283874512, 'ptb': 17.025671005249023, 'c4': 14.771271705627441}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 20:01:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.619338035583496, 'ptb': 17.010160446166992, 'c4': 14.779218673706055}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 20:19:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.619338035583496, 'ptb': 17.010160446166992, 'c4': 14.779218673706055}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 20:21:35 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.619338035583496, 'ptb': 17.010160446166992, 'c4': 14.779218673706055}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 20:40:36 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579723358154297, 'ptb': 17.004995346069336, 'c4': 14.761272430419922}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 20:41:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579723358154297, 'ptb': 17.004995346069336, 'c4': 14.761272430419922}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 20:42:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579723358154297, 'ptb': 17.004995346069336, 'c4': 14.761272430419922}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 20:59:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579723358154297, 'ptb': 17.004995346069336, 'c4': 14.761272430419922}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 21:01:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579723358154297, 'ptb': 17.004995346069336, 'c4': 14.761272430419922}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 21:02:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579927444458008, 'ptb': 16.996137619018555, 'c4': 14.765524864196777}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 21:24:30 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579927444458008, 'ptb': 16.996137619018555, 'c4': 14.765524864196777}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 21:25:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.583488464355469, 'ptb': 16.998350143432617, 'c4': 14.765637397766113}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 21:26:05 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.592239379882812, 'ptb': 17.00278091430664, 'c4': 14.763609886169434}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 21:48:25 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.572504997253418, 'ptb': 17.000568389892578, 'c4': 14.763243675231934}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 21:49:20 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.580842018127441, 'ptb': 16.99540138244629, 'c4': 14.765609741210938}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 21:49:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.573724746704102, 'ptb': 16.99171257019043, 'c4': 14.76197624206543}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 22:07:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579621315002441, 'ptb': 16.999826431274414, 'c4': 14.763497352600098}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 22:08:09 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.580229759216309, 'ptb': 16.999088287353516, 'c4': 14.764595985412598}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 22:10:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.58104419708252, 'ptb': 16.99761199951172, 'c4': 14.764313697814941}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 00:37:45 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579010963439941, 'ptb': 16.996137619018555, 'c4': 14.763132095336914}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 10:03:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 25.11500358581543, 'ptb': 50.986141204833984, 'c4': 28.930456161499023}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 11:16:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.572707176208496, 'ptb': 17.00351905822754, 'c4': 14.764117240905762}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 11:20:25 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.576671600341797, 'ptb': 16.9902400970459, 'c4': 14.76177978515625}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 11:20:45 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579621315002441, 'ptb': 16.998350143432617, 'c4': 14.759696960449219}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 11:36:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.586336135864258, 'ptb': 16.989501953125, 'c4': 14.75553035736084}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 11:42:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.68464469909668, 'ptb': 17.070068359375, 'c4': 14.787537574768066}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 11:43:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.621582984924316, 'ptb': 17.005733489990234, 'c4': 14.766229629516602}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 14:33:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.585824966430664, 'ptb': 16.982864379882812, 'c4': 14.761666297912598}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 14:33:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.611588478088379, 'ptb': 17.013113021850586, 'c4': 14.769299507141113}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 14:35:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.660388946533203, 'ptb': 17.06488037109375, 'c4': 14.806700706481934}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 16:54:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.606904029846191, 'ptb': 17.03084373474121, 'c4': 14.782461166381836}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 16:55:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.625153541564941, 'ptb': 17.053035736083984, 'c4': 14.787226676940918}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 16:55:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.683416366577148, 'ptb': 17.106409072875977, 'c4': 14.827217102050781}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 19:44:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.75240707397461, 'ptb': 17.216646194458008, 'c4': 14.908862113952637}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 19:54:59 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.690997123718262, 'ptb': 17.172616958618164, 'c4': 14.874323844909668}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 09:13:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174496173858643}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 09:14:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174496173858643}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 09:58:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.579621315002441, 'ptb': 16.998350143432617, 'c4': 14.759696960449219}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 10:16:09 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.578704833984375, 'ptb': 16.992450714111328, 'c4': 14.762314796447754}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:07:13 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.572504997253418, 'ptb': 17.012374877929688, 'c4': 14.766904830932617}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:12:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:13:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:13:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:14:25 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:15:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:17:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0174212455749512}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:18:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0173643827438354}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:19:04 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0173643827438354}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:19:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 1.0173643827438354}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:36:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.549551010131836, 'ptb': 17.027889251708984, 'c4': 14.783926963806152}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 18:56:09 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.539403915405273, 'ptb': 17.037500381469727, 'c4': 14.792699813842773}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 19:10:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.597837448120117, 'ptb': 16.990976333618164, 'c4': 14.753166198730469}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 19:23:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.599974632263184, 'ptb': 17.00278091430664, 'c4': 14.75570011138916}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 19:29:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.608634948730469, 'ptb': 16.996875762939453, 'c4': 14.764286041259766}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 19:39:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.5452880859375, 'ptb': 17.024194717407227, 'c4': 14.783814430236816}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 19:46:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.568947792053223, 'ptb': 17.01089859008789, 'c4': 14.767609596252441}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 19:55:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.583383560180664, 'ptb': 17.010160446166992, 'c4': 14.762849807739258}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 20:03:15 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.597837448120117, 'ptb': 17.007946014404297, 'c4': 14.760794639587402}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 20:11:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.583383560180664, 'ptb': 17.010160446166992, 'c4': 14.762849807739258}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 20:19:27 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.578909873962402, 'ptb': 17.019023895263672, 'c4': 14.765637397766113}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 20:27:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582062721252441, 'ptb': 17.013851165771484, 'c4': 14.763582229614258}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 20:31:49 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.609957695007324, 'ptb': 16.99171257019043, 'c4': 14.761526107788086}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 20:39:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.600076675415039, 'ptb': 17.000568389892578, 'c4': 14.755446434020996}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 20:48:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.582062721252441, 'ptb': 17.013851165771484, 'c4': 14.763582229614258}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 20:57:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.583488464355469, 'ptb': 17.004995346069336, 'c4': 14.764567375183105}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 21:04:23 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.583488464355469, 'ptb': 17.004995346069336, 'c4': 14.764567375183105}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 21:12:48 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.581555366516113, 'ptb': 17.0219783782959, 'c4': 14.770539283752441}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-21 09:21:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.578704833984375, 'ptb': 16.992450714111328, 'c4': 14.762314796447754}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 10:17:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 10:26:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.470401763916016, 'ptb': 17.41278839111328, 'c4': 14.984952926635742}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 10:26:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.683521270751953, 'ptb': 17.127952575683594, 'c4': 14.80492115020752}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 10:33:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.78475570678711, 'ptb': 17.3245906829834, 'c4': 14.901328086853027}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 10:33:29 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.64638614654541, 'ptb': 17.07895851135254, 'c4': 14.780261039733887}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 10:41:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.784444808959961, 'ptb': 17.308805465698242, 'c4': 14.91395378112793}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 10:50:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.726805686950684, 'ptb': 17.068586349487305, 'c4': 14.786408424377441}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:03:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.4391450881958, 'ptb': 17.092308044433594, 'c4': 14.80551528930664}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:03:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.602624893188477, 'ptb': 17.009422302246094, 'c4': 14.746133804321289}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:11:05 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.492218971252441, 'ptb': 17.016809463500977, 'c4': 14.756319046020508}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:11:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.592339515686035, 'ptb': 16.989501953125, 'c4': 14.739469528198242}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:17:46 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.534839630126953, 'ptb': 16.993927001953125, 'c4': 14.743404388427734}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:17:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.588979721069336, 'ptb': 16.9902400970459, 'c4': 14.737473487854004}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 11:03:49 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.722491264343262, 'ptb': 17.106409072875977, 'c4': 14.811445236206055}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 11:39:30 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.656505584716797, 'ptb': 17.04193687438965, 'c4': 14.779894828796387}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 11:48:53 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.62964153289795, 'ptb': 17.03084373474121, 'c4': 14.763383865356445}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 14:28:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.777742385864258, 'ptb': 17.198720932006836, 'c4': 14.85784912109375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 14:38:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.630967140197754, 'ptb': 17.03084373474121, 'c4': 14.766763687133789}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 14:50:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.714691162109375, 'ptb': 17.1086368560791, 'c4': 14.809806823730469}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 16:52:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.715921401977539, 'ptb': 17.122751235961914, 'c4': 14.825634956359863}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 17:05:41 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.718796730041504, 'ptb': 17.12721061706543, 'c4': 14.824645042419434}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 17:16:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.667548179626465, 'ptb': 17.110862731933594, 'c4': 14.846829414367676}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 17:57:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.665094375610352, 'ptb': 17.112348556518555, 'c4': 14.847197532653809}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 18:08:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.667037963867188, 'ptb': 17.1420841217041, 'c4': 14.83944034576416}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 18:33:16 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.569047927856445, 'ptb': 17.05451774597168, 'c4': 14.789596557617188}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 19:05:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.596209526062012, 'ptb': 17.035282135009766, 'c4': 14.775357246398926}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 19:22:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.571587562561035, 'ptb': 17.001306533813477, 'c4': 14.756994247436523}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 19:43:24 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.688230514526367, 'ptb': 17.124238967895508, 'c4': 14.823033332824707}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 19:48:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.688230514526367, 'ptb': 17.124238967895508, 'c4': 14.823033332824707}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 12:05:10 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.722491264343262, 'ptb': 17.106409072875977, 'c4': 14.811445236206055}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 12:06:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.714691162109375, 'ptb': 17.1086368560791, 'c4': 14.809806823730469}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 12:16:58 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.713662147521973, 'ptb': 17.119037628173828, 'c4': 14.808451652526855}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 12:26:09 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.718282699584961, 'ptb': 17.10715103149414, 'c4': 14.814469337463379}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 12:32:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.657116889953613, 'ptb': 17.03084373474121, 'c4': 14.778908729553223}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 13:28:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.727423667907715, 'ptb': 17.08489227294922, 'c4': 14.817041397094727}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 13:55:13 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.658448219299316, 'ptb': 17.045635223388672, 'c4': 14.780881881713867}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 13:56:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.63127326965332, 'ptb': 17.028627395629883, 'c4': 14.763609886169434}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 18:04:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.640869140625, 'ptb': 17.028627395629883, 'c4': 14.767721176147461}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 18:30:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.707300186157227, 'ptb': 17.180070877075195, 'c4': 14.854080200195312}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 18:34:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.731325149536133, 'ptb': 17.164419174194336, 'c4': 14.840261459350586}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 18:41:04 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.726602554321289, 'ptb': 17.124238967895508, 'c4': 14.828010559082031}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 18:44:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.72937297821045, 'ptb': 17.12052345275879, 'c4': 14.822778701782227}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 18:47:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.725882530212402, 'ptb': 17.10492515563965, 'c4': 14.824050903320312}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 18:51:12 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.717255592346191, 'ptb': 17.10492515563965, 'c4': 14.818878173828125}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:12:44 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.720746994018555, 'ptb': 17.11680793762207, 'c4': 14.839526176452637}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:16:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.717873573303223, 'ptb': 17.11309242248535, 'c4': 14.825153350830078}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:20:42 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.720746994018555, 'ptb': 17.11680793762207, 'c4': 14.839526176452637}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:24:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.723828315734863, 'ptb': 17.11309242248535, 'c4': 14.82874584197998}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:33:18 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.741812705993652, 'ptb': 17.12200927734375, 'c4': 14.830018043518066}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:33:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.718076705932617, 'ptb': 17.11160659790039, 'c4': 14.82402229309082}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:44:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.693764686584473, 'ptb': 17.11457633972168, 'c4': 14.816503524780273}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:50:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.689460754394531, 'ptb': 17.075254440307617, 'c4': 14.818227767944336}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:01:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701558113098145, 'ptb': 17.132413864135742, 'c4': 14.846829414367676}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:06:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.686080932617188, 'ptb': 17.083410263061523, 'c4': 14.822439193725586}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:06:30 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701558113098145, 'ptb': 17.132413864135742, 'c4': 14.846829414367676}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:11:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.750761032104492, 'ptb': 17.066360473632812, 'c4': 14.788411140441895}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:11:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.747363090515137, 'ptb': 17.075254440307617, 'c4': 14.794307708740234}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:15:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.748907089233398, 'ptb': 17.072290420532227, 'c4': 14.794392585754395}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:16:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.723418235778809, 'ptb': 17.06562042236328, 'c4': 14.790329933166504}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:23:11 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.714280128479004, 'ptb': 17.06117820739746, 'c4': 14.787931442260742}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:23:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.725264549255371, 'ptb': 17.067106246948242, 'c4': 14.786972999572754}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:23:28 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.728757858276367, 'ptb': 17.05673599243164, 'c4': 14.791910171508789}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:31:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.766305923461914, 'ptb': 17.072290420532227, 'c4': 14.789483070373535}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:31:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.731224060058594, 'ptb': 17.0596981048584, 'c4': 14.79072380065918}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:41:11 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.69243335723877, 'ptb': 17.049333572387695, 'c4': 14.792529106140137}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:41:25 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.69243335723877, 'ptb': 17.049333572387695, 'c4': 14.792529106140137}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:48:45 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.703097343444824, 'ptb': 17.077476501464844, 'c4': 14.78843879699707}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 20:51:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.703097343444824, 'ptb': 17.077476501464844, 'c4': 14.78843879699707}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:01:31 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701250076293945, 'ptb': 17.07895851135254, 'c4': 14.789596557617188}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:01:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701250076293945, 'ptb': 17.07895851135254, 'c4': 14.789596557617188}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:02:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701250076293945, 'ptb': 17.07895851135254, 'c4': 14.789596557617188}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:06:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701250076293945, 'ptb': 17.07895851135254, 'c4': 14.789596557617188}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:11:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701250076293945, 'ptb': 17.07895851135254, 'c4': 14.789596557617188}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:12:36 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701250076293945, 'ptb': 17.07895851135254, 'c4': 14.789596557617188}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:21:00 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701250076293945, 'ptb': 17.07895851135254, 'c4': 14.789596557617188}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:22:02 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.717873573303223, 'ptb': 17.1428279876709, 'c4': 14.85274887084961}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:31:34 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.69263744354248, 'ptb': 17.113834381103516, 'c4': 14.818115234375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:37:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.69263744354248, 'ptb': 17.113834381103516, 'c4': 14.818115234375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:42:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.69263744354248, 'ptb': 17.113834381103516, 'c4': 14.818115234375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:48:10 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.69263744354248, 'ptb': 17.113834381103516, 'c4': 14.818115234375}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:49:37 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'ptb': 17.113834381103516}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:51:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'ptb': 17.083410263061523}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 21:52:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'ptb': 17.143571853637695}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 22:04:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.694482803344727, 'ptb': 17.143571853637695, 'c4': 14.84439468383789}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 22:04:14 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.686080932617188, 'ptb': 17.083410263061523, 'c4': 14.822439193725586}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-26 13:40:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.698070526123047, 'ptb': 17.087858200073242, 'c4': 14.789031982421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-26 13:41:43 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'ptb': 17.087858200073242}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-26 15:11:22 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.686080932617188, 'ptb': 17.083410263061523, 'c4': 14.822439193725586}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-26 15:12:10 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.694173812866211, 'ptb': 17.138364791870117, 'c4': 14.831092834472656}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-26 20:13:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.784444808959961, 'ptb': 17.308805465698242, 'c4': 14.91395378112793}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-26 20:23:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.75477409362793, 'ptb': 17.314064025878906, 'c4': 14.94074535369873}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 08:47:58 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.784444808959961, 'ptb': 17.308805465698242, 'c4': 14.91395378112793}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 08:50:09 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.788676261901855, 'ptb': 17.338130950927734, 'c4': 14.902010917663574}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 09:18:54 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.802605628967285, 'ptb': 17.372026443481445, 'c4': 14.958595275878906}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 09:53:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': nan, 'ptb': nan, 'c4': nan}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 10:05:51 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.770940780639648, 'ptb': 17.290035247802734, 'c4': 14.920639038085938}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 10:11:39 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.829891204833984, 'ptb': 17.29979133605957, 'c4': 14.902464866638184}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 10:22:17 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.829477310180664, 'ptb': 17.302047729492188, 'c4': 14.9016695022583}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 10:28:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.84034252166748, 'ptb': 17.29078483581543, 'c4': 14.90559196472168}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 10:42:08 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.862096786499023, 'ptb': 17.37805938720703, 'c4': 14.951977729797363}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 10:47:45 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.862096786499023, 'ptb': 17.37805938720703, 'c4': 14.951977729797363}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 11:05:12 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.872157096862793, 'ptb': 17.377304077148438, 'c4': 14.950750350952148}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 11:05:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.885753631591797, 'ptb': 17.372026443481445, 'c4': 14.955598831176758}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 11:07:19 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.86479377746582, 'ptb': 17.380321502685547, 'c4': 14.952489852905273}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 11:28:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.771869659423828, 'ptb': 17.272785186767578, 'c4': 14.893741607666016}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 11:28:40 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.815726280212402, 'ptb': 17.3005428314209, 'c4': 14.90559196472168}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 11:37:26 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.791665077209473, 'ptb': 17.28403091430664, 'c4': 14.891667366027832}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 11:48:03 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.750761032104492, 'ptb': 17.26678466796875, 'c4': 14.884881019592285}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 11:58:42 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.750761032104492, 'ptb': 17.26678466796875, 'c4': 14.884881019592285}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 12:09:01 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.718487739562988, 'ptb': 17.353940963745117, 'c4': 14.94764232635498}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 12:28:50 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.729578971862793, 'ptb': 17.34640884399414, 'c4': 14.938521385192871}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 12:41:26 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.701250076293945, 'ptb': 17.3005428314209, 'c4': 14.918191909790039}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 12:41:26 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.678092956542969, 'ptb': 17.393905639648438, 'c4': 14.961905479431152}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 16:41:56 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.624336242675781, 'ptb': 16.962238311767578, 'c4': 14.721122741699219}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 16:45:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 17.87666130065918, 'ptb': 23.89776039123535, 'c4': 16.766033172607422}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-12-03 16:48:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a8 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 64 2023-12-03 17:09:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 15.629434585571289, 'ptb': 18.24527931213379, 'c4': 15.778464317321777}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-12-03 17:23:05 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.467819213867188, 'ptb': 21.106182098388672, 'c4': 17.839452743530273}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-12-03 17:45:25 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 334.5755920410156, 'ptb': 315.50250244140625, 'c4': 209.76129150390625}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-12-03 18:03:55 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.43358039855957, 'ptb': 21.0357666015625, 'c4': 17.611249923706055}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-12-03 18:17:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.399539947509766, 'ptb': 21.091529846191406, 'c4': 17.66063117980957}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-12-03 18:34:57 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 343.0646057128906, 'ptb': 304.2070617675781, 'c4': 185.57749938964844}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-12-03 18:44:47 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.43358039855957, 'ptb': 21.0357666015625, 'c4': 17.611249923706055}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-12-03 18:55:52 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=1, R3_clusters=1, R4_clusters=32, R5_clusters=128, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.615907669067383, 'ptb': 21.478607177734375, 'c4': 17.945966720581055}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-12-03 19:05:38 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=1, R3_clusters=1, R4_clusters=32, R5_clusters=128, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.65243148803711, 'ptb': 21.529003143310547, 'c4': 17.829113006591797}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-12-03 19:23:33 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 16.96736717224121, 'ptb': 19.33116912841797, 'c4': 16.603572845458984}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-12-03 19:30:06 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-1.3b') 
 w4a4 {'wikitext2': 14.6225004196167, 'ptb': 16.95929527282715, 'c4': 14.720672607421875}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-12-04 11:21:12 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.399539947509766, 'ptb': 21.091529846191406, 'c4': 17.66063117980957}

main.py opt-1.3b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-12-04 12:04:07 
 Namespace(net='opt-1.3b', cache_dir='./data/opt/1.3b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, group_size=64, batch_size=1, model='facebook/opt-1.3b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 18.43358039855957, 'ptb': 21.0357666015625, 'c4': 17.611249923706055}

