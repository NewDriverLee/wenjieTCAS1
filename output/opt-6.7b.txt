main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:29:40 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'ptb': 1.0649104118347168}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:30:28 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'ptb': 1.0649104118347168}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:32:16 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:33:21 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:35:44 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:37:28 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:41:42 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:45:19 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:48:22 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:49:52 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:50:36 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:53:21 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 13:57:54 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 14:08:43 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 14:10:23 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 10.860910415649414}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-08-22 14:37:29 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 10.860910415649414, 'ptb': 13.088074684143066, 'c4': 11.742748260498047, 'results': {'piqa': {'acc': 0.7622415669205659, 'acc_stderr': 0.009932525779525489, 'acc_norm': 0.764417845484222, 'acc_norm_stderr': 0.009901067586473886}, 'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}, 'arc_easy': {'acc': 0.6557239057239057, 'acc_stderr': 0.009749495321590819, 'acc_norm': 0.601010101010101, 'acc_norm_stderr': 0.010048240683798742}, 'arc_challenge': {'acc': 0.3046075085324232, 'acc_stderr': 0.013449522109932489, 'acc_norm': 0.3464163822525597, 'acc_norm_stderr': 0.01390501118006325}, 'openbookqa': {'acc': 0.276, 'acc_stderr': 0.020011219298073524, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}, 'boolq': {'acc': 0.6617737003058104, 'acc_stderr': 0.008274675638686668}}, 'versions': {'piqa': 0, 'lambada_openai': 0, 'arc_easy': 0, 'arc_challenge': 0, 'openbookqa': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7ef9f8a35fd0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 14:56:33 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7050190ee0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 15:17:51 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f55e6d61fa0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 15:24:09 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fe03c643e80>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 15:29:55 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f46ef474fa0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 15:35:50 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f4e3d0cffa0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 15:41:54 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f5285e9fe80>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 15:47:35 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f9cc2fa0e80>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 15:56:12 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f24042f4f10>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 16:01:47 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fd9f6bdefa0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 16:08:56 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f2b297ccf70>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 16:16:49 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f94319bde80>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-22 16:22:24 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252769685396974, 'ppl_stderr': 0.09272321806648938, 'acc': 0.676693188433922, 'acc_stderr': 0.0065165150497071425}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f07fb55df70>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-23 10:06:10 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 1.5405336867828523, 'ppl_stderr': 0.156659286673574, 'acc': 1.0, 'acc_stderr': 0.0}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fb335e02040>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-23 10:08:29 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 1.5405336867828523, 'ppl_stderr': 0.156659286673574, 'acc': 1.0, 'acc_stderr': 0.0}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fd8778cb040>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-08-23 10:17:54 
 Namespace(R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', w_quantizer='gptq', wbits=4) 
 w4a4 {'results': {'lambada_openai': {'ppl': 1.7258424913399228, 'ppl_stderr': 0.5245028944702435, 'acc': 1.0, 'acc_stderr': 0.0}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f31ae84ef10>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks boolq --multigpu 2023-08-23 15:58:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'wikitext2': 10.859848976135254}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 12:58:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'wikitext2': 10.859848976135254, 'ptb': 13.086371421813965, 'c4': 11.742904663085938}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 13:24:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.944613456726074, 'ptb': 15.256416320800781, 'c4': 12.827728271484375}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 13:46:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.239805221557617, 'ptb': 13.418816566467285, 'c4': 12.111367225646973}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 14:09:44 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 51.54270553588867, 'ptb': 94.59136962890625, 'c4': 105.79899597167969}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 14:42:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0157194137573242}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 14:47:05 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0157194137573242}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 14:50:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0157194137573242}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 14:55:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156910419464111}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 14:58:27 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156910419464111}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 15:00:43 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156910419464111}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 15:02:35 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156910419464111}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 15:05:56 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156910419464111}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 15:09:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0157052278518677}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 15:11:05 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.015804409980774}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 15:12:54 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0157194137573242}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 15:16:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.015804409980774}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 15:39:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1240.0850830078125, 'ptb': 976.1282958984375, 'c4': 1146.2493896484375}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 16:01:40 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 51.54270553588867, 'ptb': 94.59136962890625, 'c4': 105.79899597167969}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 16:08:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 10.952587127685547, 'ptb': 13.565802574157715, 'c4': 12.490152359008789}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 16:10:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.015662670135498, 'ptb': 1.065696358680725, 'c4': 1.0089586973190308}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 16:16:05 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 10.926260948181152, 'ptb': 13.407755851745605, 'c4': 12.327790260314941}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 16:38:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 22.17643928527832, 'ptb': 27.983003616333008, 'c4': 26.041595458984375}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 17:15:58 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1240.0850830078125, 'ptb': 976.1282958984375, 'c4': 1146.2493896484375}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 18:13:20 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 27.40049171447754, 'ptb': 34.79368209838867, 'c4': 44.60950469970703}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 18:37:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 20.163307189941406, 'ptb': 26.26706886291504, 'c4': 31.176090240478516}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 19:01:35 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 31.0306339263916, 'ptb': 44.7419548034668, 'c4': 42.132442474365234}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 19:24:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 19.720834732055664, 'ptb': 25.515331268310547, 'c4': 30.60494613647461}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 19:48:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 19.595638275146484, 'ptb': 25.51201057434082, 'c4': 30.335458755493164}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 20:11:20 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 20.163307189941406, 'ptb': 26.26706886291504, 'c4': 31.176090240478516}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 20:33:40 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 53.6542854309082, 'ptb': 79.48470306396484, 'c4': 98.30901336669922}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 20:56:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 17.85846710205078, 'ptb': 25.55190658569336, 'c4': 29.33754539489746}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-08-31 21:19:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 14.321682929992676, 'ptb': 17.55698013305664, 'c4': 15.500308990478516}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 09:14:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 13.497779846191406, 'ptb': 16.54631233215332, 'c4': 14.43886947631836}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 09:37:46 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 13.510684967041016, 'ptb': 16.52191162109375, 'c4': 14.403303146362305}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 10:01:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 13.462516784667969, 'ptb': 16.51474380493164, 'c4': 14.311101913452148}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 10:26:23 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 13.49100112915039, 'ptb': 16.56499481201172, 'c4': 14.444929122924805}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 10:49:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 213.32286071777344, 'ptb': 247.27566528320312, 'c4': 205.14776611328125}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 11:11:53 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 13.501262664794922, 'ptb': 16.49755096435547, 'c4': 14.40223217010498}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 11:35:53 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.48897933959961, 'ptb': 15.100939750671387, 'c4': 13.345011711120605}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 12:04:01 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=40, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 13.008151054382324, 'ptb': 15.848333358764648, 'c4': 13.823518753051758}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 12:27:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.919351577758789, 'ptb': 15.654179573059082, 'c4': 13.733613967895508}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 12:57:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=160, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.846112251281738, 'ptb': 15.55799674987793, 'c4': 13.642601013183594}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 13:21:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=160, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.846112251281738, 'ptb': 15.55799674987793, 'c4': 13.642601013183594}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 14:03:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.78630542755127, 'ptb': 15.457036018371582, 'c4': 13.571334838867188}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 14:26:14 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=4, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.772222518920898, 'ptb': 15.432901382446289, 'c4': 13.526445388793945}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 14:49:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.790765762329102, 'ptb': 15.444964408874512, 'c4': 13.567710876464844}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 15:13:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.78630542755127, 'ptb': 15.457036018371582, 'c4': 13.571334838867188}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 15:38:31 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.421646118164062, 'ptb': 14.995134353637695, 'c4': 13.32857894897461}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 16:01:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.58579158782959, 'ptb': 15.218716621398926, 'c4': 13.425867080688477}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 16:25:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.588249206542969, 'ptb': 15.170576095581055, 'c4': 13.461740493774414}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 16:47:51 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.42398738861084, 'ptb': 14.683416366577148, 'c4': 12.937068939208984}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 17:15:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.82283878326416, 'ptb': 15.453012466430664, 'c4': 13.576796531677246}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 17:56:28 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.82283878326416, 'ptb': 15.453012466430664, 'c4': 13.576796531677246}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 18:18:58 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.428146362304688, 'ptb': 14.62807846069336, 'c4': 12.960927963256836}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 18:42:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.265117645263672, 'ptb': 14.472723960876465, 'c4': 12.833332061767578}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 19:05:46 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=160, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.457135200500488, 'ptb': 14.641417503356934, 'c4': 12.95996379852295}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 19:36:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, topk_num_q_proj_head=2, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.386430740356445, 'ptb': 14.596365928649902, 'c4': 12.91781234741211}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 19:59:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, topk_num_q_proj_head=4, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.410561561584473, 'ptb': 14.589400291442871, 'c4': 12.92518138885498}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 20:22:01 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.375205039978027, 'ptb': 14.54577350616455, 'c4': 12.897107124328613}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai --multigpu 2023-09-01 21:27:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.375205039978027, 'ptb': 14.54577350616455, 'c4': 12.897107124328613, 'results': {'lambada_openai': {'ppl': 5.838805755776536, 'ppl_stderr': 0.13500156596259222, 'acc': 0.6116825150397827, 'acc_stderr': 0.006789981313755395}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7370ef5f60>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-02 12:25:28 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.375205039978027, 'ptb': 14.54577350616455, 'c4': 12.897107124328613, 'results': {'lambada_openai': {'ppl': 5.838805755776536, 'ppl_stderr': 0.13500156596259222, 'acc': 0.6116825150397827, 'acc_stderr': 0.006789981313755395}, 'arc_challenge': {'acc': 0.295221843003413, 'acc_stderr': 0.013329750293382316, 'acc_norm': 0.31569965870307165, 'acc_norm_stderr': 0.013582571095815288}, 'arc_easy': {'acc': 0.622895622895623, 'acc_stderr': 0.009945041946366508, 'acc_norm': 0.5593434343434344, 'acc_norm_stderr': 0.010187264635711995}, 'openbookqa': {'acc': 0.248, 'acc_stderr': 0.019332342821239103, 'acc_norm': 0.368, 'acc_norm_stderr': 0.02158898256835354}, 'piqa': {'acc': 0.7448313384113167, 'acc_stderr': 0.010171571592521822, 'acc_norm': 0.750272034820457, 'acc_norm_stderr': 0.010099232969867469}, 'boolq': {'acc': 0.6067278287461774, 'acc_stderr': 0.00854350553741787}}, 'versions': {'lambada_openai': 0, 'arc_challenge': 0, 'arc_easy': 0, 'openbookqa': 0, 'piqa': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f96edfb1ed0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-02 13:09:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'wikitext2': 10.859848976135254, 'ptb': 13.086371421813965, 'c4': 11.742904663085938, 'results': {'arc_challenge': {'acc': 0.3054607508532423, 'acc_stderr': 0.0134600804780025, 'acc_norm': 0.3464163822525597, 'acc_norm_stderr': 0.01390501118006325}, 'arc_easy': {'acc': 0.6561447811447811, 'acc_stderr': 0.009746660584852457, 'acc_norm': 0.6005892255892256, 'acc_norm_stderr': 0.010050018228742125}, 'openbookqa': {'acc': 0.276, 'acc_stderr': 0.020011219298073524, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}, 'piqa': {'acc': 0.7622415669205659, 'acc_stderr': 0.009932525779525489, 'acc_norm': 0.76550598476605, 'acc_norm_stderr': 0.00988520314324054}, 'boolq': {'acc': 0.6605504587155964, 'acc_stderr': 0.008281960446071344}}, 'versions': {'arc_challenge': 0, 'arc_easy': 0, 'openbookqa': 0, 'lambada_openai': 0, 'piqa': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7fac419c3400>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-02 14:33:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=80, topk_num_final_layer_norm=80, topk_num_fc2=80, topk_num_out_proj_head=2, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.944613456726074, 'ptb': 15.256416320800781, 'c4': 12.827728271484375, 'results': {'boolq': {'acc': 0.6376146788990825, 'acc_stderr': 0.00840730865586404}, 'arc_challenge': {'acc': 0.30887372013651876, 'acc_stderr': 0.013501770929344003, 'acc_norm': 0.3361774744027304, 'acc_norm_stderr': 0.013804855026205761}, 'openbookqa': {'acc': 0.24, 'acc_stderr': 0.019118866653759756, 'acc_norm': 0.382, 'acc_norm_stderr': 0.02175082059125084}, 'arc_easy': {'acc': 0.6317340067340067, 'acc_stderr': 0.009897286209010892, 'acc_norm': 0.5845959595959596, 'acc_norm_stderr': 0.010111869494911517}, 'lambada_openai': {'ppl': 4.739096913378005, 'ppl_stderr': 0.1058389383845084, 'acc': 0.6543760915971278, 'acc_stderr': 0.00662563752855394}, 'piqa': {'acc': 0.749727965179543, 'acc_stderr': 0.010106561880089788, 'acc_norm': 0.750816104461371, 'acc_norm_stderr': 0.01009188277012021}}, 'versions': {'boolq': 1, 'arc_challenge': 0, 'openbookqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fc818f69f30>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-02 17:01:13 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=160, topk_num_final_layer_norm=160, topk_num_fc2=160, topk_num_out_proj_head=2, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.33495807647705, 'ptb': 14.497869491577148, 'c4': 12.84927749633789, 'results': {'openbookqa': {'acc': 0.276, 'acc_stderr': 0.020011219298073528, 'acc_norm': 0.36, 'acc_norm_stderr': 0.02148775108972053}, 'lambada_openai': {'ppl': 5.876086699287313, 'ppl_stderr': 0.13758883149808243, 'acc': 0.6095478362119154, 'acc_stderr': 0.006796727947203368}, 'arc_challenge': {'acc': 0.30204778156996587, 'acc_stderr': 0.01341751914471641, 'acc_norm': 0.3267918088737201, 'acc_norm_stderr': 0.013706665975587333}, 'boolq': {'acc': 0.6058103975535168, 'acc_stderr': 0.008546995661233635}, 'arc_easy': {'acc': 0.6384680134680135, 'acc_stderr': 0.009858506543162058, 'acc_norm': 0.569023569023569, 'acc_norm_stderr': 0.010161552863493748}, 'piqa': {'acc': 0.7448313384113167, 'acc_stderr': 0.01017157159252182, 'acc_norm': 0.750272034820457, 'acc_norm_stderr': 0.010099232969867467}}, 'versions': {'openbookqa': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7efea4f4cd60>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-02 18:28:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=160, topk_num_final_layer_norm=160, topk_num_fc2=160, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.277185440063477, 'ptb': 14.488435745239258, 'c4': 12.820560455322266, 'results': {'lambada_openai': {'ppl': 5.785212706842214, 'ppl_stderr': 0.13451239735944845, 'acc': 0.6149815641373957, 'acc_stderr': 0.006779284873671319}, 'arc_easy': {'acc': 0.6372053872053872, 'acc_stderr': 0.00986593675701394, 'acc_norm': 0.5744949494949495, 'acc_norm_stderr': 0.010145271182591021}, 'openbookqa': {'acc': 0.268, 'acc_stderr': 0.019827714859587564, 'acc_norm': 0.362, 'acc_norm_stderr': 0.021513662527582408}, 'piqa': {'acc': 0.736126224156692, 'acc_stderr': 0.010282996367695562, 'acc_norm': 0.7459194776931447, 'acc_norm_stderr': 0.010157271999135051}, 'arc_challenge': {'acc': 0.302901023890785, 'acc_stderr': 0.013428241573185349, 'acc_norm': 0.33276450511945393, 'acc_norm_stderr': 0.013769863046192305}, 'boolq': {'acc': 0.6207951070336392, 'acc_stderr': 0.00848601213724629}}, 'versions': {'lambada_openai': 0, 'arc_easy': 0, 'openbookqa': 0, 'piqa': 0, 'arc_challenge': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f5b56b85e70>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-02 19:57:38 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=320, topk_num_final_layer_norm=320, topk_num_fc2=320, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.168055534362793, 'ptb': 14.403791427612305, 'c4': 12.762420654296875, 'results': {'arc_challenge': {'acc': 0.29948805460750855, 'acc_stderr': 0.013385021637313574, 'acc_norm': 0.3225255972696246, 'acc_norm_stderr': 0.013659980894277376}, 'arc_easy': {'acc': 0.6393097643097643, 'acc_stderr': 0.009853512108416734, 'acc_norm': 0.5732323232323232, 'acc_norm_stderr': 0.010149141043955628}, 'piqa': {'acc': 0.7431991294885746, 'acc_stderr': 0.010192864802278039, 'acc_norm': 0.7519042437431991, 'acc_norm_stderr': 0.010077118315574706}, 'boolq': {'acc': 0.5847094801223242, 'acc_stderr': 0.008618637526341674}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.01987435483128748, 'acc_norm': 0.38, 'acc_norm_stderr': 0.021728881438701702}, 'lambada_openai': {'ppl': 5.5793080391524965, 'ppl_stderr': 0.12860296533617174, 'acc': 0.6202212303512517, 'acc_stderr': 0.006761619510377174}}, 'versions': {'arc_challenge': 0, 'arc_easy': 0, 'piqa': 0, 'boolq': 1, 'openbookqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7efa0f751f60>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-02 21:37:56 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=400, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.157535552978516, 'ptb': 14.365705490112305, 'c4': 12.75650691986084, 'results': {'arc_challenge': {'acc': 0.2883959044368601, 'acc_stderr': 0.013238394422428182, 'acc_norm': 0.31399317406143346, 'acc_norm_stderr': 0.013562691224726293}, 'boolq': {'acc': 0.6097859327217126, 'acc_stderr': 0.008531643526263242}, 'openbookqa': {'acc': 0.258, 'acc_stderr': 0.019586711785215837, 'acc_norm': 0.368, 'acc_norm_stderr': 0.021588982568353544}, 'arc_easy': {'acc': 0.6287878787878788, 'acc_stderr': 0.00991359900184574, 'acc_norm': 0.5601851851851852, 'acc_norm_stderr': 0.010185185185185316}, 'lambada_openai': {'ppl': 5.585002379999608, 'ppl_stderr': 0.1295867174945646, 'acc': 0.6178924898117601, 'acc_stderr': 0.006769573656693382}, 'piqa': {'acc': 0.750816104461371, 'acc_stderr': 0.010091882770120218, 'acc_norm': 0.7589771490750816, 'acc_norm_stderr': 0.009979042717267314}}, 'versions': {'arc_challenge': 0, 'boolq': 1, 'openbookqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f667f011ea0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-02 23:06:41 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.087435722351074, 'ptb': 14.232893943786621, 'c4': 12.68819808959961, 'results': {'lambada_openai': {'ppl': 5.50461163715251, 'ppl_stderr': 0.12682707162149967, 'acc': 0.6221618474674947, 'acc_stderr': 0.006754864865012911}, 'openbookqa': {'acc': 0.268, 'acc_stderr': 0.019827714859587568, 'acc_norm': 0.368, 'acc_norm_stderr': 0.02158898256835354}, 'boolq': {'acc': 0.6235474006116208, 'acc_stderr': 0.00847388227919459}, 'piqa': {'acc': 0.7475516866158868, 'acc_stderr': 0.010135665547362368, 'acc_norm': 0.7486398258977149, 'acc_norm_stderr': 0.010121156016819252}, 'arc_challenge': {'acc': 0.2858361774744027, 'acc_stderr': 0.01320319608853737, 'acc_norm': 0.3250853242320819, 'acc_norm_stderr': 0.013688147309729122}, 'arc_easy': {'acc': 0.6393097643097643, 'acc_stderr': 0.009853512108416727, 'acc_norm': 0.5669191919191919, 'acc_norm_stderr': 0.010167478013701792}}, 'versions': {'lambada_openai': 0, 'openbookqa': 0, 'boolq': 1, 'piqa': 0, 'arc_challenge': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f1575e8dea0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 10:11:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.274276733398438, 'ptb': 14.566619873046875, 'c4': 12.953784942626953, 'results': {'arc_challenge': {'acc': 0.2901023890784983, 'acc_stderr': 0.013261573677520759, 'acc_norm': 0.3319112627986348, 'acc_norm_stderr': 0.013760988200880534}, 'openbookqa': {'acc': 0.26, 'acc_stderr': 0.019635965529725512, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}, 'boolq': {'acc': 0.6180428134556575, 'acc_stderr': 0.00849785199842719}, 'piqa': {'acc': 0.7475516866158868, 'acc_stderr': 0.01013566554736237, 'acc_norm': 0.7524483133841132, 'acc_norm_stderr': 0.010069703966857116}, 'lambada_openai': {'ppl': 6.060064432584254, 'ppl_stderr': 0.14511167090889057, 'acc': 0.6050844168445566, 'acc_stderr': 0.006810393291223519}, 'arc_easy': {'acc': 0.625, 'acc_stderr': 0.009933992677987828, 'acc_norm': 0.5593434343434344, 'acc_norm_stderr': 0.010187264635711993}}, 'versions': {'arc_challenge': 0, 'openbookqa': 0, 'boolq': 1, 'piqa': 0, 'lambada_openai': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fe5c3f42170>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 10:12:44 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.127300262451172, 'ptb': 14.428194046020508, 'c4': 12.80374813079834, 'results': {'arc_challenge': {'acc': 0.2832764505119454, 'acc_stderr': 0.013167478735134576, 'acc_norm': 0.3242320819112628, 'acc_norm_stderr': 0.01367881039951882}, 'piqa': {'acc': 0.749183895538629, 'acc_stderr': 0.010113869547069044, 'acc_norm': 0.7584330794341676, 'acc_norm_stderr': 0.009986718001804451}, 'arc_easy': {'acc': 0.6308922558922558, 'acc_stderr': 0.009901987410242738, 'acc_norm': 0.5635521885521886, 'acc_norm_stderr': 0.010176569980111044}, 'lambada_openai': {'ppl': 5.613716544745028, 'ppl_stderr': 0.12932699937179268, 'acc': 0.6237143411604891, 'acc_stderr': 0.006749378304002007}, 'boolq': {'acc': 0.5896024464831804, 'acc_stderr': 0.008603488048617524}, 'openbookqa': {'acc': 0.262, 'acc_stderr': 0.01968468882019471, 'acc_norm': 0.366, 'acc_norm_stderr': 0.02156427685020161}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'boolq': 1, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f95d8d721a0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 11:41:51 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.823256492614746, 'ptb': 14.025008201599121, 'c4': 12.534708976745605, 'results': {'lambada_openai': {'ppl': 5.2014353588815805, 'ppl_stderr': 0.11826485929842605, 'acc': 0.6371045992625655, 'acc_stderr': 0.0066989721919110635}, 'arc_easy': {'acc': 0.6363636363636364, 'acc_stderr': 0.009870849346011769, 'acc_norm': 0.5648148148148148, 'acc_norm_stderr': 0.010173216430370917}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.019874354831287473, 'acc_norm': 0.366, 'acc_norm_stderr': 0.021564276850201614}, 'piqa': {'acc': 0.750272034820457, 'acc_stderr': 0.010099232969867485, 'acc_norm': 0.7562568008705114, 'acc_norm_stderr': 0.010017199471500609}, 'boolq': {'acc': 0.6152905198776758, 'acc_stderr': 0.00850940307322969}, 'arc_challenge': {'acc': 0.29692832764505117, 'acc_stderr': 0.013352025976725223, 'acc_norm': 0.3319112627986348, 'acc_norm_stderr': 0.013760988200880536}}, 'versions': {'lambada_openai': 0, 'arc_easy': 0, 'openbookqa': 0, 'piqa': 0, 'boolq': 1, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f0b4f7b2320>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 11:43:28 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.793109893798828, 'ptb': 13.914656639099121, 'c4': 12.453210830688477, 'results': {'boolq': {'acc': 0.6293577981651376, 'acc_stderr': 0.008447316806409932}, 'arc_easy': {'acc': 0.6359427609427609, 'acc_stderr': 0.009873293392779117, 'acc_norm': 0.5732323232323232, 'acc_norm_stderr': 0.010149141043955628}, 'piqa': {'acc': 0.749183895538629, 'acc_stderr': 0.010113869547069044, 'acc_norm': 0.7578890097932536, 'acc_norm_stderr': 0.009994371269104402}, 'lambada_openai': {'ppl': 4.865509138511997, 'ppl_stderr': 0.11180078388403711, 'acc': 0.6499126722297691, 'acc_stderr': 0.006645501658657035}, 'arc_challenge': {'acc': 0.30204778156996587, 'acc_stderr': 0.013417519144716417, 'acc_norm': 0.3293515358361775, 'acc_norm_stderr': 0.013734057652635474}, 'openbookqa': {'acc': 0.266, 'acc_stderr': 0.019780559675655493, 'acc_norm': 0.362, 'acc_norm_stderr': 0.021513662527582404}}, 'versions': {'boolq': 1, 'arc_easy': 0, 'piqa': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f3bdaabe350>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 13:18:35 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.988518714904785, 'ptb': 14.16817569732666, 'c4': 12.616092681884766, 'results': {'arc_easy': {'acc': 0.6422558922558923, 'acc_stderr': 0.009835772757343361, 'acc_norm': 0.5702861952861953, 'acc_norm_stderr': 0.010157908005763674}, 'openbookqa': {'acc': 0.26, 'acc_stderr': 0.019635965529725512, 'acc_norm': 0.378, 'acc_norm_stderr': 0.021706550824518184}, 'lambada_openai': {'ppl': 5.38807799802554, 'ppl_stderr': 0.12350806094680093, 'acc': 0.6266252668348535, 'acc_stderr': 0.0067388918519784855}, 'piqa': {'acc': 0.7524483133841132, 'acc_stderr': 0.010069703966857106, 'acc_norm': 0.7524483133841132, 'acc_norm_stderr': 0.010069703966857118}, 'boolq': {'acc': 0.5926605504587156, 'acc_stderr': 0.008593573302607044}, 'arc_challenge': {'acc': 0.28668941979522183, 'acc_stderr': 0.013214986329274783, 'acc_norm': 0.3302047781569966, 'acc_norm_stderr': 0.013743085603760427}}, 'versions': {'arc_easy': 0, 'openbookqa': 0, 'lambada_openai': 0, 'piqa': 0, 'boolq': 1, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f626bfde2c0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 13:18:38 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.135847091674805, 'ptb': 14.258240699768066, 'c4': 12.689408302307129, 'results': {'piqa': {'acc': 0.7513601741022851, 'acc_stderr': 0.010084511234296852, 'acc_norm': 0.749727965179543, 'acc_norm_stderr': 0.010106561880089768}, 'openbookqa': {'acc': 0.252, 'acc_stderr': 0.019435727282249536, 'acc_norm': 0.388, 'acc_norm_stderr': 0.02181430098478763}, 'arc_easy': {'acc': 0.6338383838383839, 'acc_stderr': 0.009885391390947724, 'acc_norm': 0.5686026936026936, 'acc_norm_stderr': 0.010162752847747503}, 'arc_challenge': {'acc': 0.2986348122866894, 'acc_stderr': 0.013374078615068742, 'acc_norm': 0.3319112627986348, 'acc_norm_stderr': 0.013760988200880534}, 'lambada_openai': {'ppl': 5.452141626712152, 'ppl_stderr': 0.12588414174006013, 'acc': 0.6299243159324666, 'acc_stderr': 0.006726691873834145}, 'boolq': {'acc': 0.627217125382263, 'acc_stderr': 0.008457255867914695}}, 'versions': {'piqa': 0, 'openbookqa': 0, 'arc_easy': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f211fa66260>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 14:25:57 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.185681343078613, 'ptb': 13.371726036071777, 'c4': 12.074923515319824, 'results': {'piqa': {'acc': 0.7568008705114254, 'acc_stderr': 0.010009611953858924, 'acc_norm': 0.7633297062023939, 'acc_norm_stderr': 0.009916841655042809}, 'openbookqa': {'acc': 0.268, 'acc_stderr': 0.01982771485958757, 'acc_norm': 0.348, 'acc_norm_stderr': 0.021323728632807504}, 'boolq': {'acc': 0.6116207951070336, 'acc_stderr': 0.008524357307908789}, 'lambada_openai': {'ppl': 4.562188687410534, 'ppl_stderr': 0.10174024402266398, 'acc': 0.6710653987968174, 'acc_stderr': 0.006545597195850556}, 'arc_easy': {'acc': 0.6418350168350169, 'acc_stderr': 0.009838331651451844, 'acc_norm': 0.5824915824915825, 'acc_norm_stderr': 0.010119187377776043}, 'arc_challenge': {'acc': 0.3097269624573379, 'acc_stderr': 0.01351205841523836, 'acc_norm': 0.3506825938566553, 'acc_norm_stderr': 0.013944635930726083}}, 'versions': {'piqa': 0, 'openbookqa': 0, 'boolq': 1, 'lambada_openai': 0, 'arc_easy': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f1ec206f220>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 14:31:25 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.598052024841309, 'ptb': 13.774051666259766, 'c4': 12.391393661499023, 'results': {'arc_easy': {'acc': 0.6245791245791246, 'acc_stderr': 0.009936218527114302, 'acc_norm': 0.5707070707070707, 'acc_norm_stderr': 0.01015667807591109}, 'lambada_openai': {'ppl': 4.8665627270768175, 'ppl_stderr': 0.11130690477427217, 'acc': 0.6512711042111391, 'acc_stderr': 0.0066395239985089895}, 'piqa': {'acc': 0.7562568008705114, 'acc_stderr': 0.010017199471500622, 'acc_norm': 0.764961915125136, 'acc_norm_stderr': 0.009893146688805308}, 'boolq': {'acc': 0.5938837920489297, 'acc_stderr': 0.008589510943787407}, 'openbookqa': {'acc': 0.266, 'acc_stderr': 0.019780559675655493, 'acc_norm': 0.366, 'acc_norm_stderr': 0.021564276850201614}, 'arc_challenge': {'acc': 0.2977815699658703, 'acc_stderr': 0.013363080107244489, 'acc_norm': 0.33361774744027306, 'acc_norm_stderr': 0.013778687054176541}}, 'versions': {'arc_easy': 0, 'lambada_openai': 0, 'piqa': 0, 'boolq': 1, 'openbookqa': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f9d9fc4a980>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 15:03:46 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156059265136719}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 15:10:54 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156059265136719}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-09-03 15:20:50 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156059265136719}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-09-03 15:23:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156059265136719}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq 2023-09-03 15:25:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0156059265136719}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 15:53:20 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.259817123413086, 'ptb': 13.468998908996582, 'c4': 12.134605407714844, 'results': {'arc_easy': {'acc': 0.6468855218855218, 'acc_stderr': 0.00980707893546762, 'acc_norm': 0.5858585858585859, 'acc_norm_stderr': 0.010107387673002533}, 'arc_challenge': {'acc': 0.30204778156996587, 'acc_stderr': 0.01341751914471642, 'acc_norm': 0.3438566552901024, 'acc_norm_stderr': 0.01388064457015621}, 'piqa': {'acc': 0.7611534276387377, 'acc_stderr': 0.0099481203853375, 'acc_norm': 0.7573449401523396, 'acc_norm_stderr': 0.01000200256970869}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.01987435483128748, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'lambada_openai': {'ppl': 4.759534563843063, 'ppl_stderr': 0.10578472543044208, 'acc': 0.6615563749272269, 'acc_stderr': 0.0065923259327411565}, 'boolq': {'acc': 0.6232415902140673, 'acc_stderr': 0.00847524440049143}}, 'versions': {'arc_easy': 0, 'arc_challenge': 0, 'piqa': 0, 'openbookqa': 0, 'lambada_openai': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7ff2cf78f160>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 18:00:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 2120.313720703125, 'ptb': 2563.50830078125, 'c4': 953.0040283203125, 'results': {'lambada_openai': {'ppl': 169093.93869498183, 'ppl_stderr': 8478.328648840954, 'acc': 0.0, 'acc_stderr': 0.0}, 'arc_challenge': {'acc': 0.18771331058020477, 'acc_stderr': 0.011411001314155138, 'acc_norm': 0.22866894197952217, 'acc_norm_stderr': 0.012272853582540792}, 'piqa': {'acc': 0.5413492927094669, 'acc_stderr': 0.011625864113315804, 'acc_norm': 0.5212187159956474, 'acc_norm_stderr': 0.01165531473228886}, 'boolq': {'acc': 0.3782874617737003, 'acc_stderr': 0.008482001133931005}, 'openbookqa': {'acc': 0.11, 'acc_stderr': 0.01400686919941559, 'acc_norm': 0.28, 'acc_norm_stderr': 0.020099950647503237}, 'arc_easy': {'acc': 0.27735690235690236, 'acc_stderr': 0.009186490105111904, 'acc_norm': 0.26557239057239057, 'acc_norm_stderr': 0.009062210626971844}}, 'versions': {'lambada_openai': 0, 'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'openbookqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f8d607ce050>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 18:01:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 2120.313720703125, 'ptb': 2563.50830078125, 'c4': 953.0040283203125, 'results': {'arc_easy': {'acc': 0.27735690235690236, 'acc_stderr': 0.009186490105111904, 'acc_norm': 0.26557239057239057, 'acc_norm_stderr': 0.009062210626971844}, 'lambada_openai': {'ppl': 169093.93869498183, 'ppl_stderr': 8478.328648840954, 'acc': 0.0, 'acc_stderr': 0.0}, 'piqa': {'acc': 0.5413492927094669, 'acc_stderr': 0.011625864113315804, 'acc_norm': 0.5212187159956474, 'acc_norm_stderr': 0.01165531473228886}, 'boolq': {'acc': 0.3782874617737003, 'acc_stderr': 0.008482001133931005}, 'arc_challenge': {'acc': 0.18771331058020477, 'acc_stderr': 0.011411001314155138, 'acc_norm': 0.22866894197952217, 'acc_norm_stderr': 0.012272853582540792}, 'openbookqa': {'acc': 0.11, 'acc_stderr': 0.01400686919941559, 'acc_norm': 0.28, 'acc_norm_stderr': 0.020099950647503237}}, 'versions': {'arc_easy': 0, 'lambada_openai': 0, 'piqa': 0, 'boolq': 1, 'arc_challenge': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f4530752050>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 20:43:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.190739631652832, 'ptb': 14.385669708251953, 'c4': 12.848885536193848, 'results': {'openbookqa': {'acc': 0.26, 'acc_stderr': 0.019635965529725512, 'acc_norm': 0.378, 'acc_norm_stderr': 0.02170655082451819}, 'piqa': {'acc': 0.7486398258977149, 'acc_stderr': 0.01012115601681926, 'acc_norm': 0.7529923830250272, 'acc_norm_stderr': 0.01006226814077264}, 'lambada_openai': {'ppl': 5.786549490475111, 'ppl_stderr': 0.13463182762499407, 'acc': 0.6163399961187658, 'acc_stderr': 0.00677478491589628}, 'boolq': {'acc': 0.6018348623853211, 'acc_stderr': 0.008561755594317447}, 'arc_challenge': {'acc': 0.30204778156996587, 'acc_stderr': 0.013417519144716413, 'acc_norm': 0.3242320819112628, 'acc_norm_stderr': 0.01367881039951882}, 'arc_easy': {'acc': 0.6224747474747475, 'acc_stderr': 0.00994722783346943, 'acc_norm': 0.5656565656565656, 'acc_norm_stderr': 0.010170943451269416}}, 'versions': {'openbookqa': 0, 'piqa': 0, 'lambada_openai': 0, 'boolq': 1, 'arc_challenge': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fa236705ff0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 20:47:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.219941139221191, 'ptb': 14.333320617675781, 'c4': 12.833160400390625, 'results': {'openbookqa': {'acc': 0.27, 'acc_stderr': 0.019874354831287473, 'acc_norm': 0.386, 'acc_norm_stderr': 0.021793529219281165}, 'boolq': {'acc': 0.6253822629969419, 'acc_stderr': 0.008465633983431928}, 'piqa': {'acc': 0.750816104461371, 'acc_stderr': 0.010091882770120216, 'acc_norm': 0.7568008705114254, 'acc_norm_stderr': 0.010009611953858912}, 'arc_easy': {'acc': 0.632996632996633, 'acc_stderr': 0.009890173658452128, 'acc_norm': 0.571969696969697, 'acc_norm_stderr': 0.01015294331642626}, 'lambada_openai': {'ppl': 5.766227548096711, 'ppl_stderr': 0.13334406766975862, 'acc': 0.6157578109838929, 'acc_stderr': 0.006776720307079445}, 'arc_challenge': {'acc': 0.3003412969283277, 'acc_stderr': 0.013395909309957002, 'acc_norm': 0.3387372013651877, 'acc_norm_stderr': 0.013830568927974332}}, 'versions': {'openbookqa': 0, 'boolq': 1, 'piqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f00ed451f90>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-03 22:22:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.01095199584961, 'ptb': 14.198339462280273, 'c4': 12.65390396118164, 'results': {'arc_challenge': {'acc': 0.2986348122866894, 'acc_stderr': 0.013374078615068752, 'acc_norm': 0.3378839590443686, 'acc_norm_stderr': 0.013822047922283516}, 'boolq': {'acc': 0.6174311926605505, 'acc_stderr': 0.008500443818876165}, 'piqa': {'acc': 0.7524483133841132, 'acc_stderr': 0.010069703966857111, 'acc_norm': 0.7486398258977149, 'acc_norm_stderr': 0.010121156016819245}, 'lambada_openai': {'ppl': 5.510642266077437, 'ppl_stderr': 0.12792912405905116, 'acc': 0.620415292062876, 'acc_stderr': 0.0067609492148076695}, 'openbookqa': {'acc': 0.272, 'acc_stderr': 0.01992048320956608, 'acc_norm': 0.366, 'acc_norm_stderr': 0.021564276850201614}, 'arc_easy': {'acc': 0.6380471380471381, 'acc_stderr': 0.009860991466688483, 'acc_norm': 0.5723905723905723, 'acc_norm_stderr': 0.010151683397430673}}, 'versions': {'arc_challenge': 0, 'boolq': 1, 'piqa': 0, 'lambada_openai': 0, 'openbookqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7a66b1a050>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-04 09:43:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f29fc970df0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-04 09:57:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f84cfe90ca0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-04 10:05:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7ea6e2cd30>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-04 10:18:20 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fbc14960d00>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-04 10:29:13 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f4e2afa8d00>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-04 10:37:58 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fb294160d60>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy 2023-09-04 14:11:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f9ceadfc580>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy 2023-09-04 15:20:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f4cc7666530>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy 2023-09-04 15:51:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f0351bd2590>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy 2023-09-04 16:45:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'results': {'openbookqa': {'acc': 0.276, 'acc_stderr': 0.020011219298073524, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}}, 'versions': {'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f1b3cd62e60>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-04 18:08:13 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=False, topk_num=400, topk_num_final_layer_norm=400, topk_num_fc2=1600, topk_num_out_proj_head=32, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a4 {'wikitext2': 10.859848976135254, 'ptb': 13.086371421813965, 'c4': 11.742904663085938, 'results': {'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f51a972dbd0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-05 16:22:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.191301345825195, 'ptb': 13.847180366516113, 'c4': 12.115595817565918, 'results': {'arc_challenge': {'acc': 0.30119453924914674, 'acc_stderr': 0.013406741767847626, 'acc_norm': 0.3455631399317406, 'acc_norm_stderr': 0.013896938461145682}, 'arc_easy': {'acc': 0.6595117845117845, 'acc_stderr': 0.009723676813825872, 'acc_norm': 0.6035353535353535, 'acc_norm_stderr': 0.01003741276306453}, 'piqa': {'acc': 0.7611534276387377, 'acc_stderr': 0.0099481203853375, 'acc_norm': 0.7595212187159956, 'acc_norm_stderr': 0.009971345364651062}, 'boolq': {'acc': 0.6541284403669725, 'acc_stderr': 0.008319198402415408}, 'openbookqa': {'acc': 0.26, 'acc_stderr': 0.019635965529725512, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}, 'lambada_openai': {'ppl': 4.285234169276798, 'ppl_stderr': 0.09310059779139472, 'acc': 0.6796041141082865, 'acc_stderr': 0.006501050473455609}}, 'versions': {'arc_challenge': 0, 'arc_easy': 0, 'piqa': 0, 'boolq': 1, 'openbookqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f0c5bcf8730>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-05 16:22:04 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.243412971496582, 'ptb': 13.399031639099121, 'c4': 12.099684715270996, 'results': {'piqa': {'acc': 0.7551686615886833, 'acc_stderr': 0.010032309105568803, 'acc_norm': 0.7600652883569097, 'acc_norm_stderr': 0.009963625892809545}, 'arc_easy': {'acc': 0.6443602693602694, 'acc_stderr': 0.009822854395535487, 'acc_norm': 0.5854377104377104, 'acc_norm_stderr': 0.010108889212447786}, 'lambada_openai': {'ppl': 4.733495013014279, 'ppl_stderr': 0.10454989253677256, 'acc': 0.6568988938482437, 'acc_stderr': 0.006614124982461047}, 'arc_challenge': {'acc': 0.295221843003413, 'acc_stderr': 0.013329750293382316, 'acc_norm': 0.3455631399317406, 'acc_norm_stderr': 0.013896938461145683}, 'boolq': {'acc': 0.617737003058104, 'acc_stderr': 0.008499149690449268}, 'openbookqa': {'acc': 0.272, 'acc_stderr': 0.019920483209566076, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}}, 'versions': {'piqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'boolq': 1, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fa3658d86d0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-05 18:02:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=512, topk_num_final_layer_norm=512, topk_num_fc2=2048, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.264687538146973, 'ptb': 13.393796920776367, 'c4': 12.101161003112793, 'results': {'lambada_openai': {'ppl': 4.519160598085265, 'ppl_stderr': 0.10009915188288962, 'acc': 0.669512905103823, 'acc_stderr': 0.006553432066957563}, 'piqa': {'acc': 0.7562568008705114, 'acc_stderr': 0.01001719947150062, 'acc_norm': 0.7633297062023939, 'acc_norm_stderr': 0.009916841655042809}, 'boolq': {'acc': 0.6269113149847095, 'acc_stderr': 0.008458661252058387}, 'arc_easy': {'acc': 0.6430976430976431, 'acc_stderr': 0.009830630210347009, 'acc_norm': 0.5749158249158249, 'acc_norm_stderr': 0.010143966195717845}, 'openbookqa': {'acc': 0.28, 'acc_stderr': 0.020099950647503237, 'acc_norm': 0.376, 'acc_norm_stderr': 0.021683827539286122}, 'arc_challenge': {'acc': 0.3003412969283277, 'acc_stderr': 0.013395909309957002, 'acc_norm': 0.3361774744027304, 'acc_norm_stderr': 0.013804855026205761}}, 'versions': {'lambada_openai': 0, 'piqa': 0, 'boolq': 1, 'arc_easy': 0, 'openbookqa': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f5d013e0640>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-05 18:05:56 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.281986236572266, 'ptb': 13.410667419433594, 'c4': 12.106054306030273, 'results': {'arc_easy': {'acc': 0.6388888888888888, 'acc_stderr': 0.00985601342581124, 'acc_norm': 0.57996632996633, 'acc_norm_stderr': 0.010127718838529311}, 'lambada_openai': {'ppl': 4.6108916263537525, 'ppl_stderr': 0.10214801903932748, 'acc': 0.6654376091597128, 'acc_stderr': 0.006573615585828716}, 'arc_challenge': {'acc': 0.30631399317406144, 'acc_stderr': 0.013470584417276511, 'acc_norm': 0.3370307167235495, 'acc_norm_stderr': 0.01381347665290227}, 'boolq': {'acc': 0.6152905198776758, 'acc_stderr': 0.00850940307322969}, 'piqa': {'acc': 0.7633297062023939, 'acc_stderr': 0.009916841655042806, 'acc_norm': 0.764417845484222, 'acc_norm_stderr': 0.009901067586473886}, 'openbookqa': {'acc': 0.272, 'acc_stderr': 0.019920483209566072, 'acc_norm': 0.376, 'acc_norm_stderr': 0.021683827539286122}}, 'versions': {'arc_easy': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'boolq': 1, 'piqa': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7d779e46d0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-05 19:05:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=512, topk_num_final_layer_norm=512, topk_num_fc2=2048, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.859848976135254, 'ptb': 13.086371421813965, 'c4': 11.742904663085938, 'results': {'arc_easy': {'acc': 0.6561447811447811, 'acc_stderr': 0.009746660584852457, 'acc_norm': 0.6005892255892256, 'acc_norm_stderr': 0.010050018228742125}, 'openbookqa': {'acc': 0.276, 'acc_stderr': 0.020011219298073524, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'boolq': {'acc': 0.6605504587155964, 'acc_stderr': 0.008281960446071344}, 'piqa': {'acc': 0.7622415669205659, 'acc_stderr': 0.009932525779525489, 'acc_norm': 0.76550598476605, 'acc_norm_stderr': 0.00988520314324054}, 'arc_challenge': {'acc': 0.3054607508532423, 'acc_stderr': 0.0134600804780025, 'acc_norm': 0.3464163822525597, 'acc_norm_stderr': 0.01390501118006325}, 'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'arc_easy': 0, 'openbookqa': 0, 'boolq': 1, 'piqa': 0, 'arc_challenge': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fa0a3e8dc60>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-05 19:47:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=512, topk_num_final_layer_norm=512, topk_num_fc2=2048, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.859848976135254, 'ptb': 13.086371421813965, 'c4': 11.742904663085938, 'results': {'piqa': {'acc': 0.7622415669205659, 'acc_stderr': 0.009932525779525489, 'acc_norm': 0.76550598476605, 'acc_norm_stderr': 0.00988520314324054}, 'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}, 'arc_challenge': {'acc': 0.3054607508532423, 'acc_stderr': 0.0134600804780025, 'acc_norm': 0.3464163822525597, 'acc_norm_stderr': 0.01390501118006325}, 'openbookqa': {'acc': 0.276, 'acc_stderr': 0.020011219298073524, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'boolq': {'acc': 0.6605504587155964, 'acc_stderr': 0.008281960446071344}, 'arc_easy': {'acc': 0.6561447811447811, 'acc_stderr': 0.009746660584852457, 'acc_norm': 0.6005892255892256, 'acc_norm_stderr': 0.010050018228742125}}, 'versions': {'piqa': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'openbookqa': 0, 'boolq': 1, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f3337139c90>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-05 20:28:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=512, topk_num_final_layer_norm=512, topk_num_fc2=2048, topk_num_out_proj_head=16, topk_num_q_proj_head=16, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.859848976135254, 'ptb': 13.086371421813965, 'c4': 11.742904663085938, 'results': {'piqa': {'acc': 0.7622415669205659, 'acc_stderr': 0.009932525779525489, 'acc_norm': 0.76550598476605, 'acc_norm_stderr': 0.00988520314324054}, 'boolq': {'acc': 0.6605504587155964, 'acc_stderr': 0.008281960446071344}, 'arc_easy': {'acc': 0.6561447811447811, 'acc_stderr': 0.009746660584852457, 'acc_norm': 0.6005892255892256, 'acc_norm_stderr': 0.010050018228742125}, 'openbookqa': {'acc': 0.276, 'acc_stderr': 0.020011219298073524, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'arc_challenge': {'acc': 0.3054607508532423, 'acc_stderr': 0.0134600804780025, 'acc_norm': 0.3464163822525597, 'acc_norm_stderr': 0.01390501118006325}, 'lambada_openai': {'ppl': 4.252710327565062, 'ppl_stderr': 0.09271854545557193, 'acc': 0.6768872501455463, 'acc_stderr': 0.0065154930732499805}}, 'versions': {'piqa': 0, 'boolq': 1, 'arc_easy': 0, 'openbookqa': 0, 'arc_challenge': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f345757dc00>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-05 22:00:48 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.073270797729492, 'ptb': 13.279190063476562, 'c4': 11.962824821472168, 'results': {'arc_challenge': {'acc': 0.3054607508532423, 'acc_stderr': 0.013460080478002501, 'acc_norm': 0.3464163822525597, 'acc_norm_stderr': 0.013905011180063254}, 'piqa': {'acc': 0.7611534276387377, 'acc_stderr': 0.0099481203853375, 'acc_norm': 0.76550598476605, 'acc_norm_stderr': 0.00988520314324054}, 'arc_easy': {'acc': 0.6477272727272727, 'acc_stderr': 0.009801753933112787, 'acc_norm': 0.5963804713804713, 'acc_norm_stderr': 0.010067368960348226}, 'lambada_openai': {'ppl': 4.071239362521113, 'ppl_stderr': 0.08889743913166577, 'acc': 0.6922181253638657, 'acc_stderr': 0.00643065301437623}, 'openbookqa': {'acc': 0.268, 'acc_stderr': 0.01982771485958757, 'acc_norm': 0.366, 'acc_norm_stderr': 0.021564276850201614}, 'boolq': {'acc': 0.673394495412844, 'acc_stderr': 0.00820236461292443}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'openbookqa': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7fcc22bd88e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-05 22:05:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=512, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.087413787841797, 'ptb': 13.295913696289062, 'c4': 11.963988304138184, 'results': {'arc_easy': {'acc': 0.6536195286195287, 'acc_stderr': 0.009763542075695741, 'acc_norm': 0.6039562289562289, 'acc_norm_stderr': 0.010035580962097933}, 'piqa': {'acc': 0.7573449401523396, 'acc_stderr': 0.010002002569708698, 'acc_norm': 0.7676822633297062, 'acc_norm_stderr': 0.009853201384168243}, 'openbookqa': {'acc': 0.276, 'acc_stderr': 0.020011219298073524, 'acc_norm': 0.376, 'acc_norm_stderr': 0.02168382753928612}, 'lambada_openai': {'ppl': 4.162481886998993, 'ppl_stderr': 0.09091404426584976, 'acc': 0.688530952843004, 'acc_stderr': 0.006451805320261254}, 'arc_challenge': {'acc': 0.3097269624573379, 'acc_stderr': 0.013512058415238361, 'acc_norm': 0.3412969283276451, 'acc_norm_stderr': 0.01385583128749772}, 'boolq': {'acc': 0.6626911314984709, 'acc_stderr': 0.00826917149574162}}, 'versions': {'arc_easy': 0, 'piqa': 0, 'openbookqa': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f57413887f0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-05 23:37:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=512, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.88187313079834, 'ptb': 14.102529525756836, 'c4': 12.582304954528809, 'results': {'arc_easy': {'acc': 0.6384680134680135, 'acc_stderr': 0.009858506543162058, 'acc_norm': 0.5787037037037037, 'acc_norm_stderr': 0.010131882498193124}, 'boolq': {'acc': 0.6477064220183486, 'acc_stderr': 0.008354760493906108}, 'lambada_openai': {'ppl': 4.860636146405371, 'ppl_stderr': 0.10967138117613251, 'acc': 0.6520473510576363, 'acc_stderr': 0.006636081541776563}, 'openbookqa': {'acc': 0.25, 'acc_stderr': 0.019384310743640384, 'acc_norm': 0.376, 'acc_norm_stderr': 0.021683827539286122}, 'piqa': {'acc': 0.750272034820457, 'acc_stderr': 0.010099232969867483, 'acc_norm': 0.7595212187159956, 'acc_norm_stderr': 0.009971345364651062}, 'arc_challenge': {'acc': 0.3054607508532423, 'acc_stderr': 0.013460080478002501, 'acc_norm': 0.3370307167235495, 'acc_norm_stderr': 0.013813476652902274}}, 'versions': {'arc_easy': 0, 'boolq': 1, 'lambada_openai': 0, 'openbookqa': 0, 'piqa': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f887cd1c880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-05 23:42:28 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.862744331359863, 'ptb': 14.04937744140625, 'c4': 12.558832168579102, 'results': {'piqa': {'acc': 0.7524483133841132, 'acc_stderr': 0.010069703966857102, 'acc_norm': 0.7595212187159956, 'acc_norm_stderr': 0.009971345364651064}, 'arc_challenge': {'acc': 0.28668941979522183, 'acc_stderr': 0.013214986329274777, 'acc_norm': 0.3250853242320819, 'acc_norm_stderr': 0.013688147309729122}, 'openbookqa': {'acc': 0.264, 'acc_stderr': 0.019732885585922098, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'boolq': {'acc': 0.6311926605504588, 'acc_stderr': 0.008438656079759072}, 'lambada_openai': {'ppl': 4.846788000089147, 'ppl_stderr': 0.10890783381755073, 'acc': 0.6528235979041335, 'acc_stderr': 0.006632619664862162}, 'arc_easy': {'acc': 0.6363636363636364, 'acc_stderr': 0.009870849346011769, 'acc_norm': 0.5820707070707071, 'acc_norm_stderr': 0.010120628211017875}}, 'versions': {'piqa': 0, 'arc_challenge': 0, 'openbookqa': 0, 'boolq': 1, 'lambada_openai': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f9534084820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-06 10:19:14 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.887676239013672, 'ptb': 14.067075729370117, 'c4': 12.540782928466797, 'results': {'boolq': {'acc': 0.6409785932721712, 'acc_stderr': 0.008390241754319898}, 'arc_easy': {'acc': 0.640993265993266, 'acc_stderr': 0.009843424713072176, 'acc_norm': 0.5774410774410774, 'acc_norm_stderr': 0.010135978222981073}, 'piqa': {'acc': 0.750272034820457, 'acc_stderr': 0.010099232969867483, 'acc_norm': 0.7573449401523396, 'acc_norm_stderr': 0.010002002569708691}, 'arc_challenge': {'acc': 0.29692832764505117, 'acc_stderr': 0.013352025976725223, 'acc_norm': 0.32849829351535836, 'acc_norm_stderr': 0.013724978465537377}, 'lambada_openai': {'ppl': 4.919715518334525, 'ppl_stderr': 0.11205606109885807, 'acc': 0.6522414127692606, 'acc_stderr': 0.006635217894374427}, 'openbookqa': {'acc': 0.254, 'acc_stderr': 0.019486596801643375, 'acc_norm': 0.366, 'acc_norm_stderr': 0.02156427685020161}}, 'versions': {'boolq': 1, 'arc_easy': 0, 'piqa': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7f51270820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-06 10:23:50 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.880049705505371, 'ptb': 14.107425689697266, 'c4': 12.578993797302246, 'results': {'openbookqa': {'acc': 0.264, 'acc_stderr': 0.019732885585922098, 'acc_norm': 0.376, 'acc_norm_stderr': 0.021683827539286122}, 'piqa': {'acc': 0.7529923830250272, 'acc_stderr': 0.010062268140772629, 'acc_norm': 0.7633297062023939, 'acc_norm_stderr': 0.009916841655042809}, 'boolq': {'acc': 0.6467889908256881, 'acc_stderr': 0.008359705247064302}, 'lambada_openai': {'ppl': 4.869142857980521, 'ppl_stderr': 0.10977300547387049, 'acc': 0.6534057830390064, 'acc_stderr': 0.0066300104943886}, 'arc_challenge': {'acc': 0.30631399317406144, 'acc_stderr': 0.013470584417276513, 'acc_norm': 0.3412969283276451, 'acc_norm_stderr': 0.01385583128749772}, 'arc_easy': {'acc': 0.6393097643097643, 'acc_stderr': 0.009853512108416725, 'acc_norm': 0.5833333333333334, 'acc_norm_stderr': 0.010116282977781256}}, 'versions': {'openbookqa': 0, 'piqa': 0, 'boolq': 1, 'lambada_openai': 0, 'arc_challenge': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fb6a2e14760>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 11:40:01 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 1.0187705755233765, 'ptb': 1.0741945505142212, 'c4': 1.009297490119934}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 11:52:08 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 10.888296127319336, 'ptb': 13.09091567993164, 'c4': 11.745368957519531}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 12:12:04 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 19.885906219482422, 'ptb': 18.026456832885742, 'c4': 14.915717124938965}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 12:24:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=128, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 357159.34375, 'ptb': 149767.671875, 'c4': 148434.328125, 'results': {'arc_challenge': {'acc': 0.2175767918088737, 'acc_stderr': 0.012057262020972502, 'acc_norm': 0.2696245733788396, 'acc_norm_stderr': 0.01296804068686916}, 'openbookqa': {'acc': 0.132, 'acc_stderr': 0.015152927850580157, 'acc_norm': 0.262, 'acc_norm_stderr': 0.019684688820194723}, 'lambada_openai': {'ppl': 2580869307.1439643, 'ppl_stderr': 312455984.3288476, 'acc': 0.0, 'acc_stderr': 0.0}, 'boolq': {'acc': 0.3782874617737003, 'acc_stderr': 0.008482001133931005}, 'arc_easy': {'acc': 0.255050505050505, 'acc_stderr': 0.008944265906130717, 'acc_norm': 0.255050505050505, 'acc_norm_stderr': 0.00894426590613071}, 'piqa': {'acc': 0.5190424374319913, 'acc_stderr': 0.011657360703051442, 'acc_norm': 0.49782372143634385, 'acc_norm_stderr': 0.011665713661738868}}, 'versions': {'arc_challenge': 0, 'openbookqa': 0, 'lambada_openai': 0, 'boolq': 1, 'arc_easy': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f2d6acc4970>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 12:59:38 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 10.878046989440918, 'ptb': 13.088074684143066, 'c4': 11.745436668395996}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 14:35:15 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.567995071411133, 'ptb': 13.799184799194336, 'c4': 12.300240516662598}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 16:17:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=256, topk_num_final_layer_norm=256, topk_num_fc2=1024, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.567995071411133, 'ptb': 13.799184799194336, 'c4': 12.300240516662598, 'results': {'boolq': {'acc': 0.6333333333333333, 'acc_stderr': 0.008428386213506838}, 'arc_easy': {'acc': 0.6414141414141414, 'acc_stderr': 0.009840882301225297, 'acc_norm': 0.5803872053872053, 'acc_norm_stderr': 0.010126315840891539}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.01987435483128748, 'acc_norm': 0.38, 'acc_norm_stderr': 0.0217288814387017}, 'arc_challenge': {'acc': 0.3037542662116041, 'acc_stderr': 0.013438909184778759, 'acc_norm': 0.3267918088737201, 'acc_norm_stderr': 0.013706665975587338}, 'piqa': {'acc': 0.7562568008705114, 'acc_stderr': 0.01001719947150062, 'acc_norm': 0.7568008705114254, 'acc_norm_stderr': 0.010009611953858914}, 'lambada_openai': {'ppl': 4.7508432545459, 'ppl_stderr': 0.10594595967720948, 'acc': 0.6541820298855036, 'acc_stderr': 0.0066265145588051974}}, 'versions': {'boolq': 1, 'arc_easy': 0, 'openbookqa': 0, 'arc_challenge': 0, 'piqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fa440f80880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 16:21:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=512, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.560412406921387, 'ptb': 13.852592468261719, 'c4': 12.319281578063965, 'results': {'lambada_openai': {'ppl': 4.726450387385076, 'ppl_stderr': 0.10487418843648348, 'acc': 0.6574810789831166, 'acc_stderr': 0.006611438859225008}, 'boolq': {'acc': 0.6278287461773701, 'acc_stderr': 0.008454434247373896}, 'arc_challenge': {'acc': 0.3054607508532423, 'acc_stderr': 0.0134600804780025, 'acc_norm': 0.3319112627986348, 'acc_norm_stderr': 0.01376098820088054}, 'piqa': {'acc': 0.750816104461371, 'acc_stderr': 0.010091882770120216, 'acc_norm': 0.7578890097932536, 'acc_norm_stderr': 0.0099943712691044}, 'openbookqa': {'acc': 0.244, 'acc_stderr': 0.01922673489361459, 'acc_norm': 0.368, 'acc_norm_stderr': 0.02158898256835354}, 'arc_easy': {'acc': 0.6346801346801347, 'acc_stderr': 0.009880576614806923, 'acc_norm': 0.5774410774410774, 'acc_norm_stderr': 0.010135978222981075}}, 'versions': {'lambada_openai': 0, 'boolq': 1, 'arc_challenge': 0, 'piqa': 0, 'openbookqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7ff5ba060880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 17:47:16 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=512, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.618130683898926, 'ptb': 13.854394912719727, 'c4': 12.323511123657227, 'results': {'lambada_openai': {'ppl': 4.84649127425137, 'ppl_stderr': 0.10796332344158736, 'acc': 0.6454492528624103, 'acc_stderr': 0.006664726415340314}, 'boolq': {'acc': 0.6165137614678899, 'acc_stderr': 0.008504304838837021}, 'piqa': {'acc': 0.7486398258977149, 'acc_stderr': 0.01012115601681926, 'acc_norm': 0.7546245919477693, 'acc_norm_stderr': 0.010039831320422386}, 'arc_challenge': {'acc': 0.3165529010238908, 'acc_stderr': 0.01359243151906808, 'acc_norm': 0.3387372013651877, 'acc_norm_stderr': 0.01383056892797433}, 'openbookqa': {'acc': 0.274, 'acc_stderr': 0.019966103540279473, 'acc_norm': 0.386, 'acc_norm_stderr': 0.02179352921928117}, 'arc_easy': {'acc': 0.6418350168350169, 'acc_stderr': 0.009838331651451841, 'acc_norm': 0.5858585858585859, 'acc_norm_stderr': 0.010107387673002524}}, 'versions': {'lambada_openai': 0, 'boolq': 1, 'piqa': 0, 'arc_challenge': 0, 'openbookqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f514c2a8970>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-06 17:49:49 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=512, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.998223304748535, 'ptb': 14.317155838012695, 'c4': 12.70175838470459, 'results': {'arc_challenge': {'acc': 0.30631399317406144, 'acc_stderr': 0.013470584417276513, 'acc_norm': 0.32764505119453924, 'acc_norm_stderr': 0.013715847940719342}, 'boolq': {'acc': 0.6339449541284403, 'acc_stderr': 0.008425419107728753}, 'openbookqa': {'acc': 0.26, 'acc_stderr': 0.019635965529725512, 'acc_norm': 0.362, 'acc_norm_stderr': 0.021513662527582408}, 'piqa': {'acc': 0.7529923830250272, 'acc_stderr': 0.010062268140772627, 'acc_norm': 0.7535364526659413, 'acc_norm_stderr': 0.010054810789671811}, 'arc_easy': {'acc': 0.640993265993266, 'acc_stderr': 0.009843424713072174, 'acc_norm': 0.577020202020202, 'acc_norm_stderr': 0.010137328382209087}, 'lambada_openai': {'ppl': 5.052482291586584, 'ppl_stderr': 0.11538989302891624, 'acc': 0.6343877352998254, 'acc_stderr': 0.0067096495908640745}}, 'versions': {'arc_challenge': 0, 'boolq': 1, 'openbookqa': 0, 'piqa': 0, 'arc_easy': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f10d9c707f0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-06 18:54:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=512, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.066012382507324, 'ptb': 13.313813209533691, 'c4': 11.965973854064941, 'results': {'boolq': {'acc': 0.6648318042813456, 'acc_stderr': 0.008256192949796777}, 'lambada_openai': {'ppl': 4.149109422170414, 'ppl_stderr': 0.0898721082762837, 'acc': 0.6887250145546284, 'acc_stderr': 0.006450703968778302}, 'arc_easy': {'acc': 0.6531986531986532, 'acc_stderr': 0.009766326091716005, 'acc_norm': 0.6018518518518519, 'acc_norm_stderr': 0.010044662374653398}, 'arc_challenge': {'acc': 0.30802047781569963, 'acc_stderr': 0.013491429517292038, 'acc_norm': 0.3464163822525597, 'acc_norm_stderr': 0.01390501118006325}, 'openbookqa': {'acc': 0.26, 'acc_stderr': 0.019635965529725512, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'piqa': {'acc': 0.7584330794341676, 'acc_stderr': 0.009986718001804463, 'acc_norm': 0.7709466811751904, 'acc_norm_stderr': 0.009804509865175505}}, 'versions': {'boolq': 1, 'lambada_openai': 0, 'arc_easy': 0, 'arc_challenge': 0, 'openbookqa': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f6c180999c0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-06 19:19:16 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=512, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 10.94449234008789, 'ptb': 13.150712013244629, 'c4': 11.863030433654785, 'results': {'lambada_openai': {'ppl': 4.284165477954373, 'ppl_stderr': 0.09401134392573093, 'acc': 0.6747525713176791, 'acc_stderr': 0.006526664414004574}, 'boolq': {'acc': 0.6648318042813456, 'acc_stderr': 0.008256192949796771}, 'arc_easy': {'acc': 0.6523569023569024, 'acc_stderr': 0.009771868846830909, 'acc_norm': 0.6001683501683501, 'acc_norm_stderr': 0.010051788039412911}, 'arc_challenge': {'acc': 0.302901023890785, 'acc_stderr': 0.013428241573185347, 'acc_norm': 0.3395904436860068, 'acc_norm_stderr': 0.01383903976282016}, 'piqa': {'acc': 0.7600652883569097, 'acc_stderr': 0.009963625892809544, 'acc_norm': 0.766050054406964, 'acc_norm_stderr': 0.009877236895137429}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.019874354831287473, 'acc_norm': 0.37, 'acc_norm_stderr': 0.021613289165165778}}, 'versions': {'lambada_openai': 0, 'boolq': 1, 'arc_easy': 0, 'arc_challenge': 0, 'piqa': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f9088530910>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-06 20:18:07 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=512, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.425891876220703, 'ptb': 15.86553955078125, 'c4': 13.59472942352295, 'results': {'lambada_openai': {'ppl': 5.149395637709405, 'ppl_stderr': 0.11717840361171081, 'acc': 0.6334174267417039, 'acc_stderr': 0.006713407112817484}, 'boolq': {'acc': 0.6281345565749236, 'acc_stderr': 0.008453018007354028}, 'arc_challenge': {'acc': 0.29948805460750855, 'acc_stderr': 0.013385021637313563, 'acc_norm': 0.34215017064846415, 'acc_norm_stderr': 0.013864152159177278}, 'openbookqa': {'acc': 0.274, 'acc_stderr': 0.019966103540279476, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'arc_easy': {'acc': 0.6338383838383839, 'acc_stderr': 0.009885391390947724, 'acc_norm': 0.5686026936026936, 'acc_norm_stderr': 0.010162752847747501}, 'piqa': {'acc': 0.7480957562568009, 'acc_stderr': 0.010128421335088681, 'acc_norm': 0.7513601741022851, 'acc_norm_stderr': 0.010084511234296841}}, 'versions': {'lambada_openai': 0, 'boolq': 1, 'arc_challenge': 0, 'openbookqa': 0, 'arc_easy': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f82483908b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 2023-09-06 20:42:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=128, topk_num_final_layer_norm=128, topk_num_fc2=512, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.31816577911377, 'ptb': 14.021356582641602, 'c4': 12.305378913879395, 'results': {'openbookqa': {'acc': 0.268, 'acc_stderr': 0.019827714859587568, 'acc_norm': 0.378, 'acc_norm_stderr': 0.021706550824518184}, 'arc_challenge': {'acc': 0.30716723549488056, 'acc_stderr': 0.013481034054980945, 'acc_norm': 0.34982935153583616, 'acc_norm_stderr': 0.013936809212158278}, 'boolq': {'acc': 0.6623853211009174, 'acc_stderr': 0.008271010075886842}, 'arc_easy': {'acc': 0.6544612794612794, 'acc_stderr': 0.009757948730670294, 'acc_norm': 0.6026936026936027, 'acc_norm_stderr': 0.01004105307888429}, 'piqa': {'acc': 0.7606093579978237, 'acc_stderr': 0.009955884250291685, 'acc_norm': 0.7693144722524483, 'acc_norm_stderr': 0.009828959550983096}, 'lambada_openai': {'ppl': 4.200708782887483, 'ppl_stderr': 0.09126087363985978, 'acc': 0.6815447312245294, 'acc_stderr': 0.006490579511276152}}, 'versions': {'openbookqa': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0, 'piqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7faab8158880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-08 21:26:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.25784683227539, 'ptb': 14.769063949584961, 'c4': 13.370948791503906, 'results': {'arc_challenge': {'acc': 0.29948805460750855, 'acc_stderr': 0.013385021637313562, 'acc_norm': 0.3395904436860068, 'acc_norm_stderr': 0.013839039762820164}, 'openbookqa': {'acc': 0.248, 'acc_stderr': 0.019332342821239103, 'acc_norm': 0.364, 'acc_norm_stderr': 0.0215391706373177}, 'arc_easy': {'acc': 0.6376262626262627, 'acc_stderr': 0.009863468202583787, 'acc_norm': 0.5694444444444444, 'acc_norm_stderr': 0.010160345396860082}, 'boolq': {'acc': 0.6223241590214067, 'acc_stderr': 0.008479309208281651}, 'piqa': {'acc': 0.749727965179543, 'acc_stderr': 0.010106561880089782, 'acc_norm': 0.7513601741022851, 'acc_norm_stderr': 0.010084511234296847}, 'lambada_openai': {'ppl': 5.088210959717751, 'ppl_stderr': 0.11528010868027253, 'acc': 0.6402095866485542, 'acc_stderr': 0.006686486206488779}}, 'versions': {'arc_challenge': 0, 'openbookqa': 0, 'arc_easy': 0, 'boolq': 1, 'piqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f7e2e7f8820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-08 22:57:56 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.23623275756836, 'ptb': 14.8191499710083, 'c4': 13.295520782470703, 'results': {'lambada_openai': {'ppl': 5.027733598489013, 'ppl_stderr': 0.11351025767671187, 'acc': 0.6464195614205317, 'acc_stderr': 0.006660601226776445}, 'openbookqa': {'acc': 0.246, 'acc_stderr': 0.019279819056352544, 'acc_norm': 0.38, 'acc_norm_stderr': 0.0217288814387017}, 'piqa': {'acc': 0.7513601741022851, 'acc_stderr': 0.010084511234296854, 'acc_norm': 0.7589771490750816, 'acc_norm_stderr': 0.009979042717267314}, 'boolq': {'acc': 0.6278287461773701, 'acc_stderr': 0.008454434247373901}, 'arc_easy': {'acc': 0.63510101010101, 'acc_stderr': 0.009878157021155649, 'acc_norm': 0.577020202020202, 'acc_norm_stderr': 0.010137328382209087}, 'arc_challenge': {'acc': 0.30204778156996587, 'acc_stderr': 0.013417519144716426, 'acc_norm': 0.33532423208191126, 'acc_norm_stderr': 0.013796182947785566}}, 'versions': {'lambada_openai': 0, 'openbookqa': 0, 'piqa': 0, 'boolq': 1, 'arc_easy': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fc61854c7f0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-09 00:30:43 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.221477508544922, 'ptb': 14.74280834197998, 'c4': 13.249598503112793, 'results': {'piqa': {'acc': 0.7529923830250272, 'acc_stderr': 0.010062268140772627, 'acc_norm': 0.7475516866158868, 'acc_norm_stderr': 0.010135665547362348}, 'arc_easy': {'acc': 0.6443602693602694, 'acc_stderr': 0.009822854395535487, 'acc_norm': 0.5774410774410774, 'acc_norm_stderr': 0.010135978222981073}, 'openbookqa': {'acc': 0.274, 'acc_stderr': 0.019966103540279466, 'acc_norm': 0.38, 'acc_norm_stderr': 0.021728881438701702}, 'arc_challenge': {'acc': 0.28242320819112626, 'acc_stderr': 0.013155456884097224, 'acc_norm': 0.3174061433447099, 'acc_norm_stderr': 0.01360223908803817}, 'boolq': {'acc': 0.6498470948012233, 'acc_stderr': 0.008343091327001251}, 'lambada_openai': {'ppl': 4.915012693376713, 'ppl_stderr': 0.1106879335887364, 'acc': 0.648554240248399, 'acc_stderr': 0.0066514200969375655}}, 'versions': {'piqa': 0, 'arc_easy': 0, 'openbookqa': 0, 'arc_challenge': 0, 'boolq': 1, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7efdd87207f0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-09 02:05:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.152280807495117, 'ptb': 14.605239868164062, 'c4': 13.168900489807129, 'results': {'arc_challenge': {'acc': 0.28668941979522183, 'acc_stderr': 0.01321498632927478, 'acc_norm': 0.3310580204778157, 'acc_norm_stderr': 0.013752062419817834}, 'lambada_openai': {'ppl': 4.915174138910293, 'ppl_stderr': 0.11053720674289488, 'acc': 0.6450611294391616, 'acc_stderr': 0.006666368100412543}, 'openbookqa': {'acc': 0.266, 'acc_stderr': 0.019780559675655493, 'acc_norm': 0.358, 'acc_norm_stderr': 0.021461434862859115}, 'arc_easy': {'acc': 0.6376262626262627, 'acc_stderr': 0.009863468202583792, 'acc_norm': 0.5787037037037037, 'acc_norm_stderr': 0.010131882498193126}, 'piqa': {'acc': 0.749183895538629, 'acc_stderr': 0.010113869547069044, 'acc_norm': 0.7513601741022851, 'acc_norm_stderr': 0.010084511234296847}, 'boolq': {'acc': 0.6568807339449542, 'acc_stderr': 0.008303445777655929}}, 'versions': {'arc_challenge': 0, 'lambada_openai': 0, 'openbookqa': 0, 'arc_easy': 0, 'piqa': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7fab037887c0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-09 03:34:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.299943923950195, 'ptb': 13.562271118164062, 'c4': 12.272377014160156, 'results': {'arc_challenge': {'acc': 0.302901023890785, 'acc_stderr': 0.013428241573185347, 'acc_norm': 0.3464163822525597, 'acc_norm_stderr': 0.013905011180063254}, 'boolq': {'acc': 0.6611620795107034, 'acc_stderr': 0.008278325755273755}, 'lambada_openai': {'ppl': 4.1742712212556174, 'ppl_stderr': 0.0901548405255827, 'acc': 0.685814088880264, 'acc_stderr': 0.0064670858666538945}, 'openbookqa': {'acc': 0.268, 'acc_stderr': 0.019827714859587568, 'acc_norm': 0.378, 'acc_norm_stderr': 0.021706550824518184}, 'arc_easy': {'acc': 0.6523569023569024, 'acc_stderr': 0.009771868846830912, 'acc_norm': 0.5955387205387206, 'acc_norm_stderr': 0.010070746648278794}, 'piqa': {'acc': 0.7584330794341676, 'acc_stderr': 0.009986718001804463, 'acc_norm': 0.7687704026115343, 'acc_norm_stderr': 0.009837063180625336}}, 'versions': {'arc_challenge': 0, 'boolq': 1, 'lambada_openai': 0, 'openbookqa': 0, 'arc_easy': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fea5fb90820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-09 04:59:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.296555519104004, 'ptb': 13.581122398376465, 'c4': 12.267064094543457, 'results': {'arc_challenge': {'acc': 0.29948805460750855, 'acc_stderr': 0.013385021637313565, 'acc_norm': 0.3430034129692833, 'acc_norm_stderr': 0.013872423223718169}, 'boolq': {'acc': 0.6581039755351682, 'acc_stderr': 0.008296345355563837}, 'arc_easy': {'acc': 0.656986531986532, 'acc_stderr': 0.00974096566648922, 'acc_norm': 0.6014309764309764, 'acc_norm_stderr': 0.010046455400477943}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.019874354831287473, 'acc_norm': 0.366, 'acc_norm_stderr': 0.021564276850201614}, 'piqa': {'acc': 0.7584330794341676, 'acc_stderr': 0.009986718001804463, 'acc_norm': 0.763873775843308, 'acc_norm_stderr': 0.009908965890558218}, 'lambada_openai': {'ppl': 4.181808228062419, 'ppl_stderr': 0.09039649553375068, 'acc': 0.6850378420337667, 'acc_stderr': 0.006471404446305821}}, 'versions': {'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0, 'openbookqa': 0, 'piqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f97b250c880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-09 06:23:40 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.31216812133789, 'ptb': 13.55050277709961, 'c4': 12.263204574584961, 'results': {'lambada_openai': {'ppl': 4.158282242752324, 'ppl_stderr': 0.09016672274038028, 'acc': 0.6898893848243741, 'acc_stderr': 0.006444068085916537}, 'piqa': {'acc': 0.7611534276387377, 'acc_stderr': 0.009948120385337503, 'acc_norm': 0.7687704026115343, 'acc_norm_stderr': 0.009837063180625336}, 'openbookqa': {'acc': 0.272, 'acc_stderr': 0.01992048320956608, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'boolq': {'acc': 0.6571865443425077, 'acc_stderr': 0.008301676410578645}, 'arc_challenge': {'acc': 0.3122866894197952, 'acc_stderr': 0.013542598541688065, 'acc_norm': 0.3447098976109215, 'acc_norm_stderr': 0.01388881628678211}, 'arc_easy': {'acc': 0.6595117845117845, 'acc_stderr': 0.009723676813825875, 'acc_norm': 0.5997474747474747, 'acc_norm_stderr': 0.010053550119896136}}, 'versions': {'lambada_openai': 0, 'piqa': 0, 'openbookqa': 0, 'boolq': 1, 'arc_challenge': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7efefeb50880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-09 07:49:48 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.312325477600098, 'ptb': 13.571105003356934, 'c4': 12.26530933380127, 'results': {'lambada_openai': {'ppl': 4.121241929729028, 'ppl_stderr': 0.08870728685975318, 'acc': 0.685814088880264, 'acc_stderr': 0.006467085866653892}, 'openbookqa': {'acc': 0.266, 'acc_stderr': 0.019780559675655496, 'acc_norm': 0.378, 'acc_norm_stderr': 0.021706550824518188}, 'arc_easy': {'acc': 0.6540404040404041, 'acc_stderr': 0.009760749624427507, 'acc_norm': 0.6031144781144782, 'acc_norm_stderr': 0.010039236800583195}, 'boolq': {'acc': 0.6547400611620795, 'acc_stderr': 0.008315724479705721}, 'arc_challenge': {'acc': 0.30887372013651876, 'acc_stderr': 0.013501770929344003, 'acc_norm': 0.34726962457337884, 'acc_norm_stderr': 0.013913034529620439}, 'piqa': {'acc': 0.7568008705114254, 'acc_stderr': 0.010009611953858919, 'acc_norm': 0.7698585418933623, 'acc_norm_stderr': 0.009820832826839801}}, 'versions': {'lambada_openai': 0, 'openbookqa': 0, 'arc_easy': 0, 'boolq': 1, 'arc_challenge': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f850bf04850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-09 13:00:17 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.210654258728027, 'ptb': 14.814648628234863, 'c4': 13.16360092163086, 'results': {'lambada_openai': {'ppl': 4.813117806099816, 'ppl_stderr': 0.10793258347555562, 'acc': 0.6598098195226082, 'acc_stderr': 0.006600583766063697}, 'boolq': {'acc': 0.6406727828746177, 'acc_stderr': 0.008391811770406741}, 'arc_challenge': {'acc': 0.29180887372013653, 'acc_stderr': 0.01328452529240351, 'acc_norm': 0.3293515358361775, 'acc_norm_stderr': 0.013734057652635474}, 'piqa': {'acc': 0.7513601741022851, 'acc_stderr': 0.010084511234296852, 'acc_norm': 0.7557127312295974, 'acc_norm_stderr': 0.010024765172284253}, 'arc_easy': {'acc': 0.6414141414141414, 'acc_stderr': 0.009840882301225297, 'acc_norm': 0.5829124579124579, 'acc_norm_stderr': 0.010117738967781991}, 'openbookqa': {'acc': 0.256, 'acc_stderr': 0.019536923574747612, 'acc_norm': 0.376, 'acc_norm_stderr': 0.021683827539286125}}, 'versions': {'lambada_openai': 0, 'boolq': 1, 'arc_challenge': 0, 'piqa': 0, 'arc_easy': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f5adbdc4880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-09 14:27:08 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.172723770141602, 'ptb': 14.850699424743652, 'c4': 13.080607414245605, 'results': {'openbookqa': {'acc': 0.26, 'acc_stderr': 0.019635965529725515, 'acc_norm': 0.37, 'acc_norm_stderr': 0.02161328916516578}, 'arc_easy': {'acc': 0.6376262626262627, 'acc_stderr': 0.009863468202583789, 'acc_norm': 0.5875420875420876, 'acc_norm_stderr': 0.010101305447864768}, 'boolq': {'acc': 0.6483180428134556, 'acc_stderr': 0.008351445237661383}, 'lambada_openai': {'ppl': 4.948044605328193, 'ppl_stderr': 0.11200645757637868, 'acc': 0.6437026974577916, 'acc_stderr': 0.006672076306559634}, 'piqa': {'acc': 0.7540805223068553, 'acc_stderr': 0.010047331865625194, 'acc_norm': 0.7589771490750816, 'acc_norm_stderr': 0.009979042717267314}, 'arc_challenge': {'acc': 0.3097269624573379, 'acc_stderr': 0.01351205841523836, 'acc_norm': 0.3395904436860068, 'acc_norm_stderr': 0.013839039762820166}}, 'versions': {'openbookqa': 0, 'arc_easy': 0, 'boolq': 1, 'lambada_openai': 0, 'piqa': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f160a59c7c0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-09 15:57:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.148804664611816, 'ptb': 14.721065521240234, 'c4': 13.081379890441895, 'results': {'arc_easy': {'acc': 0.6372053872053872, 'acc_stderr': 0.00986593675701394, 'acc_norm': 0.5816498316498316, 'acc_norm_stderr': 0.010122061470742863}, 'openbookqa': {'acc': 0.264, 'acc_stderr': 0.019732885585922108, 'acc_norm': 0.358, 'acc_norm_stderr': 0.02146143486285912}, 'lambada_openai': {'ppl': 4.747128069707152, 'ppl_stderr': 0.10557974499884594, 'acc': 0.6600038812342325, 'acc_stderr': 0.006599671169668108}, 'piqa': {'acc': 0.7546245919477693, 'acc_stderr': 0.010039831320422396, 'acc_norm': 0.7573449401523396, 'acc_norm_stderr': 0.010002002569708688}, 'arc_challenge': {'acc': 0.29948805460750855, 'acc_stderr': 0.013385021637313565, 'acc_norm': 0.3430034129692833, 'acc_norm_stderr': 0.013872423223718166}, 'boolq': {'acc': 0.637308868501529, 'acc_stderr': 0.008408838061823179}}, 'versions': {'arc_easy': 0, 'openbookqa': 0, 'lambada_openai': 0, 'piqa': 0, 'arc_challenge': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7fdb7d050850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-09 17:23:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.089797019958496, 'ptb': 14.635697364807129, 'c4': 13.040699005126953, 'results': {'boolq': {'acc': 0.6440366972477064, 'acc_stderr': 0.00837433751772658}, 'arc_easy': {'acc': 0.6435185185185185, 'acc_stderr': 0.009828046544504422, 'acc_norm': 0.5896464646464646, 'acc_norm_stderr': 0.01009353125576545}, 'arc_challenge': {'acc': 0.3054607508532423, 'acc_stderr': 0.013460080478002496, 'acc_norm': 0.3447098976109215, 'acc_norm_stderr': 0.01388881628678211}, 'lambada_openai': {'ppl': 4.757595958166093, 'ppl_stderr': 0.10650884891956525, 'acc': 0.6594216960993596, 'acc_stderr': 0.006602405259021261}, 'piqa': {'acc': 0.7453754080522307, 'acc_stderr': 0.0101644322370605, 'acc_norm': 0.763873775843308, 'acc_norm_stderr': 0.009908965890558218}, 'openbookqa': {'acc': 0.278, 'acc_stderr': 0.02005583388807089, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}}, 'versions': {'boolq': 1, 'arc_easy': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'piqa': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f16b351c880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-09 18:50:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.360800743103027, 'ptb': 13.535807609558105, 'c4': 12.22700309753418, 'results': {'arc_challenge': {'acc': 0.29948805460750855, 'acc_stderr': 0.013385021637313562, 'acc_norm': 0.34215017064846415, 'acc_norm_stderr': 0.013864152159177275}, 'piqa': {'acc': 0.7633297062023939, 'acc_stderr': 0.009916841655042806, 'acc_norm': 0.76550598476605, 'acc_norm_stderr': 0.00988520314324054}, 'arc_easy': {'acc': 0.6531986531986532, 'acc_stderr': 0.009766326091716005, 'acc_norm': 0.5934343434343434, 'acc_norm_stderr': 0.010079056419223537}, 'boolq': {'acc': 0.6675840978593273, 'acc_stderr': 0.008239226214991662}, 'openbookqa': {'acc': 0.266, 'acc_stderr': 0.01978055967565549, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'lambada_openai': {'ppl': 4.031614754353508, 'ppl_stderr': 0.08726023749157455, 'acc': 0.6970696681544731, 'acc_stderr': 0.006402086620816847}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'arc_easy': 0, 'boolq': 1, 'openbookqa': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f730ec4c820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-09 20:17:10 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.36048412322998, 'ptb': 13.533458709716797, 'c4': 12.222060203552246, 'results': {'piqa': {'acc': 0.7584330794341676, 'acc_stderr': 0.009986718001804463, 'acc_norm': 0.766050054406964, 'acc_norm_stderr': 0.009877236895137436}, 'boolq': {'acc': 0.6669724770642201, 'acc_stderr': 0.008243023912688885}, 'arc_challenge': {'acc': 0.30119453924914674, 'acc_stderr': 0.01340674176784762, 'acc_norm': 0.3387372013651877, 'acc_norm_stderr': 0.01383056892797433}, 'lambada_openai': {'ppl': 4.055717542583188, 'ppl_stderr': 0.08833739172242212, 'acc': 0.6941587424801087, 'acc_stderr': 0.00641932711589258}, 'arc_easy': {'acc': 0.6485690235690236, 'acc_stderr': 0.00979639558281772, 'acc_norm': 0.601010101010101, 'acc_norm_stderr': 0.010048240683798742}, 'openbookqa': {'acc': 0.266, 'acc_stderr': 0.01978055967565549, 'acc_norm': 0.376, 'acc_norm_stderr': 0.021683827539286122}}, 'versions': {'piqa': 0, 'boolq': 1, 'arc_challenge': 0, 'lambada_openai': 0, 'arc_easy': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f4a3e8ec820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-09 21:43:03 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.328750610351562, 'ptb': 13.507051467895508, 'c4': 12.214346885681152, 'results': {'lambada_openai': {'ppl': 4.064087133517295, 'ppl_stderr': 0.08787653108077942, 'acc': 0.6931884339219871, 'acc_stderr': 0.00642500678212749}, 'openbookqa': {'acc': 0.268, 'acc_stderr': 0.019827714859587564, 'acc_norm': 0.378, 'acc_norm_stderr': 0.021706550824518188}, 'arc_challenge': {'acc': 0.30631399317406144, 'acc_stderr': 0.013470584417276511, 'acc_norm': 0.3378839590443686, 'acc_norm_stderr': 0.013822047922283512}, 'boolq': {'acc': 0.6636085626911316, 'acc_stderr': 0.00826363252934455}, 'arc_easy': {'acc': 0.6557239057239057, 'acc_stderr': 0.009749495321590817, 'acc_norm': 0.5963804713804713, 'acc_norm_stderr': 0.010067368960348226}, 'piqa': {'acc': 0.7535364526659413, 'acc_stderr': 0.010054810789671824, 'acc_norm': 0.7665941240478781, 'acc_norm_stderr': 0.009869247889520994}}, 'versions': {'lambada_openai': 0, 'openbookqa': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fb5a93787f0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-09 23:19:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.340292930603027, 'ptb': 13.51349925994873, 'c4': 12.21367073059082, 'results': {'lambada_openai': {'ppl': 4.075927243103382, 'ppl_stderr': 0.08855845229718483, 'acc': 0.6900834465359984, 'acc_stderr': 0.006442957470089094}, 'arc_easy': {'acc': 0.6510942760942761, 'acc_stderr': 0.009780119894465769, 'acc_norm': 0.6018518518518519, 'acc_norm_stderr': 0.010044662374653398}, 'piqa': {'acc': 0.7568008705114254, 'acc_stderr': 0.010009611953858917, 'acc_norm': 0.7665941240478781, 'acc_norm_stderr': 0.009869247889520993}, 'boolq': {'acc': 0.6681957186544343, 'acc_stderr': 0.008235412870849414}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.01987435483128748, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}, 'arc_challenge': {'acc': 0.30887372013651876, 'acc_stderr': 0.013501770929344003, 'acc_norm': 0.3412969283276451, 'acc_norm_stderr': 0.013855831287497723}}, 'versions': {'lambada_openai': 0, 'arc_easy': 0, 'piqa': 0, 'boolq': 1, 'openbookqa': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f20e21bc730>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-10 18:17:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=1, R3_clusters=1, R4_clusters=32, R5_clusters=128, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.265373229980469, 'ptb': 15.617533683776855, 'c4': 13.18822956085205, 'results': {'openbookqa': {'acc': 0.26, 'acc_stderr': 0.01963596552972551, 'acc_norm': 0.384, 'acc_norm_stderr': 0.021772369465547198}, 'lambada_openai': {'ppl': 5.152376925744836, 'ppl_stderr': 0.11726797727711738, 'acc': 0.6326411798952066, 'acc_stderr': 0.006716392026588045}, 'arc_easy': {'acc': 0.6367845117845118, 'acc_stderr': 0.009868397136118794, 'acc_norm': 0.5715488215488216, 'acc_norm_stderr': 0.010154195733990965}, 'arc_challenge': {'acc': 0.2858361774744027, 'acc_stderr': 0.013203196088537369, 'acc_norm': 0.3387372013651877, 'acc_norm_stderr': 0.01383056892797433}, 'piqa': {'acc': 0.7519042437431991, 'acc_stderr': 0.010077118315574719, 'acc_norm': 0.7551686615886833, 'acc_norm_stderr': 0.010032309105568807}, 'boolq': {'acc': 0.6327217125382263, 'acc_stderr': 0.008431338702844847}}, 'versions': {'openbookqa': 0, 'lambada_openai': 0, 'arc_easy': 0, 'arc_challenge': 0, 'piqa': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f956c9487f0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-10 23:34:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.254085540771484, 'ptb': 14.845544815063477, 'c4': 13.159534454345703, 'results': {'openbookqa': {'acc': 0.258, 'acc_stderr': 0.019586711785215837, 'acc_norm': 0.37, 'acc_norm_stderr': 0.02161328916516578}, 'piqa': {'acc': 0.7573449401523396, 'acc_stderr': 0.010002002569708698, 'acc_norm': 0.7633297062023939, 'acc_norm_stderr': 0.009916841655042809}, 'lambada_openai': {'ppl': 4.851504983748196, 'ppl_stderr': 0.10889387205006464, 'acc': 0.6596157578109839, 'acc_stderr': 0.006601495129011079}, 'arc_easy': {'acc': 0.6384680134680135, 'acc_stderr': 0.00985850654316206, 'acc_norm': 0.5862794612794613, 'acc_norm_stderr': 0.01010587853023813}, 'boolq': {'acc': 0.6155963302752293, 'acc_stderr': 0.008508133844703916}, 'arc_challenge': {'acc': 0.29266211604095566, 'acc_stderr': 0.013295916103619406, 'acc_norm': 0.33447098976109213, 'acc_norm_stderr': 0.01378746032244138}}, 'versions': {'openbookqa': 0, 'piqa': 0, 'lambada_openai': 0, 'arc_easy': 0, 'boolq': 1, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f003b21c8e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-11 02:28:42 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.171113967895508, 'ptb': 14.846833229064941, 'c4': 13.120512008666992, 'results': {'lambada_openai': {'ppl': 4.8396562905366505, 'ppl_stderr': 0.1075245503445798, 'acc': 0.6553464001552494, 'acc_stderr': 0.006621234074946411}, 'piqa': {'acc': 0.7448313384113167, 'acc_stderr': 0.010171571592521822, 'acc_norm': 0.750816104461371, 'acc_norm_stderr': 0.010091882770120209}, 'openbookqa': {'acc': 0.262, 'acc_stderr': 0.019684688820194713, 'acc_norm': 0.358, 'acc_norm_stderr': 0.02146143486285912}, 'arc_challenge': {'acc': 0.30119453924914674, 'acc_stderr': 0.013406741767847626, 'acc_norm': 0.32593856655290104, 'acc_norm_stderr': 0.01369743246669325}, 'boolq': {'acc': 0.6412844036697247, 'acc_stderr': 0.008388668034059408}, 'arc_easy': {'acc': 0.63510101010101, 'acc_stderr': 0.009878157021155649, 'acc_norm': 0.5765993265993266, 'acc_norm_stderr': 0.010138671005289054}}, 'versions': {'lambada_openai': 0, 'piqa': 0, 'openbookqa': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fb99063c820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-11 06:20:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.105578422546387, 'ptb': 14.730653762817383, 'c4': 13.054636001586914, 'results': {'openbookqa': {'acc': 0.258, 'acc_stderr': 0.019586711785215837, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}, 'lambada_openai': {'ppl': 4.84048015011542, 'ppl_stderr': 0.1081038788537625, 'acc': 0.6530176596157579, 'acc_stderr': 0.006631751157670147}, 'piqa': {'acc': 0.7453754080522307, 'acc_stderr': 0.010164432237060487, 'acc_norm': 0.7529923830250272, 'acc_norm_stderr': 0.010062268140772643}, 'arc_easy': {'acc': 0.6384680134680135, 'acc_stderr': 0.009858506543162058, 'acc_norm': 0.5892255892255892, 'acc_norm_stderr': 0.01009510134934866}, 'boolq': {'acc': 0.6403669724770642, 'acc_stderr': 0.008393378084399052}, 'arc_challenge': {'acc': 0.29692832764505117, 'acc_stderr': 0.01335202597672522, 'acc_norm': 0.32849829351535836, 'acc_norm_stderr': 0.01372497846553737}}, 'versions': {'openbookqa': 0, 'lambada_openai': 0, 'piqa': 0, 'arc_easy': 0, 'boolq': 1, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f3a19d4c8b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-11 10:03:56 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.064356803894043, 'ptb': 14.633157730102539, 'c4': 13.035526275634766, 'results': {'lambada_openai': {'ppl': 4.763496034463496, 'ppl_stderr': 0.10587367100792697, 'acc': 0.6574810789831166, 'acc_stderr': 0.006611438859225003}, 'openbookqa': {'acc': 0.272, 'acc_stderr': 0.01992048320956608, 'acc_norm': 0.376, 'acc_norm_stderr': 0.02168382753928612}, 'arc_challenge': {'acc': 0.3054607508532423, 'acc_stderr': 0.013460080478002505, 'acc_norm': 0.3395904436860068, 'acc_norm_stderr': 0.013839039762820167}, 'boolq': {'acc': 0.6501529051987768, 'acc_stderr': 0.008341409251946753}, 'arc_easy': {'acc': 0.6456228956228957, 'acc_stderr': 0.009815004030251748, 'acc_norm': 0.5845959595959596, 'acc_norm_stderr': 0.010111869494911515}, 'piqa': {'acc': 0.7448313384113167, 'acc_stderr': 0.010171571592521824, 'acc_norm': 0.7557127312295974, 'acc_norm_stderr': 0.010024765172284263}}, 'versions': {'lambada_openai': 0, 'openbookqa': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f1a97bbc910>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-11 13:31:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.354145050048828, 'ptb': 13.541686058044434, 'c4': 12.22966194152832, 'results': {'boolq': {'acc': 0.6608562691131499, 'acc_stderr': 0.008280145027624473}, 'lambada_openai': {'ppl': 4.12268308611125, 'ppl_stderr': 0.08946408618335869, 'acc': 0.6929943722103629, 'acc_stderr': 0.0064261387004681675}, 'arc_challenge': {'acc': 0.310580204778157, 'acc_stderr': 0.013522292098053047, 'acc_norm': 0.3515358361774744, 'acc_norm_stderr': 0.013952413699600945}, 'openbookqa': {'acc': 0.258, 'acc_stderr': 0.019586711785215837, 'acc_norm': 0.37, 'acc_norm_stderr': 0.02161328916516578}, 'piqa': {'acc': 0.7589771490750816, 'acc_stderr': 0.009979042717267315, 'acc_norm': 0.7698585418933623, 'acc_norm_stderr': 0.009820832826839796}, 'arc_easy': {'acc': 0.6452020202020202, 'acc_stderr': 0.009817629113069697, 'acc_norm': 0.5972222222222222, 'acc_norm_stderr': 0.010063960494989166}}, 'versions': {'boolq': 1, 'lambada_openai': 0, 'arc_challenge': 0, 'openbookqa': 0, 'piqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f332d660880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-11 16:24:31 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.344643592834473, 'ptb': 13.536982536315918, 'c4': 12.225626945495605, 'results': {'arc_easy': {'acc': 0.6473063973063973, 'acc_stderr': 0.009804420599378656, 'acc_norm': 0.5993265993265994, 'acc_norm_stderr': 0.010055304474255584}, 'openbookqa': {'acc': 0.262, 'acc_stderr': 0.019684688820194713, 'acc_norm': 0.37, 'acc_norm_stderr': 0.02161328916516578}, 'boolq': {'acc': 0.6599388379204894, 'acc_stderr': 0.008285579731379795}, 'lambada_openai': {'ppl': 4.097920076263827, 'ppl_stderr': 0.08929721968837886, 'acc': 0.6939646807684844, 'acc_stderr': 0.006420465728110205}, 'piqa': {'acc': 0.7557127312295974, 'acc_stderr': 0.01002476517228425, 'acc_norm': 0.7606093579978237, 'acc_norm_stderr': 0.009955884250291688}, 'arc_challenge': {'acc': 0.2986348122866894, 'acc_stderr': 0.013374078615068757, 'acc_norm': 0.34812286689419797, 'acc_norm_stderr': 0.013921008595179338}}, 'versions': {'arc_easy': 0, 'openbookqa': 0, 'boolq': 1, 'lambada_openai': 0, 'piqa': 0, 'arc_challenge': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fb095dbc8e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-11 19:17:19 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.354065895080566, 'ptb': 13.537569999694824, 'c4': 12.223435401916504, 'results': {'arc_easy': {'acc': 0.6477272727272727, 'acc_stderr': 0.009801753933112778, 'acc_norm': 0.5963804713804713, 'acc_norm_stderr': 0.01006736896034822}, 'piqa': {'acc': 0.7606093579978237, 'acc_stderr': 0.009955884250291678, 'acc_norm': 0.7676822633297062, 'acc_norm_stderr': 0.009853201384168243}, 'arc_challenge': {'acc': 0.3003412969283277, 'acc_stderr': 0.013395909309956995, 'acc_norm': 0.34044368600682595, 'acc_norm_stderr': 0.013847460518892981}, 'boolq': {'acc': 0.6633027522935779, 'acc_stderr': 0.00826548272506171}, 'lambada_openai': {'ppl': 4.131566757758615, 'ppl_stderr': 0.08963541489592444, 'acc': 0.6881428294197555, 'acc_stderr': 0.006454004061618764}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.019874354831287477, 'acc_norm': 0.37, 'acc_norm_stderr': 0.02161328916516578}}, 'versions': {'arc_easy': 0, 'piqa': 0, 'arc_challenge': 0, 'boolq': 1, 'lambada_openai': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f10c5e648b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-11 22:10:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.337919235229492, 'ptb': 13.517608642578125, 'c4': 12.212133407592773, 'results': {'piqa': {'acc': 0.7551686615886833, 'acc_stderr': 0.010032309105568802, 'acc_norm': 0.7665941240478781, 'acc_norm_stderr': 0.009869247889520991}, 'arc_challenge': {'acc': 0.3097269624573379, 'acc_stderr': 0.01351205841523836, 'acc_norm': 0.3412969283276451, 'acc_norm_stderr': 0.013855831287497726}, 'boolq': {'acc': 0.6709480122324158, 'acc_stderr': 0.008218058611362797}, 'arc_easy': {'acc': 0.6502525252525253, 'acc_stderr': 0.009785578618940732, 'acc_norm': 0.6014309764309764, 'acc_norm_stderr': 0.010046455400477943}, 'lambada_openai': {'ppl': 4.071336577649236, 'ppl_stderr': 0.08783611479026165, 'acc': 0.6953231127498545, 'acc_stderr': 0.0064124672584266506}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.01987435483128748, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}}, 'versions': {'piqa': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0, 'lambada_openai': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f5d40b147c0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-09-12 10:49:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=1, R3_clusters=1, R4_clusters=32, R5_clusters=128, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.151325225830078, 'ptb': 13.7489652633667, 'c4': 12.115386962890625, 'results': {'lambada_openai': {'ppl': 4.24457529461564, 'ppl_stderr': 0.09246722907381719, 'acc': 0.6815447312245294, 'acc_stderr': 0.006490579511276152}, 'boolq': {'acc': 0.6608562691131499, 'acc_stderr': 0.008280145027624475}, 'arc_challenge': {'acc': 0.2960750853242321, 'acc_stderr': 0.013340916085246263, 'acc_norm': 0.34044368600682595, 'acc_norm_stderr': 0.01384746051889298}, 'openbookqa': {'acc': 0.278, 'acc_stderr': 0.020055833888070897, 'acc_norm': 0.388, 'acc_norm_stderr': 0.02181430098478763}, 'arc_easy': {'acc': 0.6527777777777778, 'acc_stderr': 0.009769101679700926, 'acc_norm': 0.6018518518518519, 'acc_norm_stderr': 0.010044662374653398}, 'piqa': {'acc': 0.763873775843308, 'acc_stderr': 0.00990896589055821, 'acc_norm': 0.7665941240478781, 'acc_norm_stderr': 0.009869247889520991}}, 'versions': {'lambada_openai': 0, 'boolq': 1, 'arc_challenge': 0, 'openbookqa': 0, 'arc_easy': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fb9d1644940>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-12 21:41:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.209207534790039, 'ptb': 14.787666320800781, 'c4': 13.143806457519531, 'results': {'openbookqa': {'acc': 0.25, 'acc_stderr': 0.019384310743640384, 'acc_norm': 0.388, 'acc_norm_stderr': 0.02181430098478763}, 'arc_easy': {'acc': 0.6334175084175084, 'acc_stderr': 0.009887786585323952, 'acc_norm': 0.5829124579124579, 'acc_norm_stderr': 0.010117738967782001}, 'boolq': {'acc': 0.6474006116207951, 'acc_stderr': 0.008356412493562122}, 'arc_challenge': {'acc': 0.2960750853242321, 'acc_stderr': 0.013340916085246263, 'acc_norm': 0.3250853242320819, 'acc_norm_stderr': 0.013688147309729119}, 'lambada_openai': {'ppl': 4.804744397769822, 'ppl_stderr': 0.10730850316491186, 'acc': 0.6551523384436251, 'acc_stderr': 0.006622117207603225}, 'piqa': {'acc': 0.749183895538629, 'acc_stderr': 0.010113869547069044, 'acc_norm': 0.7578890097932536, 'acc_norm_stderr': 0.009994371269104395}}, 'versions': {'openbookqa': 0, 'arc_easy': 0, 'boolq': 1, 'arc_challenge': 0, 'lambada_openai': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f9bed658970>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-12 23:20:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.188019752502441, 'ptb': 14.76842212677002, 'c4': 13.050403594970703, 'results': {'piqa': {'acc': 0.7475516866158868, 'acc_stderr': 0.010135665547362364, 'acc_norm': 0.7421109902067464, 'acc_norm_stderr': 0.010206956662056246}, 'lambada_openai': {'ppl': 4.868574928442618, 'ppl_stderr': 0.1082618683543228, 'acc': 0.650494857364642, 'acc_stderr': 0.006642947065250699}, 'arc_challenge': {'acc': 0.3046075085324232, 'acc_stderr': 0.013449522109932492, 'acc_norm': 0.33532423208191126, 'acc_norm_stderr': 0.013796182947785564}, 'boolq': {'acc': 0.6480122324159021, 'acc_stderr': 0.00835310474268296}, 'openbookqa': {'acc': 0.288, 'acc_stderr': 0.02027150383507522, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}, 'arc_easy': {'acc': 0.6346801346801347, 'acc_stderr': 0.009880576614806926, 'acc_norm': 0.5791245791245792, 'acc_norm_stderr': 0.010130502164066336}}, 'versions': {'piqa': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'boolq': 1, 'openbookqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7fa85f66c880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-13 00:48:55 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.108701705932617, 'ptb': 14.641417503356934, 'c4': 13.003889083862305, 'results': {'arc_challenge': {'acc': 0.302901023890785, 'acc_stderr': 0.013428241573185347, 'acc_norm': 0.3250853242320819, 'acc_norm_stderr': 0.013688147309729124}, 'piqa': {'acc': 0.750816104461371, 'acc_stderr': 0.010091882770120216, 'acc_norm': 0.7568008705114254, 'acc_norm_stderr': 0.010009611953858917}, 'boolq': {'acc': 0.6541284403669725, 'acc_stderr': 0.008319198402415403}, 'arc_easy': {'acc': 0.6422558922558923, 'acc_stderr': 0.009835772757343361, 'acc_norm': 0.5803872053872053, 'acc_norm_stderr': 0.010126315840891539}, 'lambada_openai': {'ppl': 4.761130738115796, 'ppl_stderr': 0.10595057321447103, 'acc': 0.659033572676111, 'acc_stderr': 0.006604221822265863}, 'openbookqa': {'acc': 0.274, 'acc_stderr': 0.019966103540279473, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'arc_easy': 0, 'lambada_openai': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f2611a48880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-13 02:16:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.109715461730957, 'ptb': 14.611577987670898, 'c4': 12.931863784790039, 'results': {'arc_easy': {'acc': 0.6435185185185185, 'acc_stderr': 0.009828046544504422, 'acc_norm': 0.5791245791245792, 'acc_norm_stderr': 0.010130502164066336}, 'piqa': {'acc': 0.7513601741022851, 'acc_stderr': 0.01008451123429685, 'acc_norm': 0.7573449401523396, 'acc_norm_stderr': 0.01000200256970869}, 'openbookqa': {'acc': 0.264, 'acc_stderr': 0.019732885585922094, 'acc_norm': 0.38, 'acc_norm_stderr': 0.021728881438701702}, 'boolq': {'acc': 0.6495412844036698, 'acc_stderr': 0.00834476963472485}, 'arc_challenge': {'acc': 0.2901023890784983, 'acc_stderr': 0.013261573677520773, 'acc_norm': 0.33361774744027306, 'acc_norm_stderr': 0.013778687054176538}, 'lambada_openai': {'ppl': 4.70138322305892, 'ppl_stderr': 0.1059781950095957, 'acc': 0.6607801280807297, 'acc_stderr': 0.006596008439349898}}, 'versions': {'arc_easy': 0, 'piqa': 0, 'openbookqa': 0, 'boolq': 1, 'arc_challenge': 0, 'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f5293814850>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-13 03:41:48 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.33325481414795, 'ptb': 13.5322847366333, 'c4': 12.22413444519043, 'results': {'arc_easy': {'acc': 0.6464646464646465, 'acc_stderr': 0.009809728948151493, 'acc_norm': 0.5942760942760943, 'acc_norm_stderr': 0.010075755540128878}, 'lambada_openai': {'ppl': 4.142194192778548, 'ppl_stderr': 0.09057109834593949, 'acc': 0.6912478168057442, 'acc_stderr': 0.006436265900629436}, 'piqa': {'acc': 0.7551686615886833, 'acc_stderr': 0.010032309105568802, 'acc_norm': 0.76550598476605, 'acc_norm_stderr': 0.00988520314324054}, 'arc_challenge': {'acc': 0.29692832764505117, 'acc_stderr': 0.013352025976725222, 'acc_norm': 0.3319112627986348, 'acc_norm_stderr': 0.013760988200880533}, 'boolq': {'acc': 0.6513761467889908, 'acc_stderr': 0.008334643232728133}, 'openbookqa': {'acc': 0.258, 'acc_stderr': 0.019586711785215837, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}}, 'versions': {'arc_easy': 0, 'lambada_openai': 0, 'piqa': 0, 'arc_challenge': 0, 'boolq': 1, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f2492d24880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-13 05:06:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.33966064453125, 'ptb': 13.529348373413086, 'c4': 12.220544815063477, 'results': {'lambada_openai': {'ppl': 4.120622246902131, 'ppl_stderr': 0.09031250470395479, 'acc': 0.695711236173103, 'acc_stderr': 0.006410169885207217}, 'boolq': {'acc': 0.6599388379204894, 'acc_stderr': 0.008285579731379793}, 'openbookqa': {'acc': 0.262, 'acc_stderr': 0.01968468882019471, 'acc_norm': 0.366, 'acc_norm_stderr': 0.021564276850201614}, 'piqa': {'acc': 0.7562568008705114, 'acc_stderr': 0.010017199471500622, 'acc_norm': 0.764417845484222, 'acc_norm_stderr': 0.009901067586473888}, 'arc_challenge': {'acc': 0.2986348122866894, 'acc_stderr': 0.013374078615068756, 'acc_norm': 0.3395904436860068, 'acc_norm_stderr': 0.013839039762820164}, 'arc_easy': {'acc': 0.6498316498316499, 'acc_stderr': 0.009788295410093144, 'acc_norm': 0.5955387205387206, 'acc_norm_stderr': 0.010070746648278795}}, 'versions': {'lambada_openai': 0, 'boolq': 1, 'openbookqa': 0, 'piqa': 0, 'arc_challenge': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f2d97d54910>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-13 06:32:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.330963134765625, 'ptb': 13.518195152282715, 'c4': 12.223784446716309, 'results': {'boolq': {'acc': 0.6730886850152905, 'acc_stderr': 0.008204340208838748}, 'piqa': {'acc': 0.7551686615886833, 'acc_stderr': 0.010032309105568802, 'acc_norm': 0.7665941240478781, 'acc_norm_stderr': 0.009869247889520994}, 'arc_challenge': {'acc': 0.30119453924914674, 'acc_stderr': 0.01340674176784762, 'acc_norm': 0.3412969283276451, 'acc_norm_stderr': 0.01385583128749772}, 'lambada_openai': {'ppl': 4.0935208008715405, 'ppl_stderr': 0.08944824286679376, 'acc': 0.6896953231127498, 'acc_stderr': 0.006445177376219966}, 'arc_easy': {'acc': 0.6519360269360269, 'acc_stderr': 0.009774627600259012, 'acc_norm': 0.6039562289562289, 'acc_norm_stderr': 0.01003558096209793}, 'openbookqa': {'acc': 0.266, 'acc_stderr': 0.01978055967565549, 'acc_norm': 0.368, 'acc_norm_stderr': 0.021588982568353544}}, 'versions': {'boolq': 1, 'piqa': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'arc_easy': 0, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f4cb35ac910>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-13 07:57:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.34409236907959, 'ptb': 13.517022132873535, 'c4': 12.225720405578613, 'results': {'arc_easy': {'acc': 0.6460437710437711, 'acc_stderr': 0.00981237064417442, 'acc_norm': 0.5984848484848485, 'acc_norm_stderr': 0.010058790020755562}, 'openbookqa': {'acc': 0.268, 'acc_stderr': 0.019827714859587574, 'acc_norm': 0.376, 'acc_norm_stderr': 0.021683827539286122}, 'arc_challenge': {'acc': 0.2986348122866894, 'acc_stderr': 0.013374078615068756, 'acc_norm': 0.34044368600682595, 'acc_norm_stderr': 0.01384746051889298}, 'lambada_openai': {'ppl': 4.135140482870512, 'ppl_stderr': 0.09055151739542099, 'acc': 0.6906656316708714, 'acc_stderr': 0.006439617662597991}, 'boolq': {'acc': 0.6651376146788991, 'acc_stderr': 0.008254323342627932}, 'piqa': {'acc': 0.7557127312295974, 'acc_stderr': 0.010024765172284253, 'acc_norm': 0.7676822633297062, 'acc_norm_stderr': 0.009853201384168243}}, 'versions': {'arc_easy': 0, 'openbookqa': 0, 'arc_challenge': 0, 'lambada_openai': 0, 'boolq': 1, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7eff1ee308b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-14 15:44:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.248958587646484, 'ptb': 14.801794052124023, 'c4': 13.14157485961914, 'results': {'arc_challenge': {'acc': 0.28242320819112626, 'acc_stderr': 0.013155456884097224, 'acc_norm': 0.3319112627986348, 'acc_norm_stderr': 0.013760988200880536}, 'lambada_openai': {'ppl': 4.776344598727041, 'ppl_stderr': 0.10668000729392739, 'acc': 0.6594216960993596, 'acc_stderr': 0.006602405259021264}, 'piqa': {'acc': 0.7475516866158868, 'acc_stderr': 0.01013566554736237, 'acc_norm': 0.7616974972796517, 'acc_norm_stderr': 0.009940334245876214}, 'boolq': {'acc': 0.6443425076452599, 'acc_stderr': 0.008372726639977393}, 'openbookqa': {'acc': 0.27, 'acc_stderr': 0.01987435483128748, 'acc_norm': 0.364, 'acc_norm_stderr': 0.02153917063731769}, 'arc_easy': {'acc': 0.6296296296296297, 'acc_stderr': 0.009908978578665758, 'acc_norm': 0.5757575757575758, 'acc_norm_stderr': 0.010141333654958559}}, 'versions': {'arc_challenge': 0, 'lambada_openai': 0, 'piqa': 0, 'boolq': 1, 'openbookqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f00bf65c880>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-14 17:11:53 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.160250663757324, 'ptb': 14.787666320800781, 'c4': 13.053017616271973, 'results': {'openbookqa': {'acc': 0.272, 'acc_stderr': 0.019920483209566072, 'acc_norm': 0.384, 'acc_norm_stderr': 0.021772369465547194}, 'arc_challenge': {'acc': 0.30887372013651876, 'acc_stderr': 0.013501770929344, 'acc_norm': 0.3378839590443686, 'acc_norm_stderr': 0.013822047922283514}, 'arc_easy': {'acc': 0.6325757575757576, 'acc_stderr': 0.009892552616211558, 'acc_norm': 0.5757575757575758, 'acc_norm_stderr': 0.010141333654958557}, 'lambada_openai': {'ppl': 4.893431063595831, 'ppl_stderr': 0.11043456383724723, 'acc': 0.6497186105181447, 'acc_stderr': 0.006646350771961375}, 'piqa': {'acc': 0.7546245919477693, 'acc_stderr': 0.010039831320422398, 'acc_norm': 0.7606093579978237, 'acc_norm_stderr': 0.00995588425029168}, 'boolq': {'acc': 0.6483180428134556, 'acc_stderr': 0.008351445237661381}}, 'versions': {'openbookqa': 0, 'arc_challenge': 0, 'arc_easy': 0, 'lambada_openai': 0, 'piqa': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f02dec14940>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-14 18:38:20 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.09831714630127, 'ptb': 14.65667724609375, 'c4': 13.009496688842773, 'results': {'arc_easy': {'acc': 0.6397306397306397, 'acc_stderr': 0.009851002584732385, 'acc_norm': 0.5892255892255892, 'acc_norm_stderr': 0.010095101349348656}, 'lambada_openai': {'ppl': 4.729329589974133, 'ppl_stderr': 0.10469607706991997, 'acc': 0.6594216960993596, 'acc_stderr': 0.0066024052590212615}, 'arc_challenge': {'acc': 0.29948805460750855, 'acc_stderr': 0.013385021637313572, 'acc_norm': 0.3319112627986348, 'acc_norm_stderr': 0.01376098820088054}, 'piqa': {'acc': 0.749183895538629, 'acc_stderr': 0.010113869547069044, 'acc_norm': 0.7573449401523396, 'acc_norm_stderr': 0.010002002569708688}, 'boolq': {'acc': 0.6522935779816513, 'acc_stderr': 0.008329529048948695}, 'openbookqa': {'acc': 0.246, 'acc_stderr': 0.019279819056352548, 'acc_norm': 0.36, 'acc_norm_stderr': 0.02148775108972053}}, 'versions': {'arc_easy': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'openbookqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f302dcb4820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-14 20:02:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.063011169433594, 'ptb': 14.591300010681152, 'c4': 12.956231117248535, 'results': {'piqa': {'acc': 0.7486398258977149, 'acc_stderr': 0.01012115601681926, 'acc_norm': 0.7573449401523396, 'acc_norm_stderr': 0.010002002569708688}, 'arc_easy': {'acc': 0.6338383838383839, 'acc_stderr': 0.009885391390947726, 'acc_norm': 0.5824915824915825, 'acc_norm_stderr': 0.01011918737777604}, 'openbookqa': {'acc': 0.26, 'acc_stderr': 0.019635965529725512, 'acc_norm': 0.372, 'acc_norm_stderr': 0.0216371979857224}, 'lambada_openai': {'ppl': 4.681763826877339, 'ppl_stderr': 0.10346750218255657, 'acc': 0.6594216960993596, 'acc_stderr': 0.0066024052590212615}, 'arc_challenge': {'acc': 0.29436860068259385, 'acc_stderr': 0.013318528460539426, 'acc_norm': 0.33361774744027306, 'acc_norm_stderr': 0.013778687054176541}, 'boolq': {'acc': 0.6504587155963303, 'acc_stderr': 0.008339723407282292}}, 'versions': {'piqa': 0, 'arc_easy': 0, 'openbookqa': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'boolq': 1}, 'config': {'model': <models.opt.OPTClass object at 0x7f9695754820>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 1 --topk_num_final_layer_norm 1 --topk_num_fc2 1 --topk_num_out_proj_head 1 --topk_num_q_proj_head 1 2023-09-14 21:24:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=1, topk_num_final_layer_norm=1, topk_num_fc2=1, topk_num_out_proj_head=1, topk_num_q_proj_head=1, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.357154846191406, 'ptb': 13.515849113464355, 'c4': 12.22910213470459, 'results': {'lambada_openai': {'ppl': 4.068802449354715, 'ppl_stderr': 0.08849967282033497, 'acc': 0.694352804191733, 'acc_stderr': 0.006418187162765871}, 'boolq': {'acc': 0.655045871559633, 'acc_stderr': 0.008313981812572256}, 'arc_challenge': {'acc': 0.302901023890785, 'acc_stderr': 0.013428241573185347, 'acc_norm': 0.33447098976109213, 'acc_norm_stderr': 0.013787460322441379}, 'openbookqa': {'acc': 0.258, 'acc_stderr': 0.019586711785215837, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}, 'arc_easy': {'acc': 0.6494107744107744, 'acc_stderr': 0.00979100382983156, 'acc_norm': 0.5984848484848485, 'acc_norm_stderr': 0.01005879002075556}, 'piqa': {'acc': 0.7589771490750816, 'acc_stderr': 0.009979042717267315, 'acc_norm': 0.76550598476605, 'acc_norm_stderr': 0.00988520314324054}}, 'versions': {'lambada_openai': 0, 'boolq': 1, 'arc_challenge': 0, 'openbookqa': 0, 'arc_easy': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f655de188b0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 2 --topk_num_final_layer_norm 2 --topk_num_fc2 2 --topk_num_out_proj_head 2 --topk_num_q_proj_head 2 2023-09-14 22:45:42 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.344725608825684, 'ptb': 13.52054214477539, 'c4': 12.222991943359375, 'results': {'openbookqa': {'acc': 0.264, 'acc_stderr': 0.019732885585922098, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}, 'lambada_openai': {'ppl': 4.133253090458695, 'ppl_stderr': 0.09004608103081814, 'acc': 0.6960993595963516, 'acc_stderr': 0.006407867125328482}, 'arc_challenge': {'acc': 0.2977815699658703, 'acc_stderr': 0.013363080107244487, 'acc_norm': 0.3387372013651877, 'acc_norm_stderr': 0.01383056892797433}, 'piqa': {'acc': 0.7589771490750816, 'acc_stderr': 0.009979042717267317, 'acc_norm': 0.7665941240478781, 'acc_norm_stderr': 0.009869247889520993}, 'boolq': {'acc': 0.6617737003058104, 'acc_stderr': 0.008274675638686672}, 'arc_easy': {'acc': 0.6447811447811448, 'acc_stderr': 0.009820245899287117, 'acc_norm': 0.6005892255892256, 'acc_norm_stderr': 0.010050018228742125}}, 'versions': {'openbookqa': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f03922f88e0>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 4 --topk_num_final_layer_norm 4 --topk_num_fc2 4 --topk_num_out_proj_head 4 --topk_num_q_proj_head 4 2023-09-15 00:06:27 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=4, topk_num_final_layer_norm=4, topk_num_fc2=4, topk_num_out_proj_head=4, topk_num_q_proj_head=4, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.326221466064453, 'ptb': 13.52112865447998, 'c4': 12.218936920166016, 'results': {'arc_challenge': {'acc': 0.2986348122866894, 'acc_stderr': 0.013374078615068756, 'acc_norm': 0.33361774744027306, 'acc_norm_stderr': 0.013778687054176541}, 'lambada_openai': {'ppl': 4.143540429555492, 'ppl_stderr': 0.09056946881669627, 'acc': 0.6879487677081312, 'acc_stderr': 0.006455101452842896}, 'piqa': {'acc': 0.7589771490750816, 'acc_stderr': 0.009979042717267317, 'acc_norm': 0.7611534276387377, 'acc_norm_stderr': 0.00994812038533748}, 'boolq': {'acc': 0.6639143730886851, 'acc_stderr': 0.008261778456573674}, 'openbookqa': {'acc': 0.256, 'acc_stderr': 0.019536923574747605, 'acc_norm': 0.374, 'acc_norm_stderr': 0.02166071034720448}, 'arc_easy': {'acc': 0.6418350168350169, 'acc_stderr': 0.009838331651451844, 'acc_norm': 0.5955387205387206, 'acc_norm_stderr': 0.010070746648278792}}, 'versions': {'arc_challenge': 0, 'lambada_openai': 0, 'piqa': 0, 'boolq': 1, 'openbookqa': 0, 'arc_easy': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7efcfce18910>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-15 01:27:44 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a8 {'wikitext2': 11.365316390991211, 'ptb': 13.508223533630371, 'c4': 12.219006538391113, 'results': {'boolq': {'acc': 0.6666666666666666, 'acc_stderr': 0.008244916900880283}, 'openbookqa': {'acc': 0.272, 'acc_stderr': 0.019920483209566072, 'acc_norm': 0.376, 'acc_norm_stderr': 0.021683827539286122}, 'arc_easy': {'acc': 0.6464646464646465, 'acc_stderr': 0.009809728948151493, 'acc_norm': 0.5904882154882155, 'acc_norm_stderr': 0.010090368160990062}, 'lambada_openai': {'ppl': 4.129252149834849, 'ppl_stderr': 0.09004358673417184, 'acc': 0.6922181253638657, 'acc_stderr': 0.006430653014376231}, 'arc_challenge': {'acc': 0.30204778156996587, 'acc_stderr': 0.01341751914471642, 'acc_norm': 0.3447098976109215, 'acc_norm_stderr': 0.01388881628678211}, 'piqa': {'acc': 0.7568008705114254, 'acc_stderr': 0.010009611953858912, 'acc_norm': 0.7622415669205659, 'acc_norm_stderr': 0.009932525779525492}}, 'versions': {'boolq': 1, 'openbookqa': 0, 'arc_easy': 0, 'lambada_openai': 0, 'arc_challenge': 0, 'piqa': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7f97b5ef4760>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai 2023-09-19 11:11:13 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=0, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', pack_weight=False, percdamp=0.01, reorder='12345', seed=2, tasks='lambada_openai', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, w_quantizer='gptq', wbits=4) 
 w4a4 {'wikitext2': 10.859848976135254, 'ptb': 13.086371421813965, 'c4': 11.742904663085938, 'results': {'lambada_openai': {'ppl': 4.75240956324051, 'ppl_stderr': 0.10709122166403184, 'acc': 0.6171162429652629, 'acc_stderr': 0.0067721884226138625}}, 'versions': {'lambada_openai': 0}, 'config': {'model': <models.opt.OPTClass object at 0x7effcd4ac610>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 15:24:09 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 11.382851600646973, 'ptb': 13.571105003356934, 'c4': 12.256118774414062}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 15:49:24 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=False, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 12.395505905151367, 'ptb': 15.228629112243652, 'c4': 13.34093952178955}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 19:27:42 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 11.33191204071045, 'ptb': 14.082345962524414, 'c4': 12.34882926940918}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 2023-09-20 19:50:32 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=8, topk_num_fc2=8, topk_num_final_layer_norm=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 12.561758041381836, 'ptb': 15.921412467956543, 'c4': 13.797335624694824}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 512 2023-09-20 22:25:24 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=512, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 11.402402877807617, 'ptb': 14.22362995147705, 'c4': 12.421990394592285}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 64 2023-09-20 22:50:05 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=64, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 11.267043113708496, 'ptb': 13.912845611572266, 'c4': 12.313150405883789}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 32 2023-09-20 23:17:14 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=32, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 11.286867141723633, 'ptb': 14.03414249420166, 'c4': 12.348970413208008}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 16 2023-09-20 23:50:16 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=16, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 11.348206520080566, 'ptb': 14.187251091003418, 'c4': 12.4940824508667}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 8 2023-09-21 00:35:11 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=8, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 11.568560600280762, 'ptb': 14.583067893981934, 'c4': 12.813252449035645}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 512 2023-09-21 00:57:12 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=512, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 12.713201522827148, 'ptb': 16.6514949798584, 'c4': 14.065492630004883}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 64 2023-09-21 01:21:29 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=64, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 12.218493461608887, 'ptb': 15.119301795959473, 'c4': 13.377275466918945}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 32 2023-09-21 01:48:37 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=32, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 11.993370056152344, 'ptb': 15.084564208984375, 'c4': 13.154214859008789}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 16 2023-09-21 02:22:12 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=16, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 12.051738739013672, 'ptb': 15.107497215270996, 'c4': 13.156271934509277}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 8 2023-09-21 03:08:18 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=4, act_dist_plot=False, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=8, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a4 {'wikitext2': 12.350625038146973, 'ptb': 15.382080078125, 'c4': 13.532922744750977}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 512 2023-09-21 14:31:30 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=512, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 11.10451889038086, 'ptb': 13.308615684509277, 'c4': 11.9818696975708}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 256 2023-09-21 14:52:49 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=256, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 11.034408569335938, 'ptb': 13.316123962402344, 'c4': 11.969215393066406}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 64 2023-09-21 15:16:16 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=64, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 10.940597534179688, 'ptb': 13.224546432495117, 'c4': 11.9299898147583}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 32 2023-09-21 15:42:39 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=32, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 10.967876434326172, 'ptb': 13.193016052246094, 'c4': 11.914891242980957}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 16 2023-09-21 16:15:11 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=16, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 10.954879760742188, 'ptb': 13.174703598022461, 'c4': 11.91818618774414}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --group_size 8 2023-09-21 17:00:15 
 Namespace(R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, a_dynamic=False, abits=8, act_dist_plot=False, act_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, batch_size=1, cache_dir='./data/opt/6.7b', calib_dataset='mix', disable_a_quant=False, disable_w_quant=False, eval_base_ppl=False, eval_ppl=True, group128=1, group_size=8, k_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, limit=-1, load='', metric='ema_minmax', model='facebook/opt-6.7b', multigpu=True, net='opt-6.7b', nsamples=128, num_fewshot=0, only_quant_kv=False, output_path='./output', p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}, pack_weight=False, percdamp=0.01, q_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, reorder='12345', seed=2, tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', topk_num=2, topk_num_fc2=2, topk_num_final_layer_norm=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, v_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, w_quantizer='gptq', wbits=4, weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}) 
 w4a8 {'wikitext2': 10.963212013244629, 'ptb': 13.164989471435547, 'c4': 11.920869827270508}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-10-30 11:09:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.931291580200195, 'ptb': 13.265939712524414, 'c4': 11.844151496887207}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-01 19:02:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 13.122344970703125, 'ptb': 16.65005111694336, 'c4': 12.786688804626465}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-01 19:30:53 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 13.23559856414795, 'ptb': 16.626941680908203, 'c4': 12.87540340423584}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-01 19:51:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 13.286938667297363, 'ptb': 16.814903259277344, 'c4': 12.902692794799805}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-02 11:08:14 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.946554183959961, 'ptb': 13.162129402160645, 'c4': 11.778122901916504}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-02 11:47:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.96114730834961, 'ptb': 13.275154113769531, 'c4': 11.834102630615234}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-02 17:45:38 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.962599754333496, 'ptb': 13.315546035766602, 'c4': 11.869185447692871}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-02 19:15:08 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.014413833618164, 'ptb': 13.282071113586426, 'c4': 11.852445602416992}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 09:23:52 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.004507064819336, 'ptb': 13.265360832214355, 'c4': 11.846613883972168}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-03 16:16:03 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 19:16:42 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 471.9325256347656, 'ptb': 556.9056396484375, 'c4': 292.2061767578125}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 19:32:31 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 390.0250244140625, 'ptb': 425.1451721191406, 'c4': 242.52484130859375}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 19:50:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 432.34521484375, 'ptb': 513.80322265625, 'c4': 275.6776428222656}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:14:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.043701410293579, 'ptb': 1.145411491394043, 'c4': 1.0254027843475342}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:21:15 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 390.0250244140625, 'ptb': 425.1451721191406, 'c4': 242.52484130859375}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:42:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.044050931930542}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:49:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.044050931930542}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:52:38 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.044546365737915}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:54:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.044546365737915}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 20:56:58 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.044546365737915}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:00:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.0442841053009033}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:03:03 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.044546365737915}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:08:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.044546365737915}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:23:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.0442841053009033}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:29:57 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.0155351161956787}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:31:25 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.015492558479309}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:36:38 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.8599271774292, 'ptb': 13.085803985595703, 'c4': 11.742524147033691}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-05 21:54:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.85061264038086, 'ptb': 13.096596717834473, 'c4': 11.74870777130127}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 09:52:31 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.382376670837402, 'ptb': 13.808771133422852, 'c4': 12.153715133666992}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 10:29:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.842970848083496, 'ptb': 13.133597373962402, 'c4': 11.771610260009766}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 10:50:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.091049194335938, 'ptb': 13.408919334411621, 'c4': 11.99515438079834}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 11:12:11 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.891865730285645, 'ptb': 13.145003318786621, 'c4': 11.80767822265625}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 11:34:05 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.860380172729492, 'ptb': 13.101146697998047, 'c4': 11.764359474182129}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 14:50:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.037565231323242, 'ptb': 13.365921974182129, 'c4': 11.960429191589355}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 14:58:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.016412734985352, 'ptb': 13.288989067077637, 'c4': 11.875345230102539}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 16:11:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.703049659729004, 'ptb': 13.168416023254395, 'c4': 11.796355247497559}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 16:39:20 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.6920804977417, 'ptb': 13.368823051452637, 'c4': 11.907960891723633}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 18:43:55 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.728165626525879, 'ptb': 13.201608657836914, 'c4': 11.816329956054688}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 19:22:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.855305671691895, 'ptb': 13.142722129821777, 'c4': 11.770980834960938}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-06 19:55:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.881991386413574, 'ptb': 13.162703514099121, 'c4': 11.78454875946045}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 10:44:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.937240600585938, 'ptb': 13.248101234436035, 'c4': 11.845235824584961}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 11:08:19 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.898097038269043, 'ptb': 13.267091751098633, 'c4': 11.855091094970703}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 12:49:03 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.688725471496582, 'ptb': 13.288989067077637, 'c4': 11.875073432922363}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 12:49:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.693721771240234, 'ptb': 13.27630615234375, 'c4': 11.860970497131348}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 13:25:28 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.961069107055664, 'ptb': 13.234308242797852, 'c4': 11.827603340148926}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 13:57:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1313.560546875, 'ptb': 962.664794921875, 'c4': 536.5972290039062}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 14:09:07 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.777894973754883, 'ptb': 13.294758796691895, 'c4': 11.887446403503418}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 14:50:01 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.8330659866333, 'ptb': 13.10228443145752, 'c4': 11.755141258239746}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 15:17:58 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.747637748718262, 'ptb': 13.121631622314453, 'c4': 11.764629364013672}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 15:45:40 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.827025413513184, 'ptb': 13.103989601135254, 'c4': 11.751867294311523}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 16:18:56 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.78210735321045, 'ptb': 13.107401847839355, 'c4': 11.754557609558105}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 16:50:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.817436218261719, 'ptb': 13.2188081741333, 'c4': 11.852625846862793}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 19:05:40 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.843501091003418, 'ptb': 13.199315071105957, 'c4': 11.837782859802246}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 19:44:19 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.802279472351074, 'ptb': 13.10228443145752, 'c4': 11.751644134521484}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 20:26:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.717768669128418, 'ptb': 13.201032638549805, 'c4': 11.829205513000488}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-07 21:00:03 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.847131729125977, 'ptb': 13.13644790649414, 'c4': 11.783875465393066}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 10:31:49 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.763470649719238, 'ptb': 13.150712013244629, 'c4': 11.793183326721191}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 11:09:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.835864067077637, 'ptb': 13.126190185546875, 'c4': 11.780549049377441}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 11:43:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.797006607055664, 'ptb': 13.135308265686035, 'c4': 11.78502082824707}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 12:22:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.814345359802246, 'ptb': 13.131888389587402, 'c4': 11.780661582946777}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 13:06:16 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.892016410827637, 'ptb': 13.1850004196167, 'c4': 11.834576606750488}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 13:40:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.879791259765625, 'ptb': 13.190727233886719, 'c4': 11.831258773803711}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 14:09:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.883208274841309, 'ptb': 13.18099594116211, 'c4': 11.82735538482666}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 14:44:43 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.83238697052002, 'ptb': 13.127900123596191, 'c4': 11.778953552246094}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 19:17:03 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.82868480682373, 'ptb': 13.109676361083984, 'c4': 11.754781723022461}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-08 19:49:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.810346603393555, 'ptb': 13.113662719726562, 'c4': 11.756553649902344}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 10:10:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.829366683959961, 'ptb': 13.106833457946777, 'c4': 11.754983901977539}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 10:24:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.788424491882324, 'ptb': 13.111956596374512, 'c4': 11.76083755493164}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 11:01:19 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.833144187927246, 'ptb': 13.113094329833984, 'c4': 11.7567777633667}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 11:32:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.75041389465332, 'ptb': 13.12562084197998, 'c4': 11.769768714904785}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 12:03:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.84251594543457, 'ptb': 13.122771263122559, 'c4': 11.760433197021484}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 13:04:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.705737113952637, 'ptb': 13.178709030151367, 'c4': 11.798178672790527}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 13:11:03 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.866215705871582, 'ptb': 13.096596717834473, 'c4': 11.746623992919922}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 13:29:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.882220268249512, 'ptb': 13.105695724487305, 'c4': 11.762676239013672}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 13:51:41 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.720233917236328, 'ptb': 13.206765174865723, 'c4': 11.817591667175293}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 14:21:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.849249839782715, 'ptb': 13.13644790649414, 'c4': 11.77726936340332}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 14:50:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.767600059509277, 'ptb': 13.159844398498535, 'c4': 11.785426139831543}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 15:20:15 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.845995903015137, 'ptb': 13.133597373962402, 'c4': 11.771183013916016}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 15:49:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.800548553466797, 'ptb': 13.147856712341309, 'c4': 11.777584075927734}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 16:19:41 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.84705638885498, 'ptb': 13.137590408325195, 'c4': 11.769678115844727}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 18:44:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.860152244567871, 'ptb': 13.087507247924805, 'c4': 11.742703437805176}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 18:52:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.860152244567871, 'ptb': 13.087507247924805, 'c4': 11.742703437805176}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 18:58:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.860152244567871, 'ptb': 13.087507247924805, 'c4': 11.742703437805176}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 19:25:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.860152244567871, 'ptb': 13.087507247924805, 'c4': 11.742703437805176}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 19:43:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.860152244567871, 'ptb': 13.087507247924805, 'c4': 11.742703437805176}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 20:08:23 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.858260154724121, 'ptb': 13.085803985595703, 'c4': 11.74353313446045}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 20:24:04 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.874327659606934, 'ptb': 13.087507247924805, 'c4': 11.804255485534668}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 20:42:41 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.860608100891113, 'ptb': 13.086939811706543, 'c4': 11.742793083190918}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-09 20:57:58 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.860304832458496, 'ptb': 13.087507247924805, 'c4': 11.743062019348145}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 09:35:52 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.861214637756348, 'ptb': 13.085803985595703, 'c4': 11.742815971374512}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 09:53:07 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.86197280883789, 'ptb': 13.086939811706543, 'c4': 11.743128776550293}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 10:08:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.864169120788574, 'ptb': 13.088074684143066, 'c4': 11.74272632598877}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 10:26:40 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.86826229095459, 'ptb': 13.087507247924805, 'c4': 11.743756294250488}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 11:02:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.878806114196777, 'ptb': 13.091483116149902, 'c4': 11.746086120605469}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 11:17:49 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.902962684631348, 'ptb': 13.098301887512207, 'c4': 11.753414154052734}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 11:33:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.971166610717773, 'ptb': 13.137590408325195, 'c4': 11.777897834777832}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 11:50:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.187944412231445, 'ptb': 13.28668212890625, 'c4': 11.878268241882324}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:39:52 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.8737211227417, 'ptb': 13.086371421813965, 'c4': 11.804503440856934}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:39:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.87394905090332, 'ptb': 13.086939811706543, 'c4': 11.804346084594727}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:40:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.87394905090332, 'ptb': 13.086939811706543, 'c4': 11.804503440856934}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:40:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.875162124633789, 'ptb': 13.086939811706543, 'c4': 11.804098129272461}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:46:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.877060890197754, 'ptb': 13.086371421813965, 'c4': 11.804953575134277}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:46:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.882372856140137, 'ptb': 13.085803985595703, 'c4': 11.805628776550293}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:46:42 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.891865730285645, 'ptb': 13.089210510253906, 'c4': 11.808849334716797}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:46:55 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.918335914611816, 'ptb': 13.097734451293945, 'c4': 11.81659984588623}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:53:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.85810661315918, 'ptb': 13.086371421813965, 'c4': 11.743309020996094}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:53:27 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.85810661315918, 'ptb': 13.086939811706543, 'c4': 11.743577003479004}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:53:34 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.85810661315918, 'ptb': 13.086371421813965, 'c4': 11.743309020996094}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:53:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.859395980834961, 'ptb': 13.086371421813965, 'c4': 11.744025230407715}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:59:27 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.86167049407959, 'ptb': 13.089210510253906, 'c4': 11.743868827819824}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:59:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.865456581115723, 'ptb': 13.086939811706543, 'c4': 11.745413780212402}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 13:59:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.875543594360352, 'ptb': 13.089210510253906, 'c4': 11.746466636657715}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 14:00:04 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.897717475891113, 'ptb': 13.099441528320312, 'c4': 11.75404167175293}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 16:15:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.878806114196777, 'ptb': 13.091483116149902, 'c4': 11.746086120605469}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:45:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.061456680297852, 'ptb': 13.119924545288086, 'c4': 11.83035659790039}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:45:27 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.84561824798584, 'ptb': 13.076150894165039, 'c4': 11.7393217086792}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:52:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.86424446105957, 'ptb': 13.084664344787598, 'c4': 11.741851806640625}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:52:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.855758666992188, 'ptb': 13.081827163696289, 'c4': 11.740464210510254}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:59:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.84561824798584, 'ptb': 13.076150894165039, 'c4': 11.7393217086792}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 18:59:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.84433364868164, 'ptb': 13.082962036132812, 'c4': 11.745234489440918}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 19:07:46 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.879866600036621, 'ptb': 13.117646217346191, 'c4': 11.775202751159668}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-10 19:08:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.023022651672363, 'ptb': 13.252700805664062, 'c4': 11.885406494140625}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:20:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.845163345336914, 'ptb': 13.072175979614258, 'c4': 11.739209175109863}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:20:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.845163345336914, 'ptb': 13.072175979614258, 'c4': 11.739209175109863}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:27:48 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.845163345336914, 'ptb': 13.072175979614258, 'c4': 11.739209175109863}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:28:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.845163345336914, 'ptb': 13.072175979614258, 'c4': 11.739209175109863}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:35:48 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.845163345336914, 'ptb': 13.072175979614258, 'c4': 11.739209175109863}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:36:17 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.845163345336914, 'ptb': 13.072175979614258, 'c4': 11.739209175109863}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:43:10 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.862804412841797, 'ptb': 13.086939811706543, 'c4': 11.747228622436523}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 11:43:35 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.894979476928711, 'ptb': 13.094324111938477, 'c4': 11.80900764465332}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 12:09:17 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 12.949487686157227, 'ptb': 14.999038696289062, 'c4': 13.533594131469727}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 12:10:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.843274116516113, 'ptb': 13.071609497070312, 'c4': 11.7393217086792}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 12:17:05 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.844255447387695, 'ptb': 13.065372467041016, 'c4': 11.740150451660156}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 12:17:44 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.845391273498535, 'ptb': 13.056867599487305, 'c4': 11.7423677444458}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 13:03:01 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.884041786193848, 'ptb': 13.054600715637207, 'c4': 11.762408256530762}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 13:03:35 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 41.7559928894043, 'ptb': 26.41684341430664, 'c4': 50.16901397705078}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:36:53 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.838434219360352, 'ptb': 13.071609497070312, 'c4': 11.73925495147705}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:37:11 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.838434219360352, 'ptb': 13.071609497070312, 'c4': 11.73925495147705}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:45:05 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.838434219360352, 'ptb': 13.071609497070312, 'c4': 11.73925495147705}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:45:23 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.838434219360352, 'ptb': 13.071609497070312, 'c4': 11.73925495147705}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:53:11 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.838434219360352, 'ptb': 13.071609497070312, 'c4': 11.73925495147705}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 16:53:34 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.838434219360352, 'ptb': 13.071609497070312, 'c4': 11.73925495147705}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 17:01:07 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.838434219360352, 'ptb': 13.071609497070312, 'c4': 11.73925495147705}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 17:01:28 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.838434219360352, 'ptb': 13.071609497070312, 'c4': 11.73925495147705}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 17:08:57 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.838434219360352, 'ptb': 13.071609497070312, 'c4': 11.73925495147705}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 17:09:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 940.25341796875, 'ptb': 981.7367553710938, 'c4': 684.336669921875}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 17:16:51 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.836091041564941, 'ptb': 13.07104206085205, 'c4': 11.739904403686523}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 17:20:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.827174186706543, 'ptb': 13.073882102966309, 'c4': 11.74055290222168}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 17:24:43 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.812006950378418, 'ptb': 13.08239459991455, 'c4': 11.746086120605469}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 17:27:49 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.796029090881348, 'ptb': 13.115939140319824, 'c4': 11.766154289245605}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 17:29:23 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811101913452148, 'ptb': 13.24695110321045, 'c4': 11.847811698913574}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 19:52:16 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.8428955078125, 'ptb': 13.070475578308105, 'c4': 11.739814758300781}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 20:24:49 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.820229530334473, 'ptb': 13.087507247924805, 'c4': 11.754334449768066}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-13 21:02:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.820077896118164, 'ptb': 13.088074684143066, 'c4': 11.754692077636719}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 10:41:44 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.859848976135254, 'ptb': 13.086371421813965, 'c4': 11.742904663085938}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:42:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.901823997497559, 'ptb': 13.141011238098145, 'c4': 11.804570198059082}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 11:54:15 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.867884635925293, 'ptb': 13.101146697998047, 'c4': 11.762699127197266}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:16:14 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 15685.484375, 'ptb': 13034.40234375, 'c4': 13803.173828125}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:23:55 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.88890266418457, 'ptb': 13.125051498413086, 'c4': 11.759603500366211}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:34:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.898933410644531, 'ptb': 13.134737014770508, 'c4': 11.769970893859863}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:49:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.10359001159668, 'ptb': 13.440384864807129, 'c4': 11.997031211853027}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 14:58:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.966422080993652, 'ptb': 13.294182777404785, 'c4': 11.845664978027344}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:05:57 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.005659103393555, 'ptb': 13.459648132324219, 'c4': 11.888829231262207}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:17:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 12.3605375289917, 'ptb': 16.184778213500977, 'c4': 13.729947090148926}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:26:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.68094539642334, 'ptb': 14.540090560913086, 'c4': 12.32231330871582}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:32:40 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 12.214232444763184, 'ptb': 15.655537605285645, 'c4': 12.75035285949707}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 15:54:42 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.866671562194824, 'ptb': 13.094892501831055, 'c4': 11.746781349182129}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 16:03:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.867656707763672, 'ptb': 13.095459938049316, 'c4': 11.747879028320312}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 16:23:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.825212478637695, 'ptb': 13.108539581298828, 'c4': 11.756060600280762}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 16:40:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.822569847106934, 'ptb': 13.101146697998047, 'c4': 11.756643295288086}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 19:33:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.822569847106934, 'ptb': 13.101146697998047, 'c4': 11.756643295288086}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 19:55:48 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.823020935058594, 'ptb': 13.099441528320312, 'c4': 11.756957054138184}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 19:56:16 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.865306854248047, 'ptb': 13.103421211242676, 'c4': 11.75487232208252}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 19:56:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 703.8049926757812, 'ptb': 729.6914672851562, 'c4': 396.6352233886719}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 20:18:58 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.82271957397461, 'ptb': 13.093755722045898, 'c4': 11.751420021057129}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 20:18:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.82105827331543, 'ptb': 13.09205150604248, 'c4': 11.754356384277344}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 20:19:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.82921314239502, 'ptb': 13.101715087890625, 'c4': 11.752854347229004}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-14 20:48:38 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.884572982788086, 'ptb': 13.163274765014648, 'c4': 11.786235809326172}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 09:49:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.82921314239502, 'ptb': 13.101715087890625, 'c4': 11.752854347229004}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 09:49:35 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.846299171447754, 'ptb': 13.114232063293457, 'c4': 11.767770767211914}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 14:27:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.81517219543457, 'ptb': 13.105127334594727, 'c4': 11.755186080932617}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 14:28:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.820908546447754, 'ptb': 13.10000991821289, 'c4': 11.753885269165039}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 14:29:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.81057357788086, 'ptb': 13.099441528320312, 'c4': 11.756351470947266}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 14:55:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.799943923950195, 'ptb': 13.124482154846191, 'c4': 11.779763221740723}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 14:57:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.806275367736816, 'ptb': 13.097734451293945, 'c4': 11.759042739868164}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 14:57:27 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.804841995239258, 'ptb': 13.097734451293945, 'c4': 11.767816543579102}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 17:49:27 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.804841995239258, 'ptb': 13.097734451293945, 'c4': 11.767816543579102}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 17:52:50 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.803938865661621, 'ptb': 13.09887409210205, 'c4': 11.76759147644043}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 17:53:02 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.805520057678223, 'ptb': 13.097734451293945, 'c4': 11.766401290893555}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 18:56:41 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.800323486328125, 'ptb': 13.110246658325195, 'c4': 11.76817512512207}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 19:00:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.792490005493164, 'ptb': 13.114232063293457, 'c4': 11.773001670837402}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 19:00:51 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.767826080322266, 'ptb': 13.145573616027832, 'c4': 11.795252799987793}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 19:24:57 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.803938865661621, 'ptb': 13.09887409210205, 'c4': 11.76759147644043}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 19:26:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.803938865661621, 'ptb': 13.09887409210205, 'c4': 11.76759147644043}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 19:28:53 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.80175495147705, 'ptb': 13.117077827453613, 'c4': 11.768488883972168}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 21:29:14 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.802506446838379, 'ptb': 13.121062278747559, 'c4': 11.766670227050781}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 21:31:10 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.824910163879395, 'ptb': 13.113662719726562, 'c4': 11.764246940612793}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 21:31:28 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811177253723145, 'ptb': 13.10228443145752, 'c4': 11.766895294189453}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 22:21:54 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.8001708984375, 'ptb': 13.110246658325195, 'c4': 11.767500877380371}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 22:23:17 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.801226615905762, 'ptb': 13.106833457946777, 'c4': 11.767792701721191}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-15 22:23:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.804391860961914, 'ptb': 13.115370750427246, 'c4': 11.768691062927246}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 10:02:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.805520057678223, 'ptb': 13.097734451293945, 'c4': 11.758953094482422}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 10:26:55 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.812759399414062, 'ptb': 13.103421211242676, 'c4': 11.758077621459961}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 15:00:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.812759399414062, 'ptb': 13.103421211242676, 'c4': 11.758077621459961}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 16:52:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.809367179870605, 'ptb': 13.10228443145752, 'c4': 11.75985050201416}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 16:53:41 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.807632446289062, 'ptb': 13.107401847839355, 'c4': 11.758953094482422}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 16:53:43 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.807783126831055, 'ptb': 13.101715087890625, 'c4': 11.7567777633667}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 16:54:34 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.808686256408691, 'ptb': 13.094324111938477, 'c4': 11.757988929748535}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 17:14:45 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.809367179870605, 'ptb': 13.10228443145752, 'c4': 11.75985050201416}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 17:15:58 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.807632446289062, 'ptb': 13.107401847839355, 'c4': 11.758953094482422}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 21:18:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811477661132812, 'ptb': 13.09887409210205, 'c4': 11.755790710449219}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 21:23:05 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811403274536133, 'ptb': 13.09887409210205, 'c4': 11.758684158325195}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 21:25:54 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.813060760498047, 'ptb': 13.107401847839355, 'c4': 11.758279800415039}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-16 21:26:57 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.809893608093262, 'ptb': 13.095459938049316, 'c4': 11.757405281066895}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 09:53:57 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811403274536133, 'ptb': 13.09887409210205, 'c4': 11.758684158325195}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 09:55:56 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811403274536133, 'ptb': 13.09887409210205, 'c4': 11.758684158325195}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 09:56:28 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811403274536133, 'ptb': 13.09887409210205, 'c4': 11.758684158325195}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 09:56:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811403274536133, 'ptb': 13.09887409210205, 'c4': 11.758684158325195}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 10:44:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811403274536133, 'ptb': 13.09887409210205, 'c4': 11.758684158325195}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 11:59:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811403274536133, 'ptb': 13.09887409210205, 'c4': 11.758684158325195}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 12:01:08 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811403274536133, 'ptb': 13.09887409210205, 'c4': 11.758684158325195}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 12:01:57 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.824002265930176, 'ptb': 13.10000991821289, 'c4': 11.758190155029297}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 12:02:14 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811403274536133, 'ptb': 13.09887409210205, 'c4': 11.758684158325195}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 14:47:35 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 12.102031707763672, 'ptb': 13.332319259643555, 'c4': 12.095115661621094}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 14:49:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 12.119180679321289, 'ptb': 13.330580711364746, 'c4': 12.096314430236816}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 14:50:01 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 12.108110427856445, 'ptb': 13.334054946899414, 'c4': 12.093292236328125}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 14:51:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 12.108110427856445, 'ptb': 13.334054946899414, 'c4': 12.093292236328125}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 15:17:13 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.812911987304688, 'ptb': 13.102852821350098, 'c4': 11.759064674377441}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 15:18:31 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 13.898101806640625, 'ptb': 14.109265327453613, 'c4': 12.755606651306152}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 15:18:34 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.821210861206055, 'ptb': 13.105695724487305, 'c4': 11.759334564208984}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 16:10:04 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.805295944213867, 'ptb': 13.118215560913086, 'c4': 11.760029792785645}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 16:10:25 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.788275718688965, 'ptb': 13.150712013244629, 'c4': 11.76882553100586}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 16:10:40 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.81019401550293, 'ptb': 13.108539581298828, 'c4': 11.758010864257812}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 16:11:43 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.810420989990234, 'ptb': 13.09318733215332, 'c4': 11.75711441040039}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 20:23:57 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.81019401550293, 'ptb': 13.108539581298828, 'c4': 11.758010864257812}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 20:25:28 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.81019401550293, 'ptb': 13.108539581298828, 'c4': 11.75792121887207}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 20:26:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.81019401550293, 'ptb': 13.108539581298828, 'c4': 11.758010864257812}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 20:28:15 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.854473114013672, 'ptb': 13.114232063293457, 'c4': 11.774168968200684}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 22:22:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811177253723145, 'ptb': 13.1062650680542, 'c4': 11.759356498718262}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 22:24:42 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.808083534240723, 'ptb': 13.10228443145752, 'c4': 11.759648323059082}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 22:25:14 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.812532424926758, 'ptb': 13.1062650680542, 'c4': 11.759356498718262}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-17 22:27:11 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.810797691345215, 'ptb': 13.101146697998047, 'c4': 11.759154319763184}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 11:25:43 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.809591293334961, 'ptb': 13.105127334594727, 'c4': 11.760411262512207}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 11:26:48 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.788275718688965, 'ptb': 13.153565406799316, 'c4': 11.774258613586426}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 11:29:07 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.801376342773438, 'ptb': 13.121062278747559, 'c4': 11.762676239013672}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 11:31:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.840853691101074, 'ptb': 13.358963966369629, 'c4': 13.964554786682129}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 15:47:42 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.801376342773438, 'ptb': 13.121062278747559, 'c4': 11.762676239013672}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 15:50:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.801376342773438, 'ptb': 13.121062278747559, 'c4': 11.762676239013672}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 15:51:47 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.85053825378418, 'ptb': 13.13074779510498, 'c4': 11.779402732849121}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 16:19:16 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.788275718688965, 'ptb': 13.153565406799316, 'c4': 11.774258613586426}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 16:19:50 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.809591293334961, 'ptb': 13.105127334594727, 'c4': 11.760411262512207}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 16:20:05 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.809591293334961, 'ptb': 13.105127334594727, 'c4': 11.760411262512207}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 17:20:48 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.169776916503906, 'ptb': 13.330580711364746, 'c4': 11.894840240478516}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 17:23:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.809591293334961, 'ptb': 13.105127334594727, 'c4': 11.760411262512207}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 17:24:44 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 17.424951553344727, 'ptb': 20.98378562927246, 'c4': 17.375024795532227}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 17:50:25 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.807783126831055, 'ptb': 13.110246658325195, 'c4': 11.761600494384766}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 17:51:15 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.807480812072754, 'ptb': 13.104557991027832, 'c4': 11.758639335632324}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-18 17:53:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811704635620117, 'ptb': 13.085803985595703, 'c4': 11.760613441467285}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 00:09:59 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.8024320602417, 'ptb': 13.115939140319824, 'c4': 11.76218318939209}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 00:12:11 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.802279472351074, 'ptb': 13.117646217346191, 'c4': 11.760859489440918}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 00:12:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.802279472351074, 'ptb': 13.117077827453613, 'c4': 11.761285781860352}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 00:39:22 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.8024320602417, 'ptb': 13.115939140319824, 'c4': 11.76218318939209}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 10:05:51 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.781579971313477, 'ptb': 13.12562084197998, 'c4': 11.765953063964844}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 10:29:51 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.796555519104004, 'ptb': 13.128469467163086, 'c4': 11.763798713684082}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 10:54:40 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.766773223876953, 'ptb': 13.358963966369629, 'c4': 11.887628555297852}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 10:58:44 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.779023170471191, 'ptb': 13.166702270507812, 'c4': 11.775921821594238}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 11:00:46 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 11.323139190673828, 'ptb': 14.573578834533691, 'c4': 12.967679023742676}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 12:06:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.804693222045898, 'ptb': 13.103421211242676, 'c4': 11.757046699523926}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 12:10:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.807480812072754, 'ptb': 13.10797119140625, 'c4': 11.756351470947266}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 12:13:03 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.804994583129883, 'ptb': 13.111387252807617, 'c4': 11.758392333984375}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 12:35:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.798816680908203, 'ptb': 13.114232063293457, 'c4': 11.75711441040039}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 12:39:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.811854362487793, 'ptb': 13.123340606689453, 'c4': 11.761174201965332}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 12:42:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.886091232299805, 'ptb': 13.195306777954102, 'c4': 11.783110618591309}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 15:55:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.871901512145996, 'ptb': 13.158702850341797, 'c4': 11.786235809326172}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 15:56:54 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.827703475952148, 'ptb': 13.127330780029297, 'c4': 11.766850471496582}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 15:57:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.806729316711426, 'ptb': 13.115939140319824, 'c4': 11.7578763961792}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 17:22:49 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.844255447387695, 'ptb': 13.162703514099121, 'c4': 11.778841018676758}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 17:23:42 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.892473220825195, 'ptb': 13.21135139465332, 'c4': 11.803692817687988}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 17:25:25 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.835711479187012, 'ptb': 13.162129402160645, 'c4': 11.778504371643066}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 19:48:56 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.999289512634277, 'ptb': 13.390310287475586, 'c4': 11.891188621520996}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-19 20:02:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.944032669067383, 'ptb': 13.332898139953613, 'c4': 11.865360260009766}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 09:16:14 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 1.0155917406082153}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 10:12:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.807480812072754, 'ptb': 13.10797119140625, 'c4': 11.756351470947266}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 10:34:31 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.805974006652832, 'ptb': 13.107401847839355, 'c4': 11.757494926452637}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:15:43 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.80717945098877, 'ptb': 13.119924545288086, 'c4': 11.76411247253418}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 17:44:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.796403884887695, 'ptb': 13.12675952911377, 'c4': 11.772193908691406}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 19:00:38 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.793694496154785, 'ptb': 13.132457733154297, 'c4': 11.775741577148438}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 19:16:30 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.824457168579102, 'ptb': 13.104557991027832, 'c4': 11.755566596984863}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 21:28:17 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.818870544433594, 'ptb': 13.117646217346191, 'c4': 11.762969017028809}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-20 21:35:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.824457168579102, 'ptb': 13.104557991027832, 'c4': 11.755566596984863}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-21 09:29:08 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.805974006652832, 'ptb': 13.107401847839355, 'c4': 11.757494926452637}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 10:20:19 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.859848976135254, 'ptb': 13.086371421813965, 'c4': 11.742904663085938}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:40:18 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.946554183959961, 'ptb': 13.162129402160645, 'c4': 11.778122901916504}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:41:35 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.93792724609375, 'ptb': 13.29533576965332, 'c4': 11.84598159790039}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:50:27 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.931291580200195, 'ptb': 13.265939712524414, 'c4': 11.844151496887207}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 11:51:20 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.6920804977417, 'ptb': 13.368823051452637, 'c4': 11.907960891723633}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 12:02:00 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.881991386413574, 'ptb': 13.162703514099121, 'c4': 11.78454875946045}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 12:02:44 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.855305671691895, 'ptb': 13.142722129821777, 'c4': 11.770980834960938}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 12:14:08 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.703049659729004, 'ptb': 13.168416023254395, 'c4': 11.796355247497559}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 12:15:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.8330659866333, 'ptb': 13.10228443145752, 'c4': 11.755141258239746}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 12:16:32 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.747637748718262, 'ptb': 13.121631622314453, 'c4': 11.764629364013672}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 12:47:26 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.827025413513184, 'ptb': 13.103989601135254, 'c4': 11.751867294311523}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 12:47:53 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.78210735321045, 'ptb': 13.107401847839355, 'c4': 11.754557609558105}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-22 12:48:33 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.825060844421387, 'ptb': 13.10228443145752, 'c4': 11.749873161315918}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 11:12:03 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.922144889831543, 'ptb': 13.174132347106934, 'c4': 11.793610572814941}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 11:42:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.872963905334473, 'ptb': 13.145003318786621, 'c4': 11.773001670837402}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 11:52:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.8482666015625, 'ptb': 13.130178451538086, 'c4': 11.76287841796875}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 14:32:13 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.958622932434082, 'ptb': 13.206192016601562, 'c4': 11.818312644958496}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 14:41:49 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.848721504211426, 'ptb': 13.126190185546875, 'c4': 11.763327598571777}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 14:53:16 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.912930488586426, 'ptb': 13.16727352142334, 'c4': 11.795905113220215}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 16:56:36 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.90927791595459, 'ptb': 13.174703598022461, 'c4': 11.791496276855469}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 17:10:46 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.910037994384766, 'ptb': 13.18271255493164, 'c4': 11.79257583618164}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 17:25:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.873114585876465, 'ptb': 13.176993370056152, 'c4': 11.800787925720215}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 18:03:21 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.873114585876465, 'ptb': 13.176993370056152, 'c4': 11.800787925720215}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 18:18:10 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.877742767333984, 'ptb': 13.17813777923584, 'c4': 11.801981925964355}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 18:38:44 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.808686256408691, 'ptb': 13.128469467163086, 'c4': 11.775157928466797}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 19:11:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.822041511535645, 'ptb': 13.121631622314453, 'c4': 11.76523494720459}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-23 19:31:38 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.80454158782959, 'ptb': 13.094324111938477, 'c4': 11.751553535461426}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 12:30:37 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.919023513793945, 'ptb': 13.175849914550781, 'c4': 11.792194366455078}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 12:39:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.875466346740723, 'ptb': 13.135308265686035, 'c4': 11.774147033691406}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 13:32:29 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.913996696472168, 'ptb': 13.169559478759766, 'c4': 11.795883178710938}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 13:57:52 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.872963905334473, 'ptb': 13.142151832580566, 'c4': 11.772664070129395}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 14:01:16 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.849854469299316, 'ptb': 13.127330780029297, 'c4': 11.765997886657715}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 18:08:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.85810661315918, 'ptb': 13.133028030395508, 'c4': 11.767792701721191}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 18:59:09 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.917726516723633, 'ptb': 13.18271255493164, 'c4': 11.798852920532227}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:05:05 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.916812896728516, 'ptb': 13.179852485656738, 'c4': 11.801260948181152}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 19:09:17 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.917726516723633, 'ptb': 13.18271255493164, 'c4': 11.798852920532227}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-24 22:21:06 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.885334014892578, 'ptb': 13.175849914550781, 'c4': 11.795883178710938}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-26 13:30:15 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.921002388000488, 'ptb': 13.149567604064941, 'c4': 11.777897834777832}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-26 20:44:27 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.934724807739258, 'ptb': 13.312657356262207, 'c4': 11.870363235473633}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 08:58:04 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.94418716430664, 'ptb': 13.267667770385742, 'c4': 11.844016075134277}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 09:37:12 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.938156127929688, 'ptb': 13.312657356262207, 'c4': 11.882890701293945}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 09:57:24 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': nan, 'ptb': nan, 'c4': nan}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 13:04:39 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 10.885637283325195, 'ptb': 13.269393920898438, 'c4': 11.854887008666992}

main.py opt-6.7b --wbits 4 --abits 8 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-11-27 16:49:50 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=8, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b') 
 w4a8 {'wikitext2': 13.122344970703125, 'ptb': 16.65005111694336, 'c4': 12.786688804626465}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu 2023-12-04 10:57:14 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=32, R2_clusters=4, R3_clusters=4, R4_clusters=32, R5_clusters=32, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=2, topk_num_final_layer_norm=2, topk_num_fc2=2, topk_num_out_proj_head=2, topk_num_q_proj_head=2, group128=0, group_size=64, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 11.984088897705078, 'ptb': 15.19693660736084, 'c4': 12.843396186828613}

main.py opt-6.7b --wbits 4 --abits 4 --eval_ppl --tasks lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq --multigpu --group128 1 --topk_num 8 --topk_num_final_layer_norm 8 --topk_num_fc2 8 --topk_num_out_proj_head 8 --topk_num_q_proj_head 8 --group_size 128 2023-12-04 11:48:56 
 Namespace(net='opt-6.7b', cache_dir='./data/opt/6.7b', calib_dataset='mix', nsamples=128, percdamp=0.01, seed=2, metric='ema_minmax', tasks='lambada_openai,piqa,arc_easy,arc_challenge,openbookqa,boolq', eval_ppl=True, num_fewshot=0, output_path='./output', wbits=4, abits=4, load='', disable_w_quant=False, disable_a_quant=False, R1_clusters=1, R2_clusters=1, R3_clusters=1, R4_clusters=1, R5_clusters=1, reorder='12345', w_quantizer='gptq', limit=-1, a_dynamic=False, eval_base_ppl=False, act_dist_plot=False, only_quant_kv=False, pack_weight=False, multigpu=True, topk_num=8, topk_num_final_layer_norm=8, topk_num_fc2=8, topk_num_out_proj_head=8, topk_num_q_proj_head=8, group128=1, group_size=128, batch_size=1, model='facebook/opt-6.7b', weight_quant_params={'n_bits': 4, 'per_channel_axes': [0], 'symmetric': False, 'metric': 'minmax'}, act_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, q_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, k_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, v_quant_params={'n_bits': 4, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, layer_norm_out_quant_params={'n_bits': 8, 'per_channel_axes': [], 'symmetric': False, 'metric': 'ema_minmax', 'dynamic': False}, p_quant_params={'n_bits': 8, 'metric': 'fix0to1'}) 
 w4a4 {'wikitext2': 12.132713317871094, 'ptb': 14.640143394470215, 'c4': 13.04838752746582}

